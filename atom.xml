<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Boyolo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://boyolo.github.io/"/>
  <updated>2022-05-24T11:40:47.287Z</updated>
  <id>https://boyolo.github.io/</id>
  
  <author>
    <name>bobo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图</title>
    <link href="https://boyolo.github.io/article/47098.html"/>
    <id>https://boyolo.github.io/article/47098.html</id>
    <published>2022-05-22T04:57:59.000Z</published>
    <updated>2022-05-24T11:40:47.287Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><p><strong>如何理解“图”？</strong></p><p><strong>图（Graph）</strong>和树比起来，这是一种更加复杂的非线性表结构。</p><p>图中的元素就叫做<strong>顶点（vertex）</strong>，图中的一个顶点可以与任意其他顶点建立连接关系。这种建立的关系叫做<strong>边（edge）</strong>。跟顶点相连接的边的条数叫做顶点的<strong>度（degree）</strong>。</p><p>边有方向的图叫做<strong>“有向图”</strong>。边没有方向的图就叫做<strong>“无向图”</strong>。</p><p>在有向图中，我们把度分为<strong>入度（In-degree）和出度（Out-degree）</strong>。</p><p>顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。</p><p><strong>带权图（weighted graph）</strong>。在带权图中，每条边都有一个<strong>权重（weight）</strong>。</p><h3 id="邻接矩阵存储方法"><a href="#邻接矩阵存储方法" class="headerlink" title="邻接矩阵存储方法"></a>邻接矩阵存储方法</h3><p>图最直观的一种存储方法就是，<strong>邻接矩阵（Adjacency Matrix）</strong>。</p><p>邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j]和 A[j][i]标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j]标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i]标记为 1。对于带权图，数组中就存储相应的权重。</p><img src="/article/undefined/%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5.webp" class title="邻接矩阵"><p><strong>优点：</strong></p><ol><li>邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。</li><li>其次，用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。</li></ol><p><strong>缺点：</strong></p><ol><li><p>对于无向图来说，如果 A[i][j]等于 1，那 A[j][i]也肯定等于 1</p><p>无向图的二维数组中，如果我们将其用对角线划分为上下两部分，那只需要利用上面或者下面这样一半的空间就足够了，另外一半白白浪费掉了。</p></li><li><p>如果存储的是稀疏图（Sparse Matrix），顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。</p></li></ol><h3 id="邻接表存储方法"><a href="#邻接表存储方法" class="headerlink" title="邻接表存储方法"></a>邻接表存储方法</h3><p><strong>邻接表</strong></p><img src="/article/undefined/%E9%82%BB%E6%8E%A5%E8%A1%A8.jpg" class title="邻接表"><p>每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。</p><p>有向图的邻接表存储方式，每个顶点对应的链表里面，存储的是指向的顶点</p><p>无向图的邻接表存储方式，每个顶点的链表中存储的，是跟这个顶点有边相连的顶点</p><p><strong>图的算法实现</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Graph</span> </span>&#123; <span class="hljs-comment">// 无向图</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> v; <span class="hljs-comment">// 顶点的个数</span><br>  <span class="hljs-keyword">private</span> LinkedList&lt;Integer&gt; adj[]; <span class="hljs-comment">// 邻接表</span><br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Graph</span><span class="hljs-params">(<span class="hljs-keyword">int</span> v)</span> </span>&#123;<br>    <span class="hljs-keyword">this</span>.v = v;<br>    adj = <span class="hljs-keyword">new</span> LinkedList[v];<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;v; ++i) &#123;<br>      adj[i] = <span class="hljs-keyword">new</span> LinkedList&lt;&gt;();<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addEdge</span><span class="hljs-params">(<span class="hljs-keyword">int</span> s, <span class="hljs-keyword">int</span> t)</span> </span>&#123; <span class="hljs-comment">// 无向图一条边存两次</span><br>    adj[s].add(t);<br>    adj[t].add(s);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>逆邻接表</strong></p><p>逆邻接表中，每个顶点的链表中，存储的是指向这个顶点的顶点</p><img src="/article/undefined/%E9%82%BB%E6%8E%A5%E8%A1%A8%E4%B8%8E%E9%80%86%E9%82%BB%E6%8E%A5%E8%A1%A8.jpg" class title="邻接表与逆邻接表"><h3 id="“搜索”算法？"><a href="#“搜索”算法？" class="headerlink" title="“搜索”算法？"></a>“搜索”算法？</h3><p>算法是作用于具体数据结构之上的，深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构的。</p><ol><li><p>广度优先搜索（BFS）</p><p>广度优先搜索（Breadth-First-Search，简称 BFS）。直观地讲，它其实就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。</p><img src="/article/undefined/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%88BFS%EF%BC%89%E7%A4%BA%E4%BE%8B%E5%9B%BE.jpg" class title="广度优先搜索（BFS）示例图"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-keyword">int</span> s, <span class="hljs-keyword">int</span> t)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (s == t) <span class="hljs-keyword">return</span>;<br>  <span class="hljs-comment">//visited 是用来记录已经被访问的顶点</span><br>  <span class="hljs-keyword">boolean</span>[] visited = <span class="hljs-keyword">new</span> <span class="hljs-keyword">boolean</span>[v];<br>  visited[s]=<span class="hljs-keyword">true</span>;<br>  <span class="hljs-comment">//queue 是一个队列，用来存储已经被访问、但相连的顶点还没有被访问的顶点</span><br>  Queue&lt;Integer&gt; queue = <span class="hljs-keyword">new</span> LinkedList&lt;&gt;();<br>  queue.add(s);<br>  <span class="hljs-comment">//prev 用来记录搜索路径</span><br>  <span class="hljs-keyword">int</span>[] prev = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[v];<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; v; ++i) &#123;<br>    prev[i] = -<span class="hljs-number">1</span>;<br>  &#125;<br>  <span class="hljs-keyword">while</span> (queue.size() != <span class="hljs-number">0</span>) &#123;<br>   <span class="hljs-keyword">int</span> w = queue.poll();<br>   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; adj[w].size(); ++i) &#123;<br>      <span class="hljs-keyword">int</span> q = adj[w].get(i);<br>      <span class="hljs-keyword">if</span> (!visited[q]) &#123;<br>        prev[q] = w;<br>        <span class="hljs-keyword">if</span> (q == t) &#123;<br>          print(prev, s, t);<br>          <span class="hljs-keyword">return</span>;<br>        &#125;<br>        visited[q] = <span class="hljs-keyword">true</span>;<br>        queue.add(q);<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] prev, <span class="hljs-keyword">int</span> s, <span class="hljs-keyword">int</span> t)</span> </span>&#123; <span class="hljs-comment">// 递归打印s-&gt;t的路径</span><br>  <span class="hljs-keyword">if</span> (prev[t] != -<span class="hljs-number">1</span> &amp;&amp; t != s) &#123;<br>    print(prev, s, prev[t]);<br>  &#125;<br>  System.out.print(t + <span class="hljs-string">&quot; &quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>其中 s 表示起始顶点，t 表示终止顶点。搜索一条从 s 到 t 的路径。实际上，这样求得的路径就是从 s 到 t 的最短路径。</p><p><strong>visited</strong> 是用来记录已经被访问的顶点，用来避免顶点被重复访问。如果顶点 q 被访问，那相应的 visited[q]会被设置为 true。</p><p><strong>queue</strong> 是一个队列，用来存储已经被访问、但相连的顶点还没有被访问的顶点。因为广度优先搜索是逐层访问的，也就是说，我们只有把第 k 层的顶点都访问完成之后，才能访问第 k+1 层的顶点。当我们访问到第 k 层的顶点的时候，我们需要把第 k 层的顶点记录下来，稍后才能通过第 k 层的顶点来找第 k+1 层的顶点。所以，我们用这个队列来实现记录的功能。</p><p><strong>prev</strong> 用来记录搜索路径。当我们从顶点 s 开始，广度优先搜索到顶点 t 后，prev 数组中存储的就是搜索的路径。不过，这个路径是反向存储的。prev[w]存储的是，顶点 w 是从哪个前驱顶点遍历过来的。比如，我们通过顶点 2 的邻接表访问到顶点 3，那 prev[3]就等于 2。为了正向打印出路径，我们需要递归地来打印，你可以看下 print() 函数的实现方式。</p><blockquote><img src="/article/undefined/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%9A%84%E5%88%86%E8%A7%A3%E5%9B%BE1.jpg" class title="广度优先搜索的分解图"><img src="/article/undefined/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%9A%84%E5%88%86%E8%A7%A3%E5%9B%BE2.jpg" class title="广度优先搜索的分解图"><img src="/article/undefined/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E7%9A%84%E5%88%86%E8%A7%A3%E5%9B%BE3.jpg" class title="广度优先搜索的分解图3"></blockquote><p><strong>最坏情况时间复杂度</strong>：最坏情况下，终止顶点 t 离起始顶点 s 很远，需要遍历完整个图才能找到。这个时候，每个顶点都要进出一遍队列，每个边也都会被访问一次，所以，广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数。当然，对于一个连通图来说，也就是说一个图中的所有顶点都是连通的，E 肯定要大于等于 V-1，所以，<strong>广度优先搜索的时间复杂度也可以简写为 O(E)。</strong></p><p><strong>空间复杂度</strong>：广度优先搜索的空间消耗主要在几个辅助变量 visited 数组、queue 队列、prev 数组上。这三个存储空间的大小都不会超过顶点的个数，<strong>所以空间复杂度是 O(V)。</strong></p></li><li><p>深度优先搜索（DFS）</p><p>深度优先搜索（Depth-First-Search，简称 DFS）</p><img src="/article/undefined/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%88DFS%EF%BC%89.jpg" class title="深度优先搜索（DFS）"><p>实线箭头表示遍历，虚线箭头表示回退</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//当已经找到终止顶点 t 之后，就不再递归地继续查找了。</span><br><span class="hljs-keyword">boolean</span> found = <span class="hljs-keyword">false</span>; <span class="hljs-comment">// 全局变量或者类成员变量</span><br><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-keyword">int</span> s, <span class="hljs-keyword">int</span> t)</span> </span>&#123;<br>  found = <span class="hljs-keyword">false</span>;<br>  <span class="hljs-keyword">boolean</span>[] visited = <span class="hljs-keyword">new</span> <span class="hljs-keyword">boolean</span>[v];<br>  <span class="hljs-keyword">int</span>[] prev = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[v];<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; v; ++i) &#123;<br>    prev[i] = -<span class="hljs-number">1</span>;<br>  &#125;<br>  recurDfs(s, t, visited, prev);<br>  print(prev, s, t);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">recurDfs</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> t, <span class="hljs-keyword">boolean</span>[] visited, <span class="hljs-keyword">int</span>[] prev)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (found == <span class="hljs-keyword">true</span>) <span class="hljs-keyword">return</span>;<br>  visited[w] = <span class="hljs-keyword">true</span>;<br>  <span class="hljs-keyword">if</span> (w == t) &#123;<br>    found = <span class="hljs-keyword">true</span>;<br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; adj[w].size(); ++i) &#123;<br>    <span class="hljs-keyword">int</span> q = adj[w].get(i);<br>    <span class="hljs-keyword">if</span> (!visited[q]) &#123;<br>      prev[q] = w;<br>      recurDfs(q, t, visited, prev);<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>时间复杂度：</strong>每条边最多会被访问两次，一次是遍历，一次是回退。所以，图上的深度优先搜索算法的<strong>时间复杂度是 O(E)</strong>，E 表示边的个数。</p><p><strong>空间复杂度</strong>：深度优先搜索算法的消耗内存主要是 visited、prev 数组和递归调用栈。visited、prev 数组的大小跟顶点的个数 V 成正比，递归调用栈的最大深度不会超过顶点的个数，所以<strong>总的空间复杂度就是 O(V)</strong>。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图&quot;&gt;&lt;a href=&quot;#图&quot; class=&quot;headerlink&quot; title=&quot;图&quot;&gt;&lt;/a&gt;图&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;如何理解“图”？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图（Graph）&lt;/strong&gt;和树比起来，这是一种更加复杂的非
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="图" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%9B%BE/"/>
    
    
      <category term="数据结构与算法,图" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>Redis核心技术与实战</title>
    <link href="https://boyolo.github.io/article/30584.html"/>
    <id>https://boyolo.github.io/article/30584.html</id>
    <published>2022-05-20T16:03:36.000Z</published>
    <updated>2022-05-22T03:10:48.406Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/article/268247">参考</a></p><p><strong>Redis 知识全景图包括“两大维度，三大主线”</strong></p><p><img src="/article/Redis 知识全景图.jpg"><span class="image-caption">Redis 知识全景图</span></p><p><strong>Redis问题画像</strong></p><img src="/article/undefined/Redis%E9%97%AE%E9%A2%98%E7%94%BB%E5%83%8F.jpeg" class title="Redis问题画像"><h2 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h2><blockquote><p><strong>Redis 的快，到底是快在哪里呢？</strong></p><p><strong>一方面</strong>，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。</p><p><strong>另一方面</strong>，这要归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。</p></blockquote><p>底层数据结构一共有 6 种，分别是<strong>简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组</strong></p><img src="/article/undefined/%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.jpg" class title="底层数据结构"><p>List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下称为集合类型，它们的特点是<strong>一个键对应了一个集合的数据</strong>。</p><p><strong>压缩列表</strong>实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 <strong>zlbytes、zltail 和 zllen</strong>，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 <strong>zlend</strong>，表示列表结束。</p><img src="/article/undefined/%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8.jpg" class title="压缩列表"><p><strong>跳表</strong>在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位</p><img src="/article/undefined/%E8%B7%B3%E8%A1%A8.jpg" class title="跳表"><h3 id="键和值用什么结构组织？"><a href="#键和值用什么结构组织？" class="headerlink" title="键和值用什么结构组织？"></a>键和值用什么结构组织？</h3><p><strong>Redis 使用了一个哈希表来保存所有键值对：</strong>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶，哈希桶中的元素保存的并不是值本身，而是<strong>指向具体值的指针</strong>。</p><p>哈希桶中的 entry 元素中保存了<em>key和</em>value指针，分别指向了实际的键和值</p><img src="/article/undefined/%E5%85%A8%E5%B1%80%E5%93%88%E5%B8%8C%E8%A1%A8.jpg" class title="全局哈希表"><p>可以用 <strong>O(1) 的时间复杂度</strong>来快速查找到键值对——只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素</p><h3 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h3><p>两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中</p><ol><li><p>链式哈希</p><p>Redis 解决哈希冲突的方式，就是链式哈希。<strong>指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。</strong></p><img src="/article/undefined/%E9%93%BE%E8%A1%A8%E6%B3%95.jpg" class title="链表法"></li><li><p>rehash</p><p>如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低</p><p><strong>Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突</strong></p><blockquote><p>Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：</p><ol><li>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；</li><li>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；</li><li>释放哈希表 1 的空间。</li></ol><p>从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用</p><p><strong>问题：第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求</strong></p></blockquote><p><strong>渐进式 rehash</strong></p><p>在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：</p><p><img src="/article/渐进式 rehash.jpg"><span class="image-caption">渐进式 rehash</span></p></li></ol><h3 id="不同数据结构查找的时间复杂度"><a href="#不同数据结构查找的时间复杂度" class="headerlink" title="不同数据结构查找的时间复杂度"></a>不同数据结构查找的时间复杂度</h3><img src="/article/undefined/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.jpg" class title="时间复杂度"><ol><li>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作，复杂度都是 O(1)</li><li>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。</li><li>统计操作，是指集合类型对集合中所有元素个数的记录。这类操作复杂度只有 O(1)。</li><li>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</li></ol><h2 id="Redis：高性能IO模型"><a href="#Redis：高性能IO模型" class="headerlink" title="Redis：高性能IO模型"></a>Redis：高性能IO模型</h2><p><strong>Redis 是单线程，主要是指 Redis 的<u>网络 IO 和键值对读写</u>是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。</strong></p><p><strong>采用单线程的一个核心原因是避免多线程开发的并发控制问题</strong></p><p>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，这是它实现高性能的一个重要原因。</p><p>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p><h3 id="Socket-网络模型的非阻塞模式"><a href="#Socket-网络模型的非阻塞模式" class="headerlink" title="Socket 网络模型的非阻塞模式"></a>Socket 网络模型的非阻塞模式</h3><blockquote><p>以 Get 请求为例，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。</p><img src="/article/undefined/Redis%E5%9F%BA%E6%9C%ACIO%E6%A8%A1%E5%9E%8B.jpg" class title="Redis基本IO模型"><p>但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。</p></blockquote><p>在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。</p><img src="/article/undefined/Redis%E5%A5%97%E6%8E%A5%E5%AD%97%E7%B1%BB%E5%9E%8B%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%E8%AE%BE%E7%BD%AE.jpg" class title="Redis套接字类型与非阻塞设置"><p>针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。</p><blockquote><p>要有机制继续监听监听套接字或已连接套接字，并在有数据达到时通知 Redis。</p></blockquote><h3 id="基于多路复用的高性能-I-O-模型"><a href="#基于多路复用的高性能-I-O-模型" class="headerlink" title="基于多路复用的高性能 I/O 模型"></a>基于多路复用的高性能 I/O 模型</h3><p>Linux 中的 IO 多路复用机制是指<strong>一个线程处理多个 IO 流</strong>，就是select/epoll 机制。</p><p>在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><img src="/article/undefined/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%9A%84Redis%E9%AB%98%E6%80%A7%E8%83%BDIO%E6%A8%A1%E5%9E%8B.webp" class title="基于多路复用的Redis高性能IO模型"><p>图中的多个 FD 就是多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p><strong>回调机制</strong></p><p>为了在请求到达时能通知到 Redis 线程，<strong>select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数</strong>。</p><p>select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/article/268247&quot;&gt;参考&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Redis 知识全景图包括“两大维度，三大主线”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/artic
      
    
    </summary>
    
      <category term="Redis" scheme="https://boyolo.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="https://boyolo.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>树</title>
    <link href="https://boyolo.github.io/article/23384.html"/>
    <id>https://boyolo.github.io/article/23384.html</id>
    <published>2022-05-17T02:32:28.000Z</published>
    <updated>2022-05-21T17:42:36.306Z</updated>
    
    <content type="html"><![CDATA[<p><strong>二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？</strong></p><h2 id="树（Tree）"><a href="#树（Tree）" class="headerlink" title="树（Tree）"></a>树（Tree）</h2><img src="/article/undefined/%E4%BB%80%E4%B9%88%E6%98%AF%E6%A0%91.jpg" class title="什么是树"><img src="/article/undefined/%E6%A0%91.jpg" class title="树"><p>A 节点就是 B 节点的<strong>父节点</strong>，B 节点是 A 节点的<strong>子节点</strong>。B、C、D 这三个节点的父节点是同一个节点，所以它们之间互称为<strong>兄弟节点</strong>。没有父节点的节点叫做<strong>根节点</strong>，也就是图中的节点 E。我们把没有子节点的节点叫做<strong>叶子节点或者叶节点</strong>，比如图中的 G、H、I、J、K、L 都是叶子节点。</p><p><strong>高度（Height）：</strong>节点到叶子结点的最长路径（边数） （树的高度 = 根节点的高度）</p><p><strong>深度（Depth）：</strong>根节点到这个节点所经历的边得个数</p><p><strong>层（Level）：</strong>节点的深度 + 1</p><img src="/article/undefined/%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%B1%82.jpg" class title="树的高度深度层"><h2 id="二叉树（Binary-Tree）"><a href="#二叉树（Binary-Tree）" class="headerlink" title="二叉树（Binary Tree）"></a>二叉树（Binary Tree）</h2><p>二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是<strong>左子节点和右子节点</strong>。</p><img src="/article/undefined/%E4%BA%8C%E5%8F%89%E6%A0%91.jpg" class title="二叉树"><p><strong>满二叉树：</strong>编号 2 的二叉树中，<strong>叶子节点全都在最底层</strong>，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做满二叉树。</p><p><strong>完全二叉树：</strong>编号 3 的二叉树中，<strong>叶子节点都在最底下两层</strong>，<strong>最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大</strong>，这种二叉树叫做完全二叉树。</p><blockquote><p><strong>如何求一棵包含 n 个节点的完全二叉树的高度？</strong></p><p>包含 n 个节点的完全二叉树中，第一层包含 1 个节点，第二层包含 2 个节点，第三层包含 4 个节点，依次类推，下面一层节点个数是上一层的 2 倍，第 K 层包含的节点个数就是 2^(K-1)。</p><p><strong>最后一层的节点个数包含的节点个数在 1 个到 2^(L-1) 个之间（假设最大层数是 L）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">n &gt;= 1+2+4+8+...+2^(L-2)+1<br>n &lt;= 1+2+4+8+...+2^(L-2)+2^(L-1)<br></code></pre></td></tr></table></figure><p><strong>L 的范围是[log<sub>2</sub>(n+1), log<sub>2</sub>n +1]</strong></p><p>完全二叉树的层数小于等于 log<sub>2</sub>n +1，也就是说，完全二叉树的高度小于等于 log<sub>2</sub>n。</p></blockquote><h3 id="如何表示（或者存储）一棵二叉树？"><a href="#如何表示（或者存储）一棵二叉树？" class="headerlink" title="如何表示（或者存储）一棵二叉树？"></a>如何表示（或者存储）一棵二叉树？</h3><p>想要存储一棵二叉树，有两种方法，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。</p><ol><li><p>链式存储法</p><img src="/article/undefined/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%93%BE%E5%BC%8F%E5%AD%98%E5%82%A8.jpg" class title="二叉树的链式存储"><p>每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针</p></li><li><p>顺序存储法</p><img src="/article/undefined/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8.jpg" class title="二叉树的顺序存储"><p><strong>根节点存储在下标 i = 1 的位置</strong></p><p><strong>左子节点</strong>存储在下标 <strong>2 * i = 2</strong> 的位置</p><p><strong>右子节点</strong>存储在 <strong>2 * i + 1 = 3</strong> 的位置</p><p>如果节点 X 存储在数组中下标为 i 的位置，下标为 2 <em> i 的位置存储的就是左子节点，下标为 2 </em> i + 1 的位置存储的就是右子节点。反过来，下标为 i/2 的位置存储就是它的父节点。</p><p><strong>完全二叉树，用数组存储是最节省内存的一种方式</strong></p></li></ol><h3 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h3><img src="/article/undefined/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86.jpg" class title="二叉树的遍历"><p>二叉树的前、中、后序遍历就是一个递归的过程</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c">前序遍历的递推公式：<br>preOrder(r) = print r-&gt;preOrder(r-&gt;left)-&gt;preOrder(r-&gt;right)<br><br>中序遍历的递推公式：<br>inOrder(r) = inOrder(r-&gt;left)-&gt;print r-&gt;inOrder(r-&gt;right)<br><br>后序遍历的递推公式：<br>postOrder(r) = postOrder(r-&gt;left)-&gt;postOrder(r-&gt;right)-&gt;print r<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">preOrder</span><span class="hljs-params">(Node* root)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (root == <span class="hljs-keyword">null</span>) <span class="hljs-keyword">return</span>;<br>  print root <span class="hljs-comment">// 此处为伪代码，表示打印root节点</span><br>  preOrder(root-&gt;left);<br>  preOrder(root-&gt;right);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">inOrder</span><span class="hljs-params">(Node* root)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (root == <span class="hljs-keyword">null</span>) <span class="hljs-keyword">return</span>;<br>  inOrder(root-&gt;left);<br>  print root <span class="hljs-comment">// 此处为伪代码，表示打印root节点</span><br>  inOrder(root-&gt;right);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">postOrder</span><span class="hljs-params">(Node* root)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (root == <span class="hljs-keyword">null</span>) <span class="hljs-keyword">return</span>;<br>  postOrder(root-&gt;left);<br>  postOrder(root-&gt;right);<br>  print root <span class="hljs-comment">// 此处为伪代码，表示打印root节点</span><br>&#125;<br></code></pre></td></tr></table></figure><p>每个节点最多会被访问两次，所以遍历操作的时间复杂度，跟节点的个数 n 成正比，也就是说<strong>二叉树遍历的时间复杂度是 O(n)</strong></p><p><strong>中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)</strong></p><h3 id="二叉查找树（Binary-Search-Tree）"><a href="#二叉查找树（Binary-Search-Tree）" class="headerlink" title="二叉查找树（Binary Search Tree）"></a>二叉查找树（Binary Search Tree）</h3><p><strong>二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。</strong></p><ol><li><p>二叉查找树的查找操作</p><p>先取根节点，如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。</p><img src="/article/undefined/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%E7%9A%84%E6%9F%A5%E6%89%BE%E6%93%8D%E4%BD%9C.jpg" class title="二叉查找树的查找操作"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BinarySearchTree</span> </span>&#123;<br>  <span class="hljs-keyword">private</span> Node tree;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> Node <span class="hljs-title">find</span><span class="hljs-params">(<span class="hljs-keyword">int</span> data)</span> </span>&#123;<br>    Node p = tree;<br>    <span class="hljs-keyword">while</span> (p != <span class="hljs-keyword">null</span>) &#123;<br>      <span class="hljs-keyword">if</span> (data &lt; p.data) p = p.left;<br>      <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (data &gt; p.data) p = p.right;<br>      <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> p;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>  &#125;<br><br>  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> data;<br>    <span class="hljs-keyword">private</span> Node left;<br>    <span class="hljs-keyword">private</span> Node right;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Node</span><span class="hljs-params">(<span class="hljs-keyword">int</span> data)</span> </span>&#123;<br>      <span class="hljs-keyword">this</span>.data = data;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>二叉查找树的插入操作</p><p>新插入的数据一般都是在叶子节点上，所以我们只需要从根节点开始，依次比较要插入的数据和节点的大小关系。</p><p>如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-keyword">int</span> data)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (tree == <span class="hljs-keyword">null</span>) &#123;<br>    tree = <span class="hljs-keyword">new</span> Node(data);<br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br><br>  Node p = tree;<br>  <span class="hljs-keyword">while</span> (p != <span class="hljs-keyword">null</span>) &#123;<br>    <span class="hljs-keyword">if</span> (data &gt; p.data) &#123;<br>      <span class="hljs-keyword">if</span> (p.right == <span class="hljs-keyword">null</span>) &#123;<br>        p.right = <span class="hljs-keyword">new</span> Node(data);<br>        <span class="hljs-keyword">return</span>;<br>      &#125;<br>      p = p.right;<br>    &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// data &lt; p.data</span><br>      <span class="hljs-keyword">if</span> (p.left == <span class="hljs-keyword">null</span>) &#123;<br>        p.left = <span class="hljs-keyword">new</span> Node(data);<br>        <span class="hljs-keyword">return</span>;<br>      &#125;<br>      p = p.left;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>二叉查找树的删除操作</p><ol><li>如果要删除的节点没有子节点，只需要直接将父节点中，指向要删除节点的指针置为 null</li><li>如果要删除的节点只有一个子节点（只有左子节点或者右子节点），只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了</li><li>如果要删除的节点有两个子节点，需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了）</li></ol><img src="/article/undefined/%E8%A6%81%E5%88%A0%E9%99%A4%E7%9A%84%E8%8A%82%E7%82%B9%E6%9C%89%E4%B8%A4%E4%B8%AA%E5%AD%90%E8%8A%82%E7%82%B9.jpg" class title="要删除的节点有两个子节点"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">delete</span><span class="hljs-params">(<span class="hljs-keyword">int</span> data)</span> </span>&#123;<br>  Node p = tree; <span class="hljs-comment">// p指向要删除的节点，初始化指向根节点</span><br>  Node pp = <span class="hljs-keyword">null</span>; <span class="hljs-comment">// pp记录的是p的父节点</span><br>  <span class="hljs-keyword">while</span> (p != <span class="hljs-keyword">null</span> &amp;&amp; p.data != data) &#123;<br>    pp = p;<br>    <span class="hljs-keyword">if</span> (data &gt; p.data) p = p.right;<br>    <span class="hljs-keyword">else</span> p = p.left;<br>  &#125;<br>  <span class="hljs-keyword">if</span> (p == <span class="hljs-keyword">null</span>) <span class="hljs-keyword">return</span>; <span class="hljs-comment">// 没有找到</span><br><br>  <span class="hljs-comment">// 要删除的节点有两个子节点</span><br>  <span class="hljs-keyword">if</span> (p.left != <span class="hljs-keyword">null</span> &amp;&amp; p.right != <span class="hljs-keyword">null</span>) &#123; <span class="hljs-comment">// 查找右子树中最小节点</span><br>    Node minP = p.right;<br>    Node minPP = p; <span class="hljs-comment">// minPP表示minP的父节点</span><br>    <span class="hljs-keyword">while</span> (minP.left != <span class="hljs-keyword">null</span>) &#123;<br>      minPP = minP;<br>      minP = minP.left;<br>    &#125;<br>    p.data = minP.data; <span class="hljs-comment">// 将minP的数据替换到p中</span><br>    p = minP; <span class="hljs-comment">// 下面就变成了删除minP了</span><br>    pp = minPP;<br>  &#125;<br><br>  <span class="hljs-comment">// 删除节点是叶子节点或者仅有一个子节点</span><br>  Node child; <span class="hljs-comment">// p的子节点</span><br>  <span class="hljs-keyword">if</span> (p.left != <span class="hljs-keyword">null</span>) child = p.left;<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (p.right != <span class="hljs-keyword">null</span>) child = p.right;<br>  <span class="hljs-keyword">else</span> child = <span class="hljs-keyword">null</span>;<br><br>  <span class="hljs-keyword">if</span> (pp == <span class="hljs-keyword">null</span>) tree = child; <span class="hljs-comment">// 删除的是根节点</span><br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (pp.left == p) pp.left = child;<br>  <span class="hljs-keyword">else</span> pp.right = child;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>二叉查找树的其他操作</p><p>二叉查找树中还可以支持快速地查找最大节点和最小节点、前驱节点和后继节点</p></li></ol><p><strong>支持重复数据的二叉查找树</strong></p><p>二叉查找树也可以存储包含很多字段的对象</p><p>利用对象的<strong>某个字段作为键值（key）</strong>来构建二叉查找树。对象中的其他字段叫作卫星数据。</p><blockquote><p><strong>问题：如果存储的两个对象键值相同，这种情况该怎么处理呢？</strong></p><ol><li><p>二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。</p></li><li><p>每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。</p><p>当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。</p></li></ol></blockquote><p><strong>二叉查找树的时间复杂度分析</strong></p><ol><li><p>最坏情况时间复杂度：O(n)</p></li><li><p>最好情况时间复杂度：二叉查找树是一棵完全二叉树（或满二叉树），跟树的高度成正比，也就是 O(height)</p></li></ol><hr><blockquote><p><strong>问题：相对散列表，为什么还要用二叉查找树呢？</strong></p><ol><li>第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。</li><li>散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。</li><li>尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。</li><li>第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。</li><li>最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。</li></ol></blockquote><hr><h2 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h2><h3 id="什么是“平衡二叉查找树”？"><a href="#什么是“平衡二叉查找树”？" class="headerlink" title="什么是“平衡二叉查找树”？"></a>什么是“平衡二叉查找树”？</h3><p>平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1。</p><img src="/article/undefined/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.jpg" class title="平衡二叉树"><p>很多平衡二叉查找树其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1）。比如<strong>红黑树</strong>，<strong>它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。</strong></p><h3 id="如何定义一棵“红黑树”？"><a href="#如何定义一棵“红黑树”？" class="headerlink" title="如何定义一棵“红黑树”？"></a>如何定义一棵“红黑树”？</h3><p>红黑树(Red-Black Tree，简称 R-B Tree)，是一种不严格的平衡二叉查找树。</p><p>顾名思义，红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：</p><ol><li>根节点是黑色的；</li><li>每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；</li><li>任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；</li><li>每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；</li></ol><img src="/article/undefined/%E7%9C%81%E7%95%A5%E5%8C%85%E5%90%AB%E7%A9%BA%E8%8A%82%E7%82%B9%E7%9A%84%E7%BA%A2%E9%BB%91%E6%A0%91.jpg" class title="省略包含空节点的红黑树"><h3 id="为什么说红黑树是“近似平衡”的？"><a href="#为什么说红黑树是“近似平衡”的？" class="headerlink" title="为什么说红黑树是“近似平衡”的？"></a>为什么说红黑树是“近似平衡”的？</h3><p>平衡二叉查找树的初衷，是为了解决二叉查找树因为动态更新导致的性能退化问题。所以，<strong>“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化得太严重。</strong></p><blockquote><p><strong>红黑树的高度分析</strong></p><ol><li><p>首先，如果将红色节点从红黑树中去掉，那单纯包含黑色节点的红黑树的高度是多少呢？</p><p>红色节点删除之后，有些节点就没有父节点了，它们会直接拿这些节点的祖父节点（父节点的父节点）作为父节点。所以，之前的二叉树就变成了四叉树。</p><img src="/article/undefined/%E5%8E%BB%E6%8E%89%E7%BA%A2%E8%89%B2%E8%8A%82%E7%82%B9%E7%9A%84%E7%BA%A2%E9%BB%91%E6%A0%91.jpg" class title="去掉红色节点的红黑树"><blockquote><p>红黑树的定义中：从任意节点到可达的叶子节点的每个路径包含相同数目的黑色节点。</p></blockquote><p>从四叉树中取出某些节点，放到叶节点位置，四叉树就变成了完全二叉树。所以，仅包含黑色节点的四叉树的高度，比包含相同节点个数的完全二叉树的高度还要小。</p></li><li><p>把红色节点加回去，高度会变成多少呢？</p><blockquote><p>红黑树的定义中：任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；也就是说，有一个红色节点就要至少有一个黑色节点，将它跟其他红色节点隔开。</p></blockquote><p>红黑树中包含最多黑色节点的路径不会超过 log<sub>2</sub>n，所以加入红色节点之后，最长路径不会超过 2log<sub>2</sub>nn，也就是说，<strong>红黑树的高度近似 2log<sub>2</sub>n。</strong></p></li></ol></blockquote><h3 id="实现红黑树的基本思想"><a href="#实现红黑树的基本思想" class="headerlink" title="实现红黑树的基本思想"></a>实现红黑树的基本思想</h3><p>一棵合格的红黑树需要满足这样几个要求：</p><ol><li>根节点是黑色的；</li><li>每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；</li><li>任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；</li><li>每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。</li></ol><p>在插入、删除节点的过程中，第三、第四点要求可能会被破坏，而红黑树的“平衡调整”，实际上就是要把被破坏的第三、第四点恢复过来。</p><p><strong>左旋（rotate left）围绕某个节点的左旋、右旋（rotate right）围绕某个节点的右旋</strong></p><img src="/article/undefined/%E5%B7%A6%E6%97%8B%E5%8F%B3%E6%97%8B%E7%AE%80%E5%9B%BE.jpg" class title="左旋右旋简图"><h3 id="插入删除平衡调整"><a href="#插入删除平衡调整" class="headerlink" title="插入删除平衡调整"></a>插入删除平衡调整</h3><h4 id="插入操作的平衡调整"><a href="#插入操作的平衡调整" class="headerlink" title="插入操作的平衡调整"></a>插入操作的平衡调整</h4><p><strong>红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上</strong></p><ol><li>如果插入节点的父节点是黑色的，什么都不用做，它仍然满足红黑树的定义。</li><li>如果插入的节点是根节点，那我们直接改变它的颜色，把它变成黑色就可以了。</li><li>其他违背红黑树定义的情况。（<strong>左右旋转和改变颜色</strong>）</li></ol><p>正在处理的节点叫做<strong>关注节点</strong></p><ol><li><p>如果关注节点是 a，它的叔叔节点 d 是红色</p><p><img src="/article/插入CASE 1.jpg"><span class="image-caption">CASE 1</span></p><ol><li>将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色；</li><li>将关注节点 a 的祖父节点 c 的颜色设置成红色；</li><li>关注节点变成 a 的祖父节点 c；</li><li>跳到 CASE 2 或者 CASE 3。</li></ol></li><li><p>如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点</p><p><img src="/article/插入CASE 2.jpg"><span class="image-caption">CASE 2</span></p><ol><li>关注节点变成节点 a 的父节点 b；</li><li>围绕新的关注节点b 左旋；</li><li>跳到 CASE 3。</li></ol></li><li><p>如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点</p><p><img src="/article/插入CASE 3.jpg"><span class="image-caption">CASE 3</span></p><ol><li>围绕关注节点 a 的祖父节点 c 右旋；</li><li>将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换。</li><li>调整结束。</li></ol></li></ol><h4 id="删除操作的平衡调整"><a href="#删除操作的平衡调整" class="headerlink" title="删除操作的平衡调整"></a>删除操作的平衡调整</h4><p><strong>第一步是针对删除节点初步调整</strong>。初步调整只是保证整棵红黑树在一个节点删除之后，仍然满足最后一条定义的要求，也就是说，每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；<strong>第二步是针对关注节点进行二次调整</strong>，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。</p><ol><li><p>针对删除节点初步调整</p><p>红黑树的定义中“只包含红色节点和黑色节点”，</p><p>经过初步调整之后，为了保证满足红黑树定义的最后一条要求，有些节点会被标记成两种颜色，“红 - 黑”或者“黑 - 黑”。如果一个节点被标记为了“黑 - 黑”，那在计算黑色节点个数的时候，要算成两个黑色节点。</p><ol><li><p>如果要删除的节点是 a，它只有一个子节点 b</p><p><img src="/article/初步删除CASE 1.jpg"><span class="image-caption">初步删除CASE 1</span></p><ol><li>删除节点 a，并且把节点 b 替换到节点 a 的位置；</li><li>节点 a 只能是黑色，节点 b 也只能是红色，其他情况均不符合红黑树的定义。这种情况下，我们把节点 b 改为黑色；</li><li>调整结束，不需要进行二次调整。</li></ol></li><li><p>如果要删除的节点 a 有两个非空子节点，并且它的后继节点就是节点 a 的右子节点 c</p><p><img src="/article/初步删除CASE 2.jpg"><span class="image-caption">初步删除CASE 2</span></p><ol><li>如果节点 a 的后继节点就是右子节点 c，那右子节点 c 肯定没有左子树。把节点 a 删除，并且将节点 c 替换到节点 a 的位置；</li><li>然后把节点 c 的颜色设置为跟节点 a 相同的颜色；</li><li>如果节点 c 是黑色，为了不违反红黑树的最后一条定义，我们给节点 c 的右子节点 d 多加一个黑色，这个时候节点 d 就成了“红 - 黑”或者“黑 - 黑”；</li><li>这个时候，关注节点变成了节点 d，第二步的调整操作就会针对关注节点来做。</li></ol></li><li><p>如果要删除的是节点 a，它有两个非空子节点，并且节点 a 的后继节点不是右子节点</p><p><img src="/article/初步删除CASE 3.jpg"><span class="image-caption">初步删除CASE 3</span></p><ol><li>找到后继节点 d，并将它删除，删除后继节点 d 的过程参照 CASE 1；</li><li>将节点 a 替换成后继节点 d；</li><li>把节点 d 的颜色设置为跟节点 a 相同的颜色；</li><li>如果节点 d 是黑色，为了不违反红黑树的最后一条定义，我们给节点 d 的右子节点 c 多加一个黑色，这个时候节点 c 就成了“红 - 黑”或者“黑 - 黑”；</li><li>这个时候，关注节点变成了节点 c，第二步的调整操作就会针对关注节点来做。</li></ol></li></ol></li><li><p>针对关注节点进行二次调整</p><p>经过初步调整之后，关注节点变成了“红 - 黑”或者“黑 - 黑”节点</p><ol><li><p>如果关注节点是 a，它的兄弟节点 c 是红色的</p><p><img src="/article/删除二次调整CASE 1.jpg"><span class="image-caption">删除二次调整CASE 1</span></p><ol><li>围绕关注节点 a 的父节点 b 左旋；</li><li>关注节点 a 的父节点 b 和祖父节点 c 交换颜色；</li><li>关注节点不变；</li><li>继续从四种情况中选择适合的规则来调整。</li></ol></li><li><p>如果关注节点是 a，它的兄弟节点 c 是黑色的，并且节点 c 的左右子节点 d、e 都是黑色的</p><p><img src="/article/删除二次调整CASE 2.jpg"><span class="image-caption">删除二次调整CASE 2</span></p><ol><li>将关注节点 a 的兄弟节点 c 的颜色变成红色；</li><li>从关注节点 a 中去掉一个黑色，这个时候节点 a 就是单纯的红色或者黑色；</li><li>给关注节点 a 的父节点 b 添加一个黑色，这个时候节点 b 就变成了“红 - 黑”或者“黑 - 黑”；</li><li>关注节点从 a 变成其父节点 b；</li><li>继续从四种情况中选择符合的规则来调整。</li></ol></li><li><p>如果关注节点是 a，它的兄弟节点 c 是黑色，c 的左子节点 d 是红色，c 的右子节点 e 是黑色</p><p><img src="/article/删除二次调整CASE 3.jpg"><span class="image-caption">删除二次调整CASE 3</span></p><ol><li>围绕关注节点 a 的兄弟节点 c 右旋；</li><li>节点 c 和节点 d 交换颜色；</li><li>关注节点不变；</li><li>跳转到 CASE 4，继续调整。</li></ol></li><li><p>如果关注节点 a 的兄弟节点 c 是黑色的，并且 c 的右子节点是红色的</p><p><img src="/article/删除二次调整CASE 4.jpg"><span class="image-caption">删除二次调整CASE 4</span></p><ol><li>围绕关注节点 a 的父节点 b 左旋；</li><li>将关注节点 a 的兄弟节点 c 的颜色，跟关注节点 a 的父节点 b 设置成相同的颜色；</li><li>将关注节点 a 的父节点 b 的颜色设置为黑色；</li><li>从关注节点 a 中去掉一个黑色，节点 a 就变成了单纯的红色或者黑色；</li><li>将关注节点 a 的叔叔节点 e 设置为黑色；调整结束。</li></ol></li></ol></li></ol><h2 id="递归树"><a href="#递归树" class="headerlink" title="递归树"></a>递归树</h2><p><strong>如何用递归树，来分析递归代码的时间复杂度</strong></p><blockquote><img src="/article/undefined/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E9%80%92%E5%BD%92%E6%A0%91.jpg" class title="归并排序递归树"><p>归并排序递归树时间复杂度</p><p>因为每次分解都是一分为二，所以代价很低，把时间上的消耗记作常量 1。</p><p>归并算法中比较耗时的是归并操作，也就是把两个子数组合并为大数组。从图中可以看出，每一层归并操作消耗的时间总和是一样的，跟要排序的数据规模有关。把每一层归并操作消耗的时间记作 n。</p><p>只需要知道这棵树的高度 h，用高度 h 乘以每一层的时间消耗 n，就可以得到总的时间复杂度 O(n * h)</p><p>归并排序递归树是一棵满二叉树。满二叉树的高度大约是 log<sub>2</sub>n，所以，<strong>归并排序递归实现的时间复杂度就是 O(nlogn)</strong></p></blockquote><h3 id="实战一：分析快速排序的时间复杂度"><a href="#实战一：分析快速排序的时间复杂度" class="headerlink" title="实战一：分析快速排序的时间复杂度"></a>实战一：分析快速排序的时间复杂度</h3><blockquote><p>快速排序在最好情况下，每次分区都能一分为二，用递推公式 T(n)=2T(n/2)+n，很容易就能推导出时间复杂度是 O(nlogn)。但是，不可能每次分区都正好一分为二。</p><p>假设平均情况下，每次分区之后，两个分区的大小比例为 1:k。当 k=9 时，如果用递推公式的方法来求解时间复杂度的话，递推公式就写成 T(n)=T(n/10)+T(9n/10)+n。</p></blockquote><p><strong>用递归树来分析快速排序的平均情况时间复杂度</strong></p><img src="/article/undefined/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E9%80%92%E5%BD%92%E6%A0%91.jpg" class title="快速排序递归树"><p>快速排序的过程中，每次分区都要遍历待分区区间的所有数据，所以，每一层分区操作所遍历的数据的个数之和就是 n。我们现在只要求出递归树的高度 h，这个快排过程遍历的数据个数就是 h <em> n ，也就是说，时间复杂度就是 O(h </em> n)。</p><p>因为每次分区并不是均匀地一分为二，所以递归树并不是满二叉树。</p><blockquote><p>快速排序结束的条件就是待排序的小区间，大小为 1，也就是说叶子节点里的数据规模是 1。从根节点 n 到叶子节点 1，递归树中最短的一个路径每次都乘以 1/10，最长的一个路径每次都乘以 9/10。通过计算可以得到，从根节点到叶子节点的最短路径是 log<sub>10</sub>n，最长的路径是 log<sub>10/9</sub>n</p><img src="/article/undefined/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E9%80%92%E5%BD%92%E6%A0%91%E8%B7%AF%E5%BE%84%E9%95%BF%E5%BA%A6.jpg" class title="快速排序递归树路径长度"></blockquote><p>所以，遍历数据的个数总和就介于 nlog<sub>10</sub>n 和 nlog<sub>10/9</sub>n 之间</p><p>当分区大小比例是 1:9 时，快速排序的时间复杂度仍然是 O(nlogn)</p><p>对于 k 等于 9，99，甚至是 999，9999……，只要 k 的值不随 n 变化，是一个事先确定的常量，那快排的时间复杂度就是 O(nlogn)。所以，从概率论的角度来说，快排的平均时间复杂度就是 O(nlogn)。</p><h3 id="实战二：分析斐波那契数列的时间复杂度"><a href="#实战二：分析斐波那契数列的时间复杂度" class="headerlink" title="实战二：分析斐波那契数列的时间复杂度"></a>实战二：分析斐波那契数列的时间复杂度</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">f</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">if</span> (n == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;<br>  <span class="hljs-keyword">return</span> f(n-<span class="hljs-number">1</span>) + f(n-<span class="hljs-number">2</span>);<br>&#125;<br></code></pre></td></tr></table></figure><img src="/article/undefined/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E9%80%92%E5%BD%92%E6%A0%91.jpg" class title="斐波那契数列递归树"><blockquote><p>斐波那契数列递归树的高度</p><p>f(n) 分解为 f(n−1) 和 f(n−2)，每次数据规模都是 −1 或者 −2，叶子节点的数据规模是 1 或者 2。所以，从根节点走到叶子节点，每条路径是长短不一的。如果每次都是 −1，那最长路径大约就是 n；如果每次都是 −2，那最短路径大约就是 n/2。</p><p>每次分解之后的合并操作只需要一次加法运算，把这次加法运算的时间消耗记作 1。所以，从上往下，第一层的总时间消耗是 1，第二层的总时间消耗是 2，第三层的总时间消耗就是 2<sup>2</sup>。依次类推，第 k 层的时间消耗就是 2<sup>k−1</sup>，那整个算法的总的时间消耗就是每一层时间消耗之和。</p><p>如果路径长度都为 n，那这个总和就是 2<sup>n</sup>−1。</p><p>如果路径长度都是 n/2 ，那整个算法的总的时间消耗就是 2<sup>n/2</sup>−1。</p></blockquote><p>算法的时间复杂度就介于 O(2<sup>n</sup>) 和 O(2<sup>n/2</sup>) 之间</p><h3 id="实战三：分析全排列的时间复杂度"><a href="#实战三：分析全排列的时间复杂度" class="headerlink" title="实战三：分析全排列的时间复杂度"></a>实战三：分析全排列的时间复杂度</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">1, 2, 3<br>1, 3, 2<br>2, 1, 3<br>2, 3, 1<br>3, 1, 2<br>3, 2, 1<br></code></pre></td></tr></table></figure><p>如果确定了最后一位数据，那就变成了求解剩下 n−1 个数据的排列问题。而最后一位数据可以是 n 个数据中的任意一个，因此它的取值就有 n 种情况。所以，“n 个数据的排列”问题，就可以分解成 n 个“n−1 个数据的排列”的子问题。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">假设数组中存储的是1，2， 3...n。<br>        <br>f(1,2,...n) = &#123;最后一位是1, f(n-1)&#125; + &#123;最后一位是2, f(n-1)&#125; +...+&#123;最后一位是n, f(n-1)&#125;。<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 调用方式：</span><br><span class="hljs-comment">// int[]a = a=&#123;1, 2, 3, 4&#125;; printPermutations(a, 4, 4);</span><br><span class="hljs-comment">// k表示要处理的子数组的数据个数</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printPermutations</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] data, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> k)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (k == <span class="hljs-number">1</span>) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>      System.out.print(data[i] + <span class="hljs-string">&quot; &quot;</span>);<br>    &#125;<br>    System.out.println();<br>  &#125;<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; k; ++i) &#123;<br>    <span class="hljs-keyword">int</span> tmp = data[i];<br>    data[i] = data[k-<span class="hljs-number">1</span>];<br>    data[k-<span class="hljs-number">1</span>] = tmp;<br><br>    printPermutations(data, n, k - <span class="hljs-number">1</span>);<br><br>    tmp = data[i];<br>    data[i] = data[k-<span class="hljs-number">1</span>];<br>    data[k-<span class="hljs-number">1</span>] = tmp;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><img src="/article/undefined/%E5%85%A8%E6%8E%92%E5%88%97%E9%80%92%E5%BD%92%E6%A0%91.jpg" class title="全排列递归树"><p>第一层分解有 n 次交换操作，第二层有 n 个节点，每个节点分解需要 n−1 次交换，所以第二层总的交换次数是 n <em> (n−1)。第三层有 n </em> (n−1) 个节点，每个节点分解需要 n−2 次交换，所以第三层总的交换次数是 n <em> (n−1) </em> (n−2)。</p><p>以此类推，第 k 层总的交换次数就是 n <em> (n−1) </em> (n−2) <em> … </em> (n−k+1)。最后一层的交换次数就是 n <em> (n−1) </em> (n−2) <em> … </em> 2 * 1。每一层的交换次数之和就是总的交换次数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">n + n*(n-1) + n*(n-1)*(n-2) +... + n*(n-1)*(n-2)*...*2*1<br></code></pre></td></tr></table></figure><p>最后一个数，n <em> (n−1) </em> (n−2) <em> … </em> 2 <em> 1 等于 n!，而前面的 n−1 个数都小于最后一个数，所以，总和肯定小于 n </em> n!，也就是说，<strong>全排列的递归算法的时间复杂度大于 O(n!)，小于 O(n * n!)</strong></p><h2 id="“堆”（Heap）"><a href="#“堆”（Heap）" class="headerlink" title="“堆”（Heap）"></a>“堆”（Heap）</h2><p><strong>堆排序是一种原地的、时间复杂度为 O(nlogn) 的排序算法</strong></p><p><strong>堆排序不是稳定的排序算法</strong></p><p>堆满足的两点要求：</p><ol><li>堆是一个完全二叉树；</li><li>堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。</li></ol><h3 id="如何实现一个堆？"><a href="#如何实现一个堆？" class="headerlink" title="如何实现一个堆？"></a>如何实现一个堆？</h3><p>完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。</p><img src="/article/undefined/%E6%95%B0%E7%BB%84%E5%AD%98%E5%82%A8%E5%A0%86.jpg" class title="数组存储堆"><p>数组中下标为 i 的节点的左子节点，就是下标为 i <em> 2 的节点，右子节点就是下标为 i </em> 2 + 1 的节点，父节点就是下标为 i/2 的节点。</p><p><strong>堆化（heapify）</strong></p><p>堆化有两种，从下往上和从上往下</p><ol><li><p>从下往上的堆化方法</p><img src="/article/undefined/%E5%BE%80%E5%A0%86%E4%B8%AD%E6%8F%92%E5%85%A5%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0.jpg" class title="往堆中插入一个元素"><p>让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足堆的大小关系</p><img src="/article/undefined/%E4%BB%8E%E4%B8%8B%E5%BE%80%E4%B8%8A%E7%9A%84%E5%A0%86%E5%8C%96%E6%96%B9%E6%B3%95.jpg" class title="从下往上的堆化方法"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Heap</span> </span>&#123;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span>[] a; <span class="hljs-comment">// 数组，从下标1开始存储数据</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> n;  <span class="hljs-comment">// 堆可以存储的最大数据个数</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> count; <span class="hljs-comment">// 堆中已经存储的数据个数</span><br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Heap</span><span class="hljs-params">(<span class="hljs-keyword">int</span> capacity)</span> </span>&#123;<br>    a = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[capacity + <span class="hljs-number">1</span>];<br>    n = capacity;<br>    count = <span class="hljs-number">0</span>;<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-keyword">int</span> data)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (count &gt;= n) <span class="hljs-keyword">return</span>; <span class="hljs-comment">// 堆满了</span><br>    ++count;<br>    a[count] = data;<br>    <span class="hljs-keyword">int</span> i = count;<br>    <span class="hljs-keyword">while</span> (i/<span class="hljs-number">2</span> &gt; <span class="hljs-number">0</span> &amp;&amp; a[i] &gt; a[i/<span class="hljs-number">2</span>]) &#123; <span class="hljs-comment">// 自下往上堆化</span><br>      swap(a, i, i/<span class="hljs-number">2</span>); <span class="hljs-comment">// swap()函数作用：交换下标为i和i/2的两个元素</span><br>      i = i/<span class="hljs-number">2</span>;<br>    &#125;<br>  &#125;<br> &#125;<br></code></pre></td></tr></table></figure></li><li><p>从上往下的堆化方法</p><p>删除堆顶元素之后，需要把第二大的元素放到堆顶，那第二大元素肯定会出现在左右子节点中。然后再迭代地删除第二大节点，以此类推，直到叶子节点被删除。</p><p>把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。这就是<strong>从上往下的堆化方法</strong>。</p><img src="/article/undefined/%E4%BB%8E%E4%B8%8A%E5%BE%80%E4%B8%8B%E7%9A%84%E5%A0%86%E5%8C%96%E6%96%B9%E6%B3%95.jpg" class title="从上往下的堆化方法"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">removeMax</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (count == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>; <span class="hljs-comment">// 堆中没有数据</span><br>  a[<span class="hljs-number">1</span>] = a[count];<br>  --count;<br>  heapify(a, count, <span class="hljs-number">1</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">heapify</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> i)</span> </span>&#123; <span class="hljs-comment">// 自上往下堆化</span><br>  <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>    <span class="hljs-keyword">int</span> maxPos = i;<br>    <span class="hljs-keyword">if</span> (i*<span class="hljs-number">2</span> &lt;= n &amp;&amp; a[i] &lt; a[i*<span class="hljs-number">2</span>]) maxPos = i*<span class="hljs-number">2</span>;<br>    <span class="hljs-keyword">if</span> (i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span> &lt;= n &amp;&amp; a[maxPos] &lt; a[i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span>]) maxPos = i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (maxPos == i) <span class="hljs-keyword">break</span>;<br>    swap(a, i, maxPos);<br>    i = maxPos;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ol><p>一个包含 n 个节点的完全二叉树，树的高度不会超过 log<sub>2</sub>n。堆化的过程是顺着节点所在路径比较交换的，所以堆化的时间复杂度跟树的高度成正比，也就是 O(logn)。插入数据和删除堆顶元素的主要逻辑就是堆化，所以，往堆中插入一个元素和删除堆顶元素的时间复杂度都是 O(logn)。</p><h3 id="如何基于堆实现排序？"><a href="#如何基于堆实现排序？" class="headerlink" title="如何基于堆实现排序？"></a>如何基于堆实现排序？</h3><ol><li><p>建堆</p><p>将数组原地建成一个堆。所谓“原地”就是，不借助另一个数组，就在原数组上操作。</p><ol><li><p>第一种是在堆中插入一个元素的思路。尽管数组中包含 n 个数据，假设，起初堆中只包含一个数据，就是下标为 1 的数据。然后，调用插入操作，将下标从 2 到 n 的数据依次插入到堆中。</p></li><li><p>第二种实现思路是从后往前处理数组，并且每个数据都是从上往下堆化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">buildHeap</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = n/<span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">1</span>; --i) &#123;<br>    heapify(a, n, i);<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">heapify</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> i)</span> </span>&#123;<br>  <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>    <span class="hljs-keyword">int</span> maxPos = i;<br>    <span class="hljs-keyword">if</span> (i*<span class="hljs-number">2</span> &lt;= n &amp;&amp; a[i] &lt; a[i*<span class="hljs-number">2</span>]) maxPos = i*<span class="hljs-number">2</span>;<br>    <span class="hljs-keyword">if</span> (i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span> &lt;= n &amp;&amp; a[maxPos] &lt; a[i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span>]) maxPos = i*<span class="hljs-number">2</span>+<span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (maxPos == i) <span class="hljs-keyword">break</span>;<br>    swap(a, i, maxPos);<br>    i = maxPos;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>对下标从 n/2 开始到 1 的数据进行堆化，下标是 n/2+1 到 n 的节点是叶子节点，我们不需要堆化</p><p><strong>对于完全二叉树来说，下标从 n/2+1 到 n 的节点都是叶子节点</strong></p></li></ol><blockquote><p>建堆操作的时间复杂度:</p><p>因为叶子节点不需要堆化，所以需要堆化的节点从倒数第二层开始。每个节点堆化的过程中，需要比较和交换的节点个数，跟这个节点的高度 k 成正比。</p><img src="/article/undefined/%E5%BB%BA%E5%A0%86%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.jpg" class title="建堆的时间复杂度"><img src="/article/undefined/%E6%AF%8F%E4%B8%AA%E9%9D%9E%E5%8F%B6%E5%AD%90%E8%8A%82%E7%82%B9%E7%9A%84%E9%AB%98%E5%BA%A6%E6%B1%82%E5%92%8C.jpg" class title="每个非叶子节点的高度求和"></blockquote><p>因为 h=log<sub>2</sub>n，代入公式 S，就能得到 S=O(n)，所以，建堆的时间复杂度就是 O(n)。</p></li><li><p>排序</p><p>建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。把它跟最后一个元素交换，那最大元素就放到了下标为 n 的位置。</p><p>然后再通过堆化的方法，将剩下的 n−1 个元素重新构建成堆。堆化完成之后，我们再取堆顶的元素，放到下标是 n−1 的位置，一直重复这个过程，直到最后堆中只剩下标为 1 的一个元素，排序工作就完成了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// n表示数据的个数，数组a中的数据从下标1到n的位置。</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">sort</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  buildHeap(a, n);<br>  <span class="hljs-keyword">int</span> k = n;<br>  <span class="hljs-keyword">while</span> (k &gt; <span class="hljs-number">1</span>) &#123;<br>    swap(a, <span class="hljs-number">1</span>, k);<br>    --k;<br>    heapify(a, k, <span class="hljs-number">1</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>堆排序的时间复杂度:</p><p>整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。</p></blockquote></li></ol><hr><blockquote><p><strong>问题：实际开发中，为什么快速排序要比堆排序性能好？</strong></p><ol><li><p>堆排序数据访问的方式没有快速排序友好</p></li><li><p>对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序</p><p>对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。</p><p>但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。</p></li></ol></blockquote><hr><h3 id="堆的应用"><a href="#堆的应用" class="headerlink" title="堆的应用"></a>堆的应用</h3><ol><li><p>优先级队列</p><p>在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。</p><p>往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。</p><blockquote><ol><li><p>合并有序小文件</p><p>假设有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。希望将这些 100 个小文件合并成一个有序的大文件。</p><blockquote><p>将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。</p></blockquote></li><li><p>高性能定时器</p><p>假设有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。</p><img src="/article/undefined/%E9%AB%98%E6%80%A7%E8%83%BD%E5%AE%9A%E6%97%B6%E5%99%A8%E5%AE%9E%E4%BE%8B.jpg" class title="高性能定时器实例"><p>但是，这样每过 1 秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。</p><blockquote><p>按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。</p><p>定时器拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。</p><p>这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。</p><p>定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。</p><p>当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。这样，定时器既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。</p></blockquote></li></ol></blockquote></li><li><p>利用堆求 Top K</p><blockquote><ol><li><p>针对静态数据集合：数据集合事先确定，不会再变</p><blockquote><p>维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。</p></blockquote><p>遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK) 的时间复杂度，所以最坏情况下，n 个元素都入堆一次，时间复杂度就是 O(nlogK)。</p></li><li><p>针对动态数据集合：数据集合事先并不确定，有数据动态地加入到集合中</p><p>一个数据集合中有两个操作，一个是添加数据，另一个询问当前的前 K 大数据。如果每次询问前 K 大数据，我们都基于当前的数据重新计算的话，那时间复杂度就是 O(nlogK)，n 表示当前的数据的大小。</p><blockquote><p>一直维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，我们都可以立刻返回。</p></blockquote></li></ol></blockquote></li><li><p>利用堆求中位数</p><blockquote><p>维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。</p><p>如果有 n 个数据，n 是偶数，我们从小到大排序，那前 n/2 个数据存储在大顶堆中，后 n/2 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 n/2+1 个数据，小顶堆中就存储 n/2 个数据。</p><p>如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；否则，我们就将这个新数据插入到小顶堆。</p><p>可能出现，两个堆中的数据个数不符合前面约定的情况:从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。</p><img src="/article/undefined/%E4%B8%A4%E4%B8%AA%E5%A0%86%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%AA%E6%95%B0%E4%B8%8D%E7%AC%A6%E5%90%88.jpg" class title="两个堆中的数据个数不符合"></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;树（Tree）&quot;&gt;&lt;a href=&quot;#树（Tree）&quot; class=&quot;headerlink&quot; title=&quot;树（Tree）&quot;&gt;&lt;/a&gt;树（Tree）&lt;/h2&gt;
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="树" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A0%91/"/>
    
    
      <category term="数据结构与算法,树" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>哈希算法</title>
    <link href="https://boyolo.github.io/article/60365.html"/>
    <id>https://boyolo.github.io/article/60365.html</id>
    <published>2022-05-16T02:36:16.000Z</published>
    <updated>2022-05-17T02:32:06.394Z</updated>
    
    <content type="html"><![CDATA[<h2 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h2><p><strong>将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值</strong></p><p>优秀的哈希算法需要满足的几点要求：</p><ol><li>从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；</li><li>对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；</li><li>散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；</li><li>哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。</li></ol><h3 id="哈希算法的应用"><a href="#哈希算法的应用" class="headerlink" title="哈希算法的应用"></a>哈希算法的应用</h3><ol><li><p>应用一：安全加密</p><p>最常用于加密的哈希算法是 MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）、 SHA（Secure Hash Algorithm，安全散列算法）、DES（Data Encryption Standard，数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。</p><p><strong>没有绝对安全的加密。越复杂、越难破解的加密算法，需要的计算时间也越长</strong></p></li><li><p>应用二：唯一标识</p></li><li><p>应用三：数据校验</p></li><li><p>应用四：散列函数</p><p>散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。</p><p>散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。</p></li><li><p>应用五：负载均衡</p><p>负载均衡算法有很多，比如轮询、随机、加权轮询等。</p><blockquote><p>如何实现一个会话粘滞（session sticky）的负载均衡算法？</p><p>需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。</p><p>最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。</p><p>弊端：</p><ol><li>如果客户端很多，映射表可能会很大，比较浪费内存空间；</li><li>客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；</li></ol><p><strong>可以通过哈希算法</strong>，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。</p></blockquote></li><li><p>应用六：数据分片</p><ol><li><blockquote><p>如何统计“搜索关键词”出现的次数？</p><p>假如我们有 <strong>1T</strong> 的日志文件，这里面记录了用户的搜索关键词，想要<strong>快速统计</strong>出每个关键词被搜索的次数，该怎么做呢？</p><p>可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。</p><p>具体思路：为了提高处理的速度，我们用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。</p><p>哈希值相同的搜索关键词就被分配到了同一个机器上,每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。</p></blockquote></li><li><blockquote><p>如何快速判断图片是否在有1 亿张图片的图库中？</p><p>可以对数据进行分片，然后采用多机处理。</p><p>具体思路：准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。</p><p>当要判断一个图片是否在图库中的时候，通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。</p></blockquote></li></ol></li><li><p>应用七：分布式存储</p><p>现在互联网面对的都是海量的数据、海量的用户。为了提高数据的读取、写入能力，一般都采用<strong>分布式的方式来存储数据</strong>，比如分布式缓存。</p><p>该如何决定将哪个数据放到哪个机器上呢？可以借用数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。</p><blockquote><p>如果数据增多，原来的 10 个机器已经无法承受了，就需要扩容，比如扩到 11 个机器，<strong>但这里并不是简单地加个机器就可以了</strong>。</p><p>所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。</p></blockquote><p><strong><a href="https://www.zsythink.net/archives/1182">一致性哈希算法</a></strong>：假设有 k 个机器，数据的哈希值的范围是[0, MAX]。将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;哈希算法&quot;&gt;&lt;a href=&quot;#哈希算法&quot; class=&quot;headerlink&quot; title=&quot;哈希算法&quot;&gt;&lt;/a&gt;哈希算法&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="哈希算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构与算法,哈希算法" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>散列表</title>
    <link href="https://boyolo.github.io/article/31130.html"/>
    <id>https://boyolo.github.io/article/31130.html</id>
    <published>2022-05-15T01:47:00.000Z</published>
    <updated>2022-05-16T02:41:55.970Z</updated>
    
    <content type="html"><![CDATA[<h2 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h2><p><strong>散列表(Hash Table)，也叫“哈希表”或者“Hash 表”</strong></p><p><strong>散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。</strong></p><p>散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><h3 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h3><p>散列函数，顾名思义，它是一个函数。我们可以把它定义成 <strong>hash(key)</strong>，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。</p><p><strong>散列函数设计的基本要求：</strong></p><ol><li>散列函数计算得到的散列值是一个非负整数；</li><li>如果 key1 = key2，那 hash(key1) == hash(key2)；</li><li>如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。</li></ol><h3 id="散列冲突"><a href="#散列冲突" class="headerlink" title="散列冲突"></a>散列冲突</h3><p><strong>再好的散列函数也无法避免散列冲突</strong></p><ol><li><p>开放寻址法</p><p>开放寻址法的<strong>核心思想</strong>是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。</p><ol><li><p>线性探测（Linear Probing）</p><p><strong>插入数据</strong><br>往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。</p><blockquote><img src="/article/undefined/%E7%BA%BF%E6%80%A7%E6%8E%A2%E6%B5%8B%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE.jpg" class title="线性探测插入数据"><p>散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。</p><p>于是顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。</p></blockquote><p><strong>查找数据</strong></p><p>在散列表中查找元素的过程有点儿类似插入过程。</p><p>通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。</p><blockquote><img src="/article/undefined/%E7%BA%BF%E6%80%A7%E6%8E%A2%E6%B5%8B%E6%9F%A5%E6%89%BE%E6%95%B0%E6%8D%AE.jpg" class title="线性探测查找数据"></blockquote><p><strong>删除数据</strong></p><p>删除数据时，不能单纯地把要删除的元素设置为空</p><blockquote><p>因为在查找的时候，一旦通过线性探测方法，找到一个空闲位置，就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。</p></blockquote><p>将删除的元素，<strong>特殊标记为 deleted</strong>。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。</p></li></ol></li></ol><pre><code>**线性探测问题：**当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。</code></pre><ol start="2"><li><p>二次探测（Quadratic probing）</p><p>所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+1<sup>2</sup>，hash(key)+2<sup>2</sup>……</p></li><li><p>双重散列（Double hashing）</p><p>所谓双重散列，意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。</p></li></ol><p>   不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会<strong>尽可能保证散列表中有一定比例的空闲槽位</strong>。我们用<strong>装载因子（load factor）</strong>来表示空位的多少。</p><p>   <strong>散列表的装载因子=填入表中的元素个数/散列表的长度</strong></p><p>   装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。</p><ol start="2"><li><p>链表法</p><p>在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。</p><blockquote><img src="/article/undefined/%E9%93%BE%E8%A1%A8%E6%B3%95.jpg" class title="链表法"></blockquote><p>当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。</p><p>当查找、删除一个元素时，同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。</p><p>时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。</p></li></ol><h3 id="如何选择冲突解决方法？"><a href="#如何选择冲突解决方法？" class="headerlink" title="如何选择冲突解决方法？"></a>如何选择冲突解决方法？</h3><ol><li><p>开放寻址法</p><p><strong>优点：</strong>开放寻址法不像链表法，需要拉很多链表。散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。</p><p><strong>缺点：</strong></p><ol><li>用开放寻址法解决冲突的散列表，删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。</li><li>而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。</li></ol><p><strong>当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。</strong></p></li><li><p>链表法</p><p><strong>优点：</strong></p><ol><li>首先，链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。</li><li>链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。</li></ol><p><strong>缺点：</strong></p><ol><li>链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。</li><li>因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。</li></ol><p><strong>基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。</strong></p></li></ol><h3 id="如何设计散列函数？"><a href="#如何设计散列函数？" class="headerlink" title="如何设计散列函数？"></a>如何设计散列函数？</h3><ol><li><p>散列函数的设计不能太复杂</p><p>过于复杂的散列函数，势必会消耗很多计算时间，也就间接地影响到散列表的性能</p></li><li><p>散列函数生成的值要尽可能随机并且均匀分布</p><p>这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况</p></li></ol><h3 id="装载因子过大了怎么办？"><a href="#装载因子过大了怎么办？" class="headerlink" title="装载因子过大了怎么办？"></a>装载因子过大了怎么办？</h3><p>装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会因此变得很慢。</p><p>针对散列表，当装载因子过大时，可以进行<strong>动态扩容</strong>，重新申请一个更大的散列表，将数据搬移到这个新散列表中。</p><p>针对散列表的扩容，因为散列表的大小变了，数据的存储位置也变了，所以需要通过散列函数重新计算每个数据的存储位置。</p><p>装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。</p><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><ol><li><p><strong>插入数据时间复杂度</strong></p><p><strong>最好时间复杂度：</strong>插入一个数据，最好情况下，不需要扩容，最好时间复杂度是 O(1)。</p><p><strong>最坏时间复杂度：</strong>最坏情况下，散列表装载因子过高，启动扩容，需要重新申请内存空间，重新计算哈希位置，并且搬移数据，所以时间复杂度是 O(n)。</p><p><strong>摊还时间复杂度：</strong>用摊还分析法，均摊情况下，时间复杂度接近最好情况，就是 O(1)。</p></li><li><p><strong>删除数据时间复杂度</strong></p><p>删除数据时间复杂度为O(1)。</p><p>对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果我们对空间消耗非常敏感，我们可以在装载因子小于某个值之后，启动动态缩容。</p></li></ol><h3 id="如何避免低效的扩容？"><a href="#如何避免低效的扩容？" class="headerlink" title="如何避免低效的扩容？"></a>如何避免低效的扩容？</h3><p>为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。</p><p>当有新数据要插入时，将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，都重复上面的过程。</p><p>经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。</p><p>对于查询操作，为了兼容了新、老散列表中的数据，先从新散列表中查找，如果没有找到，再去老的散列表中查找。</p><p>通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。<strong>这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。</strong></p><h3 id="工业级散列表举例分析（Java-HashMap）"><a href="#工业级散列表举例分析（Java-HashMap）" class="headerlink" title="工业级散列表举例分析（Java HashMap）"></a>工业级散列表举例分析（Java HashMap）</h3><ol><li><p>初始大小</p><p>HashMap 默认的初始大小是 16，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。</p></li><li><p>装载因子和动态扩容</p><p>最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。</p></li><li><p>散列冲突解决方法</p><p>HashMap 底层采用链表法来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。</p><p>在 JDK1.8 版本中，为了对 HashMap 做进一步优化，<strong>引入了红黑树</strong>。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。但不是所有的链表长度为8后都会转成树，还需要判断存放key值的数组桶长度是否小于64。如果小于则需要扩容，扩容后链表上的数据会被拆分散列的相应的桶节点上，也就把链表长度缩短了。</p><p>可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。</p></li><li><p>散列函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">hash</span><span class="hljs-params">(Object key)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> h = key.hashCode()；<br>  <span class="hljs-keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="hljs-number">16</span>)) &amp; (capicity -<span class="hljs-number">1</span>); <span class="hljs-comment">//capicity表示散列表的大小</span><br>&#125;<br></code></pre></td></tr></table></figure><p>hashCode() 返回的是 Java 对象的 hash code。比如 String 类型的对象的 hashCode() 就是下面这样：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">hashCode</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> var1 = <span class="hljs-keyword">this</span>.hash;<br>  <span class="hljs-keyword">if</span>(var1 == <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-keyword">this</span>.value.length &gt; <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-keyword">char</span>[] var2 = <span class="hljs-keyword">this</span>.value;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> var3 = <span class="hljs-number">0</span>; var3 &lt; <span class="hljs-keyword">this</span>.value.length; ++var3) &#123;<br>      var1 = <span class="hljs-number">31</span> * var1 + var2[var3];<br>    &#125;<br>    <span class="hljs-keyword">this</span>.hash = var1;<br>  &#125;<br>  <span class="hljs-keyword">return</span> var1;<br>&#125;<br></code></pre></td></tr></table></figure></li></ol><hr><blockquote><p><strong>问题：如何设计一个工业级的散列函数？</strong></p><blockquote><p>何为一个工业级的散列表？工业级的散列表应该具有哪些特性？</p><ol><li>支持快速地查询、插入、删除操作；</li><li>内存占用合理，不能浪费过多的内存空间；</li><li>性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。</li></ol></blockquote><p>设计思路：</p><ol><li>设计一个合适的散列函数；</li><li>定义装载因子阈值，并且设计动态扩容策略；</li><li>选择合适的散列冲突解决方法。</li></ol></blockquote><h3 id="LRU-缓存淘汰算法"><a href="#LRU-缓存淘汰算法" class="headerlink" title="LRU 缓存淘汰算法"></a>LRU 缓存淘汰算法</h3><p><strong>借助散列表，可以把 LRU 缓存淘汰算法的时间复杂度降低为 O(1)</strong></p><blockquote><p>如何通过链表实现 LRU 缓存淘汰算法?</p><p>需要维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，直接将链表头部的结点删除。</p><p>当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，我们就把它移动到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 O(n)。</p></blockquote><p>一个缓存（cache）系统主要包含下面这几个操作：</p><ol><li>往缓存中添加一个数据；</li><li>从缓存中删除一个数据；</li><li>在缓存中查找一个数据。</li></ol><blockquote><p>单纯地采用链表的话，时间复杂度只能是 O(n)</p><p>将散列表和链表两种数据结构组合使用，可以将这三个操作的时间复杂度都降低到 <strong>O(1)</strong></p></blockquote><img src="/article/undefined/%E6%95%A3%E5%88%97%E8%A1%A8%E9%93%BE%E8%A1%A8URL.jpg" class title="散列表链表URL"><p>使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 hnext</p><p>散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是双向链表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。</p><p><strong>如何查找一个数据：</strong>散列表中查找数据的时间复杂度接近 O(1)，所以通过散列表，可以很快地在缓存中找到一个数据。当找到数据之后，还需要将它移动到双向链表的尾部。</p><p><strong>如何删除一个数据：</strong>需要找到数据所在的结点，然后将结点删除。借助散列表，可以在 O(1) 时间复杂度里找到要删除的结点。因为链表是双向链表，双向链表可以通过前驱指针 O(1) 时间复杂度获取前驱结点，所以在双向链表中，删除结点只需要 O(1) 的时间复杂度。</p><p><strong>如何添加一个数据：</strong>需要先看这个数据是否已经在缓存中。如果已经在其中，需要将其移动到双向链表的尾部；如果不在其中，还要看缓存有没有满。如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；如果没有满，就直接将数据放到链表的尾部。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;散列表&quot;&gt;&lt;a href=&quot;#散列表&quot; class=&quot;headerlink&quot; title=&quot;散列表&quot;&gt;&lt;/a&gt;散列表&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;散列表(Hash Table)，也叫“哈希表”或者“Hash 表”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="散列表" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%A3%E5%88%97%E8%A1%A8/"/>
    
    
      <category term="数据结构与算法,散列表" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E6%95%A3%E5%88%97%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>跳表</title>
    <link href="https://boyolo.github.io/article/44093.html"/>
    <id>https://boyolo.github.io/article/44093.html</id>
    <published>2022-05-14T02:57:57.000Z</published>
    <updated>2022-05-14T05:22:12.137Z</updated>
    
    <content type="html"><![CDATA[<h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><blockquote><p>假设每两个节点建立一个索引</p></blockquote><p>对链表稍加改造，就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫做<strong>跳表（Skip list）</strong></p><p><strong>Redis 中的有序集合（Sorted Set）就是用跳表来实现的。</strong></p><h3 id="如何理解“跳表”？"><a href="#如何理解“跳表”？" class="headerlink" title="如何理解“跳表”？"></a>如何理解“跳表”？</h3><p>对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。</p><p><strong>初级优化</strong></p><p>像图中那样，对链表建立一级“索引”，每两个结点提取一个结点到上一级，我们把抽出来的那一级叫做<strong>索引或索引层</strong>。down 表示 down 指针，指向下一级结点。</p><img src="/article/undefined/%E9%93%BE%E8%A1%A8+%E7%B4%A2%E5%BC%95.jpg" class title="链表+索引"><p>加来一层索引之后，查找一个结点需要遍历的结点个数减少了，也就是说查找效率提高了</p><p><strong>再次优化</strong></p><p>跟前面建立第一级索引的方式相似，我们在第一级索引的基础之上，每两个结点就抽出一个结点到第二级索引。</p><img src="/article/undefined/%E9%93%BE%E8%A1%A8+%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95.jpg" class title="链表+二级索引"><p><strong>这种链表加多级索引的结构，就是跳表</strong></p><h3 id="用跳表查询到底有多快？"><a href="#用跳表查询到底有多快？" class="headerlink" title="用跳表查询到底有多快？"></a>用跳表查询到底有多快？</h3><p>如果链表里有 n 个结点，会有多少级索引呢？</p><p>每两个结点会抽出一个结点作为上一级索引的结点，那第一级索引的结点个数大约就是 n/2，第二级索引的结点个数大约就是 n/4，第三级索引的结点个数大约就是 n/8，依次类推，也就是说，<strong>第 k 级索引的结点个数是第 k-1 级索引的结点个数的 1/2，那第 k级索引结点的个数就是 n/(2<sup>k</sup>)。</strong></p><p>假设索引有 h 级，最高级的索引有 2 个结点。通过上面的公式，可以得到 n/(2<sup>h</sup>)=2，从而求得 h=log<sub>2</sub>n-1。如果包含原始链表这一层，整个跳表的高度就是 log<sub>2</sub>n。我们在跳表中查询某个数据的时候，如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。</p><p>m 的值是多少呢？</p><p>按照前面这种索引结构，我们每一级索引都最多只需要遍历 3 个结点，也就是说 m=3。</p><blockquote><p>假设我们要查找的数据是 x，在第 k 级索引中，我们遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以我们通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以，我们在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。</p><img src="/article/undefined/%E6%AF%8F%E5%B1%82%E6%9C%80%E5%A4%9A3%E8%8A%82%E7%82%B9%E9%81%8D%E5%8E%86.jpg" class title="每层最多3节点遍历"></blockquote><p><strong>在跳表中查询任意数据的时间复杂度就是 O(logn)</strong></p><h3 id="跳表是不是很浪费内存？"><a href="#跳表是不是很浪费内存？" class="headerlink" title="跳表是不是很浪费内存？"></a>跳表是不是很浪费内存？</h3><p>假设原始链表大小为 n，那第一级索引大约有 n/2 个结点，第二级索引大约有 n/4 个结点，以此类推，每上升一级就减少一半，直到剩下 2 个结点。如果我们把每层索引的结点数写出来，就是一个等比数列。</p><img src="/article/undefined/%E8%B7%B3%E8%A1%A8%E6%AF%8F%E5%B1%82%E8%8A%82%E7%82%B9%E6%95%B0.jpg" class title="跳表每层节点数"><p>这几级索引的结点总和就是 n/2+n/4+n/8…+8+4+2=n-2</p><p>所以，<strong>跳表的空间复杂度是 O(n)</strong></p><h3 id="高效的动态插入和删除"><a href="#高效的动态插入和删除" class="headerlink" title="高效的动态插入和删除"></a>高效的动态插入和删除</h3><p><strong>插入、删除操作的时间复杂度是 O(logn)</strong></p><img src="/article/undefined/%E6%8F%92%E5%85%A5%E6%93%8D%E4%BD%9C.jpg" class title="插入操作"><h3 id="跳表索引动态更新"><a href="#跳表索引动态更新" class="headerlink" title="跳表索引动态更新"></a>跳表索引动态更新</h3><p>当我们不停地往跳表中插入数据时，如果不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。</p><p><strong>跳表是通过随机函数来维护前面提到的“平衡性”</strong></p><blockquote><p>当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中。如何选择加入哪些索引层呢？</p></blockquote><p>通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，那我们就将这个结点添加到第一级到第 K 级这 K 级索引中。</p><img src="/article/undefined/%E9%9A%8F%E6%9C%BA%E5%87%BD%E6%95%B0%E6%9B%B4%E6%96%B0%E7%B4%A2%E5%BC%95.jpg" class title="随机函数更新索引"><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> skiplist;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 跳表的一种实现方法。</span><br><span class="hljs-comment"> * 跳表中存储的是正整数，并且存储的是不重复的。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SkipList</span> </span>&#123;<br><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">float</span> SKIPLIST_P = <span class="hljs-number">0.5f</span>;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> MAX_LEVEL = <span class="hljs-number">16</span>;<br><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> levelCount = <span class="hljs-number">1</span>;<br><br>  <span class="hljs-keyword">private</span> Node head = <span class="hljs-keyword">new</span> Node();  <span class="hljs-comment">// 带头链表</span><br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> Node <span class="hljs-title">find</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>    Node p = head;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = levelCount - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>      <span class="hljs-keyword">while</span> (p.forwards[i] != <span class="hljs-keyword">null</span> &amp;&amp; p.forwards[i].data &lt; value) &#123;<br>        p = p.forwards[i];<br>      &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (p.forwards[<span class="hljs-number">0</span>] != <span class="hljs-keyword">null</span> &amp;&amp; p.forwards[<span class="hljs-number">0</span>].data == value) &#123;<br>      <span class="hljs-keyword">return</span> p.forwards[<span class="hljs-number">0</span>];<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>    <span class="hljs-keyword">int</span> level = randomLevel();<br>    Node newNode = <span class="hljs-keyword">new</span> Node();<br>    newNode.data = value;<br>    newNode.maxLevel = level;<br>    Node update[] = <span class="hljs-keyword">new</span> Node[level];<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; level; ++i) &#123;<br>      update[i] = head;<br>    &#125;<br><br>    <span class="hljs-comment">// record every level largest value which smaller than insert value in update[]</span><br>    Node p = head;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = level - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>      <span class="hljs-keyword">while</span> (p.forwards[i] != <span class="hljs-keyword">null</span> &amp;&amp; p.forwards[i].data &lt; value) &#123;<br>        p = p.forwards[i];<br>      &#125;<br>      update[i] = p;<span class="hljs-comment">// use update save node in search path</span><br>    &#125;<br><br>    <span class="hljs-comment">// in search path node next node become new node forwords(next)</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; level; ++i) &#123;<br>      newNode.forwards[i] = update[i].forwards[i];<br>      update[i].forwards[i] = newNode;<br>    &#125;<br><br>    <span class="hljs-comment">// update node hight</span><br>    <span class="hljs-keyword">if</span> (levelCount &lt; level) levelCount = level;<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">delete</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>    Node[] update = <span class="hljs-keyword">new</span> Node[levelCount];<br>    Node p = head;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = levelCount - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>      <span class="hljs-keyword">while</span> (p.forwards[i] != <span class="hljs-keyword">null</span> &amp;&amp; p.forwards[i].data &lt; value) &#123;<br>        p = p.forwards[i];<br>      &#125;<br>      update[i] = p;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (p.forwards[<span class="hljs-number">0</span>] != <span class="hljs-keyword">null</span> &amp;&amp; p.forwards[<span class="hljs-number">0</span>].data == value) &#123;<br>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = levelCount - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>        <span class="hljs-keyword">if</span> (update[i].forwards[i] != <span class="hljs-keyword">null</span> &amp;&amp; update[i].forwards[i].data == value) &#123;<br>          update[i].forwards[i] = update[i].forwards[i].forwards[i];<br>        &#125;<br>      &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">while</span> (levelCount&gt;<span class="hljs-number">1</span>&amp;&amp;head.forwards[levelCount]==<span class="hljs-keyword">null</span>)&#123;<br>      levelCount--;<br>    &#125;<br><br>  &#125;<br><br>  <span class="hljs-comment">// 理论来讲，一级索引中元素个数应该占原始数据的 50%，二级索引中元素个数占 25%，三级索引12.5% ，一直到最顶层。</span><br>  <span class="hljs-comment">// 因为这里每一层的晋升概率是 50%。对于每一个新插入的节点，都需要调用 randomLevel 生成一个合理的层数。</span><br>  <span class="hljs-comment">// 该 randomLevel 方法会随机生成 1~MAX_LEVEL 之间的数，且 ：</span><br>  <span class="hljs-comment">//        50%的概率返回 1</span><br>  <span class="hljs-comment">//        25%的概率返回 2</span><br>  <span class="hljs-comment">//      12.5%的概率返回 3 ...</span><br>  <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> <span class="hljs-title">randomLevel</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">int</span> level = <span class="hljs-number">1</span>;<br><br>    <span class="hljs-keyword">while</span> (Math.random() &lt; SKIPLIST_P &amp;&amp; level &lt; MAX_LEVEL)<br>      level += <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">return</span> level;<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printAll</span><span class="hljs-params">()</span> </span>&#123;<br>    Node p = head;<br>    <span class="hljs-keyword">while</span> (p.forwards[<span class="hljs-number">0</span>] != <span class="hljs-keyword">null</span>) &#123;<br>      System.out.print(p.forwards[<span class="hljs-number">0</span>] + <span class="hljs-string">&quot; &quot;</span>);<br>      p = p.forwards[<span class="hljs-number">0</span>];<br>    &#125;<br>    System.out.println();<br>  &#125;<br><br>  <span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> data = -<span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">private</span> Node forwards[] = <span class="hljs-keyword">new</span> Node[MAX_LEVEL];<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> maxLevel = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123;<br>      StringBuilder builder = <span class="hljs-keyword">new</span> StringBuilder();<br>      builder.append(<span class="hljs-string">&quot;&#123; data: &quot;</span>);<br>      builder.append(data);<br>      builder.append(<span class="hljs-string">&quot;; levels: &quot;</span>);<br>      builder.append(maxLevel);<br>      builder.append(<span class="hljs-string">&quot; &#125;&quot;</span>);<br><br>      <span class="hljs-keyword">return</span> builder.toString();<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;跳表&quot;&gt;&lt;a href=&quot;#跳表&quot; class=&quot;headerlink&quot; title=&quot;跳表&quot;&gt;&lt;/a&gt;跳表&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;假设每两个节点建立一个索引&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对链表稍加改造，就可以支持类似“二分”的查找
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="跳表" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E8%B7%B3%E8%A1%A8/"/>
    
    
      <category term="数据结构与算法,跳表" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E8%B7%B3%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="https://boyolo.github.io/article/42877.html"/>
    <id>https://boyolo.github.io/article/42877.html</id>
    <published>2022-05-13T02:46:38.000Z</published>
    <updated>2022-05-13T05:39:42.724Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><p>二分查找（Binary Search）算法，也叫折半查找算法</p><p>二分查找针对的是一个<strong>有序的数据集合</strong>，查找思想有点<strong>类似分治思想</strong>。<strong>每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。</strong></p><h3 id="时间复杂度：O-logn"><a href="#时间复杂度：O-logn" class="headerlink" title="时间复杂度：O(logn)"></a>时间复杂度：O(logn)</h3><blockquote><p>假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。</p><img src="/article/undefined/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%8C%BA%E9%97%B4%E5%8F%98%E5%8C%96.jpg" class title="二分查找区间变化"><p>其中 n/2k=1 时，k 的值就是总共缩小的次数。</p><p>而每一次缩小操作只涉及两个数据的大小比较，所以，经过了 k 次区间缩小操作，时间复杂度就是 O(k)。</p><p>通过 n/2<sup>k</sup>=1，我们可以求得 k=log<sub>2</sub>n，所以<strong>时间复杂度就是 O(logn)</strong>。</p></blockquote><p>指数时间复杂度的算法在大规模数据面前是无效的</p><h3 id="二分查找的递归与非递归实现"><a href="#二分查找的递归与非递归实现" class="headerlink" title="二分查找的递归与非递归实现"></a>二分查找的递归与非递归实现</h3><p><strong>非递归实现</strong></p><blockquote><p>有序数组中不存在重复元素，用二分查找值等于给定值的数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br><br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-comment">//int mid = (low + high) / 2;</span><br>    <span class="hljs-keyword">int</span> mid = low+(high-low)/<span class="hljs-number">2</span>;<br>    <span class="hljs-keyword">if</span> (a[mid] == value) &#123;<br>      <span class="hljs-keyword">return</span> mid;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (a[mid] &lt; value) &#123;<br>      low = mid + <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      high = mid - <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p><strong>注意：</strong></p><ol><li><p>注意是 low&lt;=high，而不是 low</p></li><li><p><strong>mid=(low+high)/2 这种写法是有问题的</strong>。</p><p>因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。</p><p><strong>改进的方法是将 mid 的计算方式写成 low+(high-low)/2。</strong>更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 <strong>low+((high-low)&gt;&gt;1)</strong>。因为相比除法运算来说，计算机处理位运算要快得多。</p></li><li><p>low 和 high 的更新</p><p>low=mid+1，high=mid-1</p></li></ol><p><strong>递归实现</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 二分查找的递归实现</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> val)</span> </span>&#123;<br>  <span class="hljs-keyword">return</span> bsearchInternally(a, <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span>, val);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearchInternally</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> low, <span class="hljs-keyword">int</span> high, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (low &gt; high) <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br><br>  <span class="hljs-keyword">int</span> mid =  low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>  <span class="hljs-keyword">if</span> (a[mid] == value) &#123;<br>    <span class="hljs-keyword">return</span> mid;<br>  &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (a[mid] &lt; value) &#123;<br>    <span class="hljs-keyword">return</span> bsearchInternally(a, mid+<span class="hljs-number">1</span>, high, value);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">return</span> bsearchInternally(a, low, mid-<span class="hljs-number">1</span>, value);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="二分查找应用场景的局限性"><a href="#二分查找应用场景的局限性" class="headerlink" title="二分查找应用场景的局限性"></a>二分查找应用场景的局限性</h3><ol><li><p>首先，二分查找依赖的是顺序表结构，简单点说就是数组。</p><p>二分查找只能用在数据是通过顺序表来存储的数据结构上。如果你的数据是通过其他数据结构存储的，则无法应用二分查找。</p></li><li><p>其次，二分查找针对的是有序数据。</p><p>二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中</p></li><li><p>再次，数据量太小不适合二分查找。</p><p><strong>例外：</strong>如果数据之间的比较操作非常耗时，不管数据量大小，推荐使用二分查找。比如，数组中存储的都是长度超过 300 的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能地减少比较次数，而比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。</p></li><li><p>最后，数据量太大也不适合二分查找。</p></li></ol><h3 id="二分查找变形问题"><a href="#二分查找变形问题" class="headerlink" title="二分查找变形问题"></a>二分查找变形问题</h3><h4 id="查找第一个值等于给定值的元素"><a href="#查找第一个值等于给定值的元素" class="headerlink" title="查找第一个值等于给定值的元素"></a>查找第一个值等于给定值的元素</h4><p><strong>问题：有序数据集合中存在重复的数据，希望找到第一个值等于给定值的数据</strong></p><blockquote><p>下面这样一个有序数组，其中，a[5]，a[6]，a[7]的值都等于 8，是重复的数据。希望查找第一个等于 8 的数据，也就是下标是 5 的元素。</p><img src="/article/undefined/%E5%8F%98%E4%BD%93%E4%B8%80.jpg" class title="变体一"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//写法一：</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-keyword">int</span> mid = low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (a[mid] &gt;= value) &#123;<br>      high = mid - <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      low = mid + <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (low &lt; n &amp;&amp; a[low]==value) <span class="hljs-keyword">return</span> low;<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br><span class="hljs-comment">//写法二：</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-keyword">int</span> mid =  low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (a[mid] &gt; value) &#123;<br>      high = mid - <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (a[mid] &lt; value) &#123;<br>      low = mid + <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-keyword">if</span> ((mid == <span class="hljs-number">0</span>) || (a[mid - <span class="hljs-number">1</span>] != value)) <span class="hljs-keyword">return</span> mid;<br>      <span class="hljs-keyword">else</span> high = mid - <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><h3 id="查找最后一个值等于给定值的元素"><a href="#查找最后一个值等于给定值的元素" class="headerlink" title="查找最后一个值等于给定值的元素"></a>查找最后一个值等于给定值的元素</h3><p><strong>问题：有序数据集合中存在重复的数据，希望查找最后一个值等于给定值的元素</strong></p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-keyword">int</span> mid =  low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (a[mid] &gt; value) &#123;<br>      high = mid - <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (a[mid] &lt; value) &#123;<br>      low = mid + <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-keyword">if</span> ((mid == n - <span class="hljs-number">1</span>) || (a[mid + <span class="hljs-number">1</span>] != value)) <span class="hljs-keyword">return</span> mid;<br>      <span class="hljs-keyword">else</span> low = mid + <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><h3 id="查找第一个大于等于给定值的元素"><a href="#查找第一个大于等于给定值的元素" class="headerlink" title="查找第一个大于等于给定值的元素"></a>查找第一个大于等于给定值的元素</h3><p><strong>问题：在有序数组中，查找第一个大于等于给定值的元素</strong></p><blockquote><p>数组中存储的这样一个序列：3，4，6，7，10。如果查找第一个大于等于 5 的元素，那就是 6。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-keyword">int</span> mid =  low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (a[mid] &gt;= value) &#123;<br>      <span class="hljs-keyword">if</span> ((mid == <span class="hljs-number">0</span>) || (a[mid - <span class="hljs-number">1</span>] &lt; value)) <span class="hljs-keyword">return</span> mid;<br>      <span class="hljs-keyword">else</span> high = mid - <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      low = mid + <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><h3 id="查找最后一个小于等于给定值的元素"><a href="#查找最后一个小于等于给定值的元素" class="headerlink" title="查找最后一个小于等于给定值的元素"></a>查找最后一个小于等于给定值的元素</h3><p><strong>问题：查找最后一个小于等于给定值的元素</strong></p><blockquote><p>数组中存储了这样一组数据：3，5，6，8，9，10。最后一个小于等于 7 的元素就是 6</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">bsearch7</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] a, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> high = n - <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>    <span class="hljs-keyword">int</span> mid =  low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (a[mid] &gt; value) &#123;<br>      high = mid - <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-keyword">if</span> ((mid == n - <span class="hljs-number">1</span>) || (a[mid + <span class="hljs-number">1</span>] &gt; value)) <span class="hljs-keyword">return</span> mid;<br>      <span class="hljs-keyword">else</span> low = mid + <span class="hljs-number">1</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;二分查找&quot;&gt;&lt;a href=&quot;#二分查找&quot; class=&quot;headerlink&quot; title=&quot;二分查找&quot;&gt;&lt;/a&gt;二分查找&lt;/h2&gt;&lt;p&gt;二分查找（Binary Search）算法，也叫折半查找算法&lt;/p&gt;
&lt;p&gt;二分查找针对的是一个&lt;strong&gt;有序的数据集
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="二分查找" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    
    
      <category term="数据结构与算法,二分查找" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    
  </entry>
  
  <entry>
    <title>Mysql45讲-实践（四）</title>
    <link href="https://boyolo.github.io/article/17540.html"/>
    <id>https://boyolo.github.io/article/17540.html</id>
    <published>2022-05-09T02:34:05.000Z</published>
    <updated>2022-05-14T02:56:25.847Z</updated>
    
    <content type="html"><![CDATA[<h2 id="自增主键为什么不是连续的？"><a href="#自增主键为什么不是连续的？" class="headerlink" title="自增主键为什么不是连续的？"></a>自增主键为什么不是连续的？</h2><p>自增主键，由于自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。</p><p><strong>自增主键不能保证连续递增</strong></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `id` int(11) NOT NULL AUTO_INCREMENT,<br>  `c` int(11) DEFAULT NULL,<br>  `d` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  UNIQUE KEY `c` (`c`)<br>) ENGINE=InnoDB;<br></code></pre></td></tr></table></figure></blockquote><h3 id="自增值保存在哪儿？"><a href="#自增值保存在哪儿？" class="headerlink" title="自增值保存在哪儿？"></a>自增值保存在哪儿？</h3><blockquote><p>在这个空表 t 里面执行 insert into t values(null, 1, 1); 插入一行数据，再执行 show create table 命令，就可以看到如下图所示的结果：</p><p><img src="/article/自动生成的 AUTO_INCREMENT 值.png"><span class="image-caption">自动生成的 AUTO_INCREMENT 值</span></p><p>表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。</p><p>其实，这个输出结果容易引起这样的误解：自增值是保存在表结构定义里的。</p></blockquote><p><strong>表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。</strong></p><p>不同的引擎对于自增值的保存策略不同：</p><ol><li><p>MyISAM 引擎的自增值保存在数据文件中。</p></li><li><p>InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是：</p><ol><li><p>在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。</p><p>﻿举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。</p><p>   ﻿也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。</p></li><li><p>在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。</p></li></ol></li></ol><h3 id="自增值修改机制"><a href="#自增值修改机制" class="headerlink" title="自增值修改机制"></a>自增值修改机制</h3><p>在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：</p><ol><li><p>如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；</p></li><li><p>如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。</p><p>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。</p><p>假设，某次要插入的值是 X，当前的自增值是 Y。</p><ol><li>如果 X&lt;Y，那么这个表的自增值不变；</li><li>如果 X≥Y，就需要把当前自增值修改为新的自增值。</li></ol></li></ol><p><strong>新的自增值生成算法</strong>是：从 <code>auto_increment_offset</code> 开始，以 <code>auto_increment_increment</code> 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。</p><p>其中，<code>auto_increment_offset</code> 和 <code>auto_increment_increment</code> 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。</p><h3 id="自增值的修改时机"><a href="#自增值的修改时机" class="headerlink" title="自增值的修改时机"></a>自增值的修改时机</h3><p><strong>导致自增主键 id 不连续的原因</strong></p><ol><li>唯一键冲突</li><li>事务回滚</li><li>批量插入数据</li></ol><p><strong>自增值为什么不能回退：为了提升性能</strong></p><blockquote><p>假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。</p><ol><li>假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。</li><li>事务 B 正确提交了，但事务 A 出现了唯一键冲突。</li><li>如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。</li><li>接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。</li></ol><p>解决这个主键冲突，有两种方法：</p><ol><li>每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。</li><li>把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。</li></ol><p>这两个方法都会导致性能问题</p></blockquote><h3 id="自增锁的优化"><a href="#自增锁的优化" class="headerlink" title="自增锁的优化"></a>自增锁的优化</h3><p>自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。</p><ol><li><p>MySQL 5.0 版本</p><p>自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。</p></li><li><p>MySQL 5.1.22 版本</p><p>新增参数 <code>innodb_autoinc_lock_mode</code>，默认值是 1</p><ol><li>这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；</li><li>这个参数的值被设置为 1 时：<ol><li>普通 <code>insert</code> 语句，自增锁在申请之后就马上释放；</li><li>类似 <code>insert … select</code> 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li></ol></li><li>这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。</li></ol></li></ol><p>在生产上，尤其是有 <code>insert … select</code> 这种批量插入数据(<code>insert … select</code>、<code>replace … select</code> 和 <code>load data</code> 语句)的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：<code>innodb_autoinc_lock_mode=2</code> ，并且 <code>binlog_format=row</code>. 这样做，既能提升并发性，又不会出现数据一致性问题。</p><p>对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：</p><ol><li>语句执行过程中，第一次申请自增 id，会分配 1 个；</li><li>1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；</li><li>2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；</li><li>依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。</li></ol><hr><blockquote><p><strong>问题：在 binlog_format=statement 时，语句 A 先获取 id=1，然后语句 B 获取 id=2；接着语句 B 提交，写 binlog，然后语句 A 再写 binlog。这时候，如果 binlog 重放，是不是会发生语句 B 的 id 为 1，而语句 A 的 id 为 2 的不一致情况呢？</strong></p><p>自增 id 的生成顺序，和 binlog 的写入顺序可能是不同的</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table t(id int auto_increment primary key);<br>insert into t values(null);<br></code></pre></td></tr></table></figure><p><img src="/article/insert 语句的 binlog.jpg"><span class="image-caption">insert 语句的 binlog</span></p><p>可以看到，在 insert 语句之前，还有一句 SET INSERT_ID=1。这条命令的意思是，这个线程里下一次需要用到自增值的时候，不论当前表的自增值是多少，固定用 1 这个值。</p><p>这个 SET INSERT_ID 语句是固定跟在 insert 语句之前的,主库上语句 A 的 id 是 1，语句 B 的 id 是 2，但是写入 binlog 的顺序先 B 后 A，那么 binlog 就变成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">SET INSERT_ID=2;<br>语句B；<br>SET INSERT_ID=1;<br>语句A；<br></code></pre></td></tr></table></figure><p>在备库上语句 B 用到的 INSERT_ID 依然是 2，跟主库相同</p></blockquote><p><strong>因此，即使两个 INSERT 语句在主备库的执行顺序不同，自增主键字段的值也不会不一致。</strong></p></blockquote><hr><h2 id="insert语句的锁为什么这么多？"><a href="#insert语句的锁为什么这么多？" class="headerlink" title="insert语句的锁为什么这么多？"></a>insert语句的锁为什么这么多？</h2><h3 id="insert-…-select-语句"><a href="#insert-…-select-语句" class="headerlink" title="insert … select 语句"></a>insert … select 语句</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `id` int(11) NOT NULL AUTO_INCREMENT,<br>  `c` int(11) DEFAULT NULL,<br>  `d` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  UNIQUE KEY `c` (`c`)<br>) ENGINE=InnoDB;<br><br>insert into t values(null, 1,1);<br>insert into t values(null, 2,2);<br>insert into t values(null, 3,3);<br>insert into t values(null, 4,4);<br><br>create table t2 like t<br></code></pre></td></tr></table></figure><p>在可重复读隔离级别下，binlog_format=statement 时执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t2(c,d) select c,d from t;<br></code></pre></td></tr></table></figure><p>需要对表 t 的所有行和间隙加锁。</p><p>执行序列：</p><p><img src="/article/并发 insert 场景.png"><span class="image-caption">并发 insert 场景</span></p><p>实际的执行效果是，如果 session B 先执行，由于这个语句对表 t 主键索引加了 (-∞,1]这个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。</p><p>但如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t values(-1,-1,-1);<br>insert into t2(c,d) select c,d from t;<br></code></pre></td></tr></table></figure><p>这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。</p></blockquote><p>执行 <code>insert … select</code> 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。</p><h3 id="insert-循环写入"><a href="#insert-循环写入" class="headerlink" title="insert 循环写入"></a>insert 循环写入</h3><blockquote><p>要往表 t2 中插入一行数据，这一行的 c 值是表 t 中 c 值的最大值加 1。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t2(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);<br></code></pre></td></tr></table></figure><p>这个语句的加锁范围，就是表 t 索引 c 上的 (3,4]和 (4,supremum]这两个 next-key lock，以及主键索引上 id=4 这一行。</p><p>执行流程:从表 t 中按照索引 c 倒序，扫描第一行，拿到结果写入到表 t2 中。</p><p>整条语句的扫描行数是 1。</p></blockquote><blockquote><p>把这样的一行数据插入到表 t 中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);<br></code></pre></td></tr></table></figure><p>慢查询日志:</p><p><img src="/article/慢查询日志 -- 将数据插入表 t.png"><span class="image-caption">慢查询日志 -- 将数据插入表 t</span></p><p>Rows_examined 的值是 5</p><p>explain 结果:</p><p><img src="/article/explain 结果.png"><span class="image-caption">explain 结果.png</span></p><p>从 Extra 字段可以看到“Using temporary”字样，表示这个语句用到了临时表。执行过程中，需要把表 t 的内容读出来，写入临时表。</p><p>在执行这个语句前后查看 Innodb_rows_read 的结果:</p><p><img src="/article/查看 Innodb_rows_read 变化.png"><span class="image-caption">查看 Innodb_rows_read 变化</span></p><p>这个语句执行前后，Innodb_rows_read 的值增加了 4。因为默认临时表是使用 Memory 引擎的，所以这 4 行查的都是表 t，也就是说对表 t 做了全表扫描。</p><p>执行过程:</p><ol><li>创建临时表，表里有两个字段 c 和 d。</li><li>按照索引 c 扫描表 t，依次取 c=4、3、2、1，然后回表，读到 c 和 d 的值写入临时表。这时，Rows_examined=4。</li><li>由于语义里面有 limit 1，所以只取了临时表的第一行，再插入到表 t 中。这时，Rows_examined 的值加 1，变成了 5。</li></ol><p>这个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。</p><p><strong>这个语句的执行为什么需要临时表?</strong></p><p>原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。</p></blockquote><h3 id="insert-唯一键冲突"><a href="#insert-唯一键冲突" class="headerlink" title="insert 唯一键冲突"></a>insert 唯一键冲突</h3><blockquote><img src="/article/undefined/%E5%94%AF%E4%B8%80%E9%94%AE%E5%86%B2%E7%AA%81%E5%8A%A0%E9%94%81.png" class title="唯一键冲突加锁"><p>在可重复读（repeatable read）隔离级别下执行</p><p>session B 要执行的 insert 语句进入了锁等待状态。</p><p>session A 执行的 insert 语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。</p><p>这时候，session A 持有索引 c 上的 (5,10]共享 next-key lock（读锁）。</p></blockquote><h3 id="insert-into-…-on-duplicate-key-update"><a href="#insert-into-…-on-duplicate-key-update" class="headerlink" title="insert into … on duplicate key update"></a>insert into … on duplicate key update</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t values(11,10,10) on duplicate key update d=100; <br></code></pre></td></tr></table></figure><p>会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）</p></blockquote><p><code>insert into … on duplicate key update</code> 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。</p><p>注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。</p><blockquote><p>现在表 t 里面已经有了 (1,1,1) 和 (2,2,2) 这两行</p><img src="/article/undefined/%E4%B8%A4%E4%B8%AA%E5%94%AF%E4%B8%80%E9%94%AE%E5%90%8C%E6%97%B6%E5%86%B2%E7%AA%81.png" class title="两个唯一键同时冲突"><p>主键 id 是先判断的，MySQL 认为这个语句跟 id=2 这一行冲突，所以修改的是 id=2 的行。</p><p>需要注意的是，执行这条语句的 affected rows 返回的是 2，很容易造成误解。实际上，真正更新的只有一行，只是在代码实现上，insert 和 update 都认为自己成功了，update 计数加了 1， insert 计数也加了 1。</p></blockquote><h2 id="怎么最快地复制一张表？"><a href="#怎么最快地复制一张表？" class="headerlink" title="怎么最快地复制一张表？"></a>怎么最快地复制一张表？</h2><ol><li>如果可以控制对源表的扫描行数和加锁范围很小的话，简单地使用 <code>insert … select</code>语句即可实现。</li><li>为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。</li></ol><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create database db1;<br>use db1;<br><br>create table t(id int primary key, a int, b int, index(a))engine=innodb;<br>delimiter ;;<br>  create procedure idata()<br>  begin<br>    declare i int;<br>    set i=1;<br>    while(i&lt;=1000)do<br>      insert into t values(i,i,i);<br>      set i=i+1;<br>    end while;<br>  end;;<br>delimiter ;<br>call idata();<br><br>create database db2;<br>create table db2.t like db1.t<br></code></pre></td></tr></table></figure><p>先创建一个表 db1.t，并插入 1000 行数据，同时创建一个相同结构的表 db2.t</p></blockquote><h3 id="mysqldump-方法"><a href="#mysqldump-方法" class="headerlink" title="mysqldump 方法"></a>mysqldump 方法</h3><p>使用 mysqldump 命令将数据导出成一组 INSERT 语句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysqldump -h<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.982ex" height="2.343ex" style="vertical-align: -0.505ex;" viewbox="0 -791.3 3867.4 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">host -P</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/><path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/><path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/><path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-68" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-6F" x="576" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="1062" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="1531" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="2115" y="0"/> <use xlink:href="#E1-MJMATHI-50" x="3115" y="0"/></g></svg>port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where=&quot;a&gt;900&quot; --result-file=/client_tmp/t.sql<br></code></pre></td></tr></table></figure><ol><li><code>–single-transaction</code> 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code>(立即开启一个事务，否则事务是再执行到第一个sql语句的时候创建的) 的方法；</li><li><code>–add-locks</code> 设置为 0，表示在输出的文件结果里，不增加” <code>LOCK TABLES t WRITE;</code>“ ；</li><li><code>–no-create-info</code> 的意思是，不需要导出表结构；</li><li><code>–set-gtid-purged=off</code> 表示的是，不输出跟 GTID 相关的信息；</li><li><code>–result-file</code> 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。</li></ol><blockquote><p>通过这条 mysqldump 命令生成的 t.sql 文件中就包含了如图所示的 INSERT 语句</p><p><img src="/article/mysqldump 输出文件的部分结果.png"><span class="image-caption">mysqldump 输出文件的部分结果</span></p><p>一条 INSERT 语句里面会包含多个 value 对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。</p><p>如果希望生成的文件中一条 INSERT 语句只插入一行数据的话，可以在执行 mysqldump 命令时，加上参数<code>–skip-extended-insert</code>。</p></blockquote><p>然后，可以通过下面这条命令，将这些 INSERT 语句放到 db2 库里去执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source /client_tmp/t.sql&quot;<br></code></pre></td></tr></table></figure><p>source 并不是一条 SQL 语句，而是一个客户端命令</p><p>mysql 客户端执行这个命令的流程是这样的：</p><ol><li>打开文件，默认以分号为结尾读取一条条的 SQL 语句；</li><li>将 SQL 语句发送到服务端执行。</li></ol><p>也就是说，服务端执行的并不是这个“<code>source t.sql</code>“语句，而是 <code>INSERT</code> 语句。所以，不论是在慢查询日志（slow log），还是在 binlog，记录的都是这些要被真正执行的 INSERT 语句。</p><h3 id="导出-CSV-文件"><a href="#导出-CSV-文件" class="headerlink" title="导出 CSV 文件"></a>导出 CSV 文件</h3><p>直接将结果导出成.csv 文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from db1.t where a&gt;900 into outfile &#x27;/server_tmp/t.csv&#x27;;<br></code></pre></td></tr></table></figure><p>需要注意如下几点:</p><ol><li>这条语句会将结果保存在服务端。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。</li><li><code>into outfile</code> 指定了文件的生成位置（/server_tmp/），这个位置必须受参数 <code>secure_file_priv</code> 的限制。参数 <code>secure_file_priv</code> 的可选值和作用分别是：<ol><li>如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；</li><li>如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；</li><li>如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 <code>select … into outfile</code> 操作。</li></ol></li><li>这条命令不会帮你覆盖文件，因此你需要确保 /server_tmp/t.csv 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。</li><li>这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。</li></ol><p>得到.csv 导出文件后，就可以用下面的 load data 命令将数据导入到目标表 db2.t 中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">load data infile &#x27;/server_tmp/t.csv&#x27; into table db2.t;<br></code></pre></td></tr></table></figure><p>这条语句的执行流程如下所示:</p><ol><li>打开文件 /server_tmp/t.csv，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；</li><li>启动事务</li><li>判断每一行的字段数与表 db2.t 是否相同：<ol><li>若不相同，则直接报错，事务回滚；</li><li>若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。</li></ol></li><li>重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务。</li></ol><blockquote><p><strong>问题：如果 binlog_format=statement，这个 load 语句记录到 binlog 里以后，怎么在备库重放呢？</strong></p><p>由于 /server_tmp/t.csv 文件只保存在主库所在的主机上，如果只是把这条语句原文写到 binlog 中，在备库执行的时候，备库的本地机器上没有这个文件，就会导致主备同步停止。</p><p>所以，这条语句执行的完整流程，其实是下面这样的：</p><ol><li>主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到 binlog 文件中。</li><li>往 binlog 文件中写入语句 load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE `db2`.`t`。</li><li>把这个 binlog 日志传到备库。</li><li>备库的 apply 线程在执行这个事务日志时：<ol><li>先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 /tmp/SQL_LOAD_MB-1-0 中；</li><li>再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据。</li></ol></li></ol><p><img src="/article/load data 的同步流程.jpg"><span class="image-caption">load data 的同步流程</span></p><p>注意，这里备库执行的 load data 语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件 /tmp/SQL_LOAD_MB-1-0 的内容，加载到目标表 db2.t 中”。</p></blockquote><p>load data 命令有两种用法：</p><ol><li>不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下；</li><li>加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程</li></ol><p><code>select …into outfile</code> 方法<strong>不会生成表结构文件</strong>, 所以我们导数据时还需要单独的命令得到表结构定义。</p><p>mysqldump 提供了一个<code>–tab</code> 参数，可以同时导出表结构定义文件和 csv 数据文件。这条命令的使用方法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysqldump -h<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.982ex" height="2.343ex" style="vertical-align: -0.505ex;" viewbox="0 -791.3 3867.4 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">host -P</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/><path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/><path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/><path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-68" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-6F" x="576" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="1062" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="1531" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="2115" y="0"/> <use xlink:href="#E1-MJMATHI-50" x="3115" y="0"/></g></svg>port -u<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="105.481ex" height="2.509ex" style="vertical-align: -0.671ex;" viewbox="0 -791.3 45415.1 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a&gt;900" --tab=</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/><path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/><path stroke-width="1" id="E1-MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"/><path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"/><path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/><path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/><path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"/><path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/><path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"/><path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/><path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"/><path stroke-width="1" id="E1-MJMATHI-4F" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/><path stroke-width="1" id="E1-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"/><path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"/><path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/><path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"/><path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/><path stroke-width="1" id="E1-MJMAIN-22" d="M34 634Q34 659 50 676T93 694Q121 694 144 668T168 579Q168 525 146 476T101 403T73 379Q69 379 60 388T50 401Q50 404 62 417T88 448T116 500T131 572Q131 584 130 584T125 581T112 576T94 573Q69 573 52 590T34 634ZM238 634Q238 659 254 676T297 694Q325 694 348 668T372 579Q372 525 350 476T305 403T277 379Q273 379 264 388T254 401Q254 404 266 417T292 448T320 500T335 572Q335 584 334 584T329 581T316 576T298 573Q273 573 256 590T238 634Z"/><path stroke-width="1" id="E1-MJMAIN-3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"/><path stroke-width="1" id="E1-MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"/><path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-75" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="572" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="1042" y="0"/> <use xlink:href="#E1-MJMATHI-72" x="1508" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="2182" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="3182" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="4183" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="5184" y="0"/> <use xlink:href="#E1-MJMATHI-69" x="5653" y="0"/> <use xlink:href="#E1-MJMATHI-6E" x="5999" y="0"/> <use xlink:href="#E1-MJMATHI-67" x="6599" y="0"/> <use xlink:href="#E1-MJMATHI-6C" x="7080" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="7378" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="8067" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="9068" y="0"/> <use xlink:href="#E1-MJMATHI-72" x="9429" y="0"/> <use xlink:href="#E1-MJMATHI-61" x="9881" y="0"/> <use xlink:href="#E1-MJMATHI-6E" x="10410" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="11011" y="0"/> <use xlink:href="#E1-MJMATHI-61" x="11480" y="0"/> <use xlink:href="#E1-MJMATHI-63" x="12010" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="12443" y="0"/> <use xlink:href="#E1-MJMATHI-69" x="12805" y="0"/> <use xlink:href="#E1-MJMATHI-6F" x="13150" y="0"/> <use xlink:href="#E1-MJMATHI-6E" x="13636" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="14459" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="15459" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="16238" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="16707" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="17174" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="17758" y="0"/> <use xlink:href="#E1-MJMATHI-67" x="18758" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="19239" y="0"/> <use xlink:href="#E1-MJMATHI-69" x="19600" y="0"/> <use xlink:href="#E1-MJMATHI-64" x="19946" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="20691" y="0"/> <use xlink:href="#E1-MJMATHI-70" x="21692" y="0"/> <use xlink:href="#E1-MJMATHI-75" x="22196" y="0"/> <use xlink:href="#E1-MJMATHI-72" x="22768" y="0"/> <use xlink:href="#E1-MJMATHI-67" x="23220" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="23700" y="0"/> <use xlink:href="#E1-MJMATHI-64" x="24167" y="0"/> <use xlink:href="#E1-MJMAIN-3D" x="24968" y="0"/> <use xlink:href="#E1-MJMATHI-4F" x="26024" y="0"/> <use xlink:href="#E1-MJMATHI-46" x="26788" y="0"/> <use xlink:href="#E1-MJMATHI-46" x="27537" y="0"/> <use xlink:href="#E1-MJMATHI-64" x="28287" y="0"/> <use xlink:href="#E1-MJMATHI-62" x="28810" y="0"/> <use xlink:href="#E1-MJMAIN-31" x="29240" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="29740" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="30324" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="31325" y="0"/> <use xlink:href="#E1-MJMATHI-77" x="32103" y="0"/> <use xlink:href="#E1-MJMATHI-68" x="32820" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="33396" y="0"/> <use xlink:href="#E1-MJMATHI-72" x="33863" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="34314" y="0"/><g transform="translate(35058,0)"> <use xlink:href="#E1-MJMAIN-3D"/> <use xlink:href="#E1-MJMAIN-22" x="778" y="0"/></g> <use xlink:href="#E1-MJMATHI-61" x="36615" y="0"/> <use xlink:href="#E1-MJMAIN-3E" x="37423" y="0"/><g transform="translate(38479,0)"> <use xlink:href="#E1-MJMAIN-39"/> <use xlink:href="#E1-MJMAIN-30" x="500" y="0"/> <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"/></g> <use xlink:href="#E1-MJMAIN-22" x="40258" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="41036" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="42037" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="43038" y="0"/> <use xlink:href="#E1-MJMATHI-61" x="43399" y="0"/> <use xlink:href="#E1-MJMATHI-62" x="43929" y="0"/> <use xlink:href="#E1-MJMAIN-3D" x="44636" y="0"/></g></svg>secure_file_priv<br></code></pre></td></tr></table></figure><p>这条命令会在 <code>$secure_file_priv</code> 定义的目录下，创建一个 t.sql 文件保存建表语句，同时创建一个 t.txt 文件保存 CSV 数据。</p><h3 id="物理拷贝方法"><a href="#物理拷贝方法" class="headerlink" title="物理拷贝方法"></a>物理拷贝方法</h3><blockquote><p><strong>问题：直接把 db1.t 表的.frm 文件和.ibd 文件拷贝到 db2 目录下，是否可行呢？</strong></p><p>一个 InnoDB 表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有 db2.t 这个表，系统是不会识别和接受它们的。</p></blockquote><p>在 MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。</p><blockquote><p>假设我们现在的目标是在 db1 库下，复制一个跟表 t 相同的表 r，具体的执行步骤如下：</p><ol><li>执行 <code>create table r like t</code>，创建一个相同表结构的空表；</li><li>执行 <code>alter table r discard tablespace</code>，这时候 r.ibd 文件会被删除；</li><li>执行 <code>flush table t for export</code>，这时候 db1 目录下会生成一个 t.cfg 文件；</li><li>在 db1 目录下执行 <code>cp t.cfg r.cfg; cp t.ibd r.ibd；</code>这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；</li><li>执行 <code>unlock tables</code>，这时候 t.cfg 文件会被删除；</li><li>执行 <code>alter table r import tablespace</code>，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。</li></ol><img src="/article/undefined/%E7%89%A9%E7%90%86%E6%8B%B7%E8%B4%9D%E8%A1%A8.jpg" class title="物理拷贝表"><p><strong>注意点：</strong></p><ol><li>在第 3 步执行完 <code>flsuh table</code> 命令之后，db1.t 整个表处于只读状态，直到执行 <code>unlock tables</code> 命令后才释放读锁；</li><li>在执行 <code>import tablespace</code> 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。而这个表空间 id 存在于每一个数据页中。因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import 语句的耗时是非常短的。</li></ol></blockquote><h3 id="三种方法的优缺点"><a href="#三种方法的优缺点" class="headerlink" title="三种方法的优缺点"></a>三种方法的优缺点</h3><ol><li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：<ol><li>必须是全表拷贝，不能只拷贝部分数据；</li><li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；</li><li>由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。</li></ol></li><li>用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。</li><li>用 <code>select … into outfile</code> 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。</li></ol><h2 id="grant之后要跟着flush-privileges吗？"><a href="#grant之后要跟着flush-privileges吗？" class="headerlink" title="grant之后要跟着flush privileges吗？"></a>grant之后要跟着flush privileges吗？</h2><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create user &#x27;ua&#x27;@&#x27;%&#x27; identified by &#x27;pa&#x27;;<br></code></pre></td></tr></table></figure><p>这条语句的逻辑是创建一个用户’ua’@’%’，密码是 pa。注意，在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户。</p><p>这条命令做了两个动作：</p><ol><li>磁盘上，往 mysql.user 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N；</li><li>内存里，往数组 acl_users 里插入一个 acl_user 对象，这个对象的 access 字段值为 0。</li></ol><p>用户 ua 在 user 表中的状态</p><p><img src="/article/mysql.user 数据行.png"><span class="image-caption">mysql.user 数据行</span></p></blockquote><h3 id="全局权限"><a href="#全局权限" class="headerlink" title="全局权限"></a>全局权限</h3><p>全局权限，作用于整个 MySQL 实例，这些权限信息保存在 mysql 库的 user 表里。</p><blockquote><p>如果要给用户 ua 赋一个最高权限的话，语句是这么写的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">grant all privileges on *.* to &#x27;ua&#x27;@&#x27;%&#x27; with grant option;<br></code></pre></td></tr></table></figure><p>这个 grant 命令做了两个动作：</p><ol><li>磁盘上，将 mysql.user 表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为‘Y’；</li><li>内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。</li></ol><p>在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位</p></blockquote><p>基于上面的分析我们可以知道：</p><ol><li>grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。</li><li>对于一个已经存在的连接，它的全局权限不受 grant 命令的影响。</li></ol><blockquote><p>如果要回收上面的 grant 语句赋予的权限，可以使用下面这条命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">revoke all privileges on *.* from &#x27;ua&#x27;@&#x27;%&#x27;;<br></code></pre></td></tr></table></figure><p>这条 revoke 命令的用法与 grant 类似，做了如下两个动作：</p><ol><li>磁盘上，将 mysql.user 表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为“N”；</li><li>内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 的值修改为 0。</li></ol></blockquote><h3 id="db-权限"><a href="#db-权限" class="headerlink" title="db 权限"></a>db 权限</h3><p>除了全局权限，MySQL 也支持库级别的权限定义。</p><blockquote><p>如果要让用户 ua 拥有库 db1 的所有权限，可以执行下面这条命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">grant all privileges on db1.* to &#x27;ua&#x27;@&#x27;%&#x27; with grant option;<br></code></pre></td></tr></table></figure><p>基于库的权限记录保存在 mysql.db 表中，在内存里则保存在数组 acl_dbs 中。这条 grant 命令做了如下两个动作：</p><ol><li>磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；</li><li>内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。</li></ol><p>这个时刻用户 ua 在 db 表中的状态:</p><p><img src="/article/mysql.db 数据行.png"><span class="image-caption">mysql.db 数据行</span></p><p>每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组，根据 user、host 和 db 找到匹配的对象，然后根据对象的权限位来判断。</p></blockquote><p>grant 修改 db 权限的时候，是同时对磁盘和内存生效的</p><p>对于全局权限，因为全局权限存储在线程对象中，所以修改用户的全局权限后，不会影响到已经存在的连接； </p><p>对于数据库权限，因为acl_dbs是一个全局数组，修改用户的数据库权限，acl_dbs也会立马随之修改，线程对象可以立刻读到，所以会直接影响到已经存在的连接。</p><h3 id="表权限和列权限"><a href="#表权限和列权限" class="headerlink" title="表权限和列权限"></a>表权限和列权限</h3><p>除了 db 级别的权限外，MySQL 支持更细粒度的表权限和列权限。</p><p>其中，表权限定义存放在表 mysql.tables_priv 中，列权限定义存放在表 mysql.columns_priv 中。</p><p>这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。</p><blockquote><p>这两类权限的赋权命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table db1.t1(id int, a int);<br><br>grant all privileges on db1.t1 to &#x27;ua&#x27;@&#x27;%&#x27; with grant option;<br>GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO &#x27;ua&#x27;@&#x27;%&#x27; with grant option;<br></code></pre></td></tr></table></figure><p>跟 db 权限类似，这两个权限每次 grant 的时候都会修改数据表，也会同步修改内存中的 hash 结构。因此，<strong>对这两类权限的操作，也会马上影响到已经存在的连接。</strong></p></blockquote><h3 id="flush-privileges-命令"><a href="#flush-privileges-命令" class="headerlink" title="flush privileges 命令"></a>flush privileges 命令</h3><p><code>flush privileges</code> 命令会清空 acl_users 数组，然后从 mysql.user 表中读取数据重新加载，重新构造一个 acl_users 数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。</p><p>对于 db 权限、表权限和列权限，MySQL 也做了这样的处理</p><p>也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。而如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。<strong>因此，正常情况下，grant 命令之后，没有必要跟着执行 flush privileges 命令。</strong></p><h3 id="flush-privileges-使用场景"><a href="#flush-privileges-使用场景" class="headerlink" title="flush privileges 使用场景"></a>flush privileges 使用场景</h3><p>当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。</p><blockquote><p>直接用 DML 语句操作系统权限表</p><p><img src="/article/使用 flush privileges.png"><span class="image-caption">使用 flush privileges</span></p><p>T3 时刻虽然已经用 delete 语句删除了用户 ua，但是在 T4 时刻，仍然可以用 ua 连接成功。原因就是，这时候内存中 acl_users 数组中还有这个用户，因此系统判断时认为用户还正常存在。</p><p>在 T5 时刻执行过 flush 命令后，内存更新，T6 时刻再要用 ua 来登录的话，就会报错“无法访问”了</p></blockquote><h2 id="要不要使用分区表？"><a href="#要不要使用分区表？" class="headerlink" title="要不要使用分区表？"></a>要不要使用分区表？</h2><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `ftime` datetime NOT NULL,<br>  `c` int(11) DEFAULT NULL,<br>  KEY (`ftime`)<br>) ENGINE=InnoDB DEFAULT CHARSET=latin1<br>PARTITION BY RANGE (YEAR(ftime))<br>(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,<br> PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,<br> PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,<br>PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);<br>insert into t values(&#x27;2017-4-1&#x27;,1),(&#x27;2018-4-1&#x27;,1);<br></code></pre></td></tr></table></figure><p><img src="/article/表 t 的磁盘文件.png"><span class="image-caption">表 t 的磁盘文件</span></p><p>在表 t 中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在 p_2018 和 p_2019 这两个分区上。</p><p>这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件。也就是说：</p><ol><li>对于引擎层来说，这是 4 个表；</li><li>对于 Server 层来说，这是 1 个表。</li></ol></blockquote><ol><li>MySQL 在第一次打开分区表的时候，需要访问所有的分区；</li><li>在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；</li><li>在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。</li></ol><ol><li>分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。</li><li>分区也不要提前预留太多，在使用之前预先创建即可。</li><li>对于没有数据的历史分区，要及时的 drop 掉。</li></ol><h2 id="自增id用完怎么办？"><a href="#自增id用完怎么办？" class="headerlink" title="自增id用完怎么办？"></a>自增id用完怎么办？</h2><p>MySQL 里有很多自增的 id，每个自增 id 都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型 (unsigned int) 是 4 个字节，上限就是 2<sup>32</sup>-1。</p><h3 id="表定义自增值-id"><a href="#表定义自增值-id" class="headerlink" title="表定义自增值 id"></a>表定义自增值 id</h3><p>表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table t(id int unsigned auto_increment primary key) auto_increment=4294967295;<br>insert into t values(null);<br>//成功插入一行 4294967295<br>show create table t;<br>/* CREATE TABLE `t` (<br>  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,<br>  PRIMARY KEY (`id`)<br>) ENGINE=InnoDB AUTO_INCREMENT=4294967295;<br>*/<br><br>insert into t values(null);<br>//Duplicate entry &#x27;4294967295&#x27; for key &#x27;PRIMARY&#x27;<br></code></pre></td></tr></table></figure><p>第一个 insert 语句插入数据成功后，这个表的 AUTO_INCREMENT 没有改变（还是 4294967295），就导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。</p></blockquote><h3 id="InnoDB-系统自增-row-id"><a href="#InnoDB-系统自增-row-id" class="headerlink" title="InnoDB 系统自增 row_id"></a>InnoDB 系统自增 row_id</h3><p>如果创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 <strong>row_id</strong>。</p><p>InnoDB 维护了一个全局的 ‘dict_sys.row_id’ 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 ‘dict_sys.row_id’ 值作为要插入数据的 row_id，然后把 ‘dict_sys.row_id’ 的值加 1。</p><p>实际上，在代码实现时 row_id 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个字节的长度，这样写到数据表中时只放了最后 6 个字节，所以 row_id 能写到数据表中的值，就有两个特征：</p><ol><li><p>row_id 写入表中的值范围，是从 0 到 2<sup>48</sup>-1；</p></li><li><p>当 ‘dict_sys.row_id=2<sup>48</sup>‘时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。(写入表的 row_id 是从 0 开始到 2<sup>48</sup>-1。达到上限后，下一个值就是 0，然后继续循环。)</p><p>在 InnoDB 逻辑里，申请到 row_id=N 后，就将这行数据写入表中；如果表中已经存在 row_id=N 的行，新写入的行就会覆盖原有的行。</p></li></ol><h3 id="Xid"><a href="#Xid" class="headerlink" title="Xid"></a>Xid</h3><p>MySQL 内部维护了一个全局变量 ‘global_query_id’，每次执行语句的时候将它赋值给 ‘Query_id’，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 ‘Query_id’ 赋值给这个事务的 <strong>Xid</strong>。</p><p>而 <strong>‘global_query_id’ 是一个纯内存变量</strong>，重启之后就清零了。所以在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，<strong>同一个 binlog 文件里，Xid 一定是惟一的</strong>。</p><p>虽然 MySQL 重启不会导致同一个 binlog 里面出现两个相同的 Xid，但是如果 ‘global_query_id’ 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。</p><h3 id="Innodb-trx-id"><a href="#Innodb-trx-id" class="headerlink" title="Innodb trx_id"></a>Innodb trx_id</h3><p><strong>Xid 是由 server 层维护的</strong>。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，<strong>InnoDB 自己的 trx_id，是另外维护的</strong>。</p><p>InnoDB 内部维护了一个 ‘max_trx_id’ 全局变量，每次需要申请一个新的 trx_id 时，就获得 ‘max_trx_id’ 的当前值，然后并将 ‘max_trx_id’ 加 1。</p><p>InnoDB 数据可见性的<strong>核心思想</strong>是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。</p><p>对于正在执行的事务，可以从 <code>information_schema.innodb_trx</code> 表中看到事务的 trx_id。</p><blockquote><p><img src="/article/事务的 trx_id.png"><span class="image-caption">事务的 trx_id</span></p><p>session B 里，从 innodb_trx 表里查出的这两个字段，第二个字段 <code>trx_mysql_thread_id</code> 就是线程 id。显示线程 id，是为了说明这两次查询看到的事务对应的线程 id 都是 5，也就是 session A 所在的线程。</p><p>实际上，在 T1 时刻，session A 还没有涉及到更新，是一个只读事务。而对于只读事务，InnoDB 并不会分配 trx_id。也就是说：</p><ol><li>在 T1 时刻，trx_id 的值其实就是 0。而这个很大的数，只是显示用的。</li><li>直到 session A 在 T3 时刻执行 insert 语句的时候，InnoDB 才真正分配了 trx_id。所以，T4 时刻，session B 查到的这个 trx_id 的值就是 1289。</li></ol></blockquote><p>除了修改类语句外，如果在 select 语句后面加上 for update，这个事务也不是只读事务。</p><ol><li>update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2；</li><li>InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。</li></ol><blockquote><p>T2 时刻查到的这个很大的数字是怎么来的呢？</p></blockquote><p>这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的 trx 变量的指针地址转成整数，再加上 2<sup>48</sup>。使用这个算法，就可以保证以下两点：</p><ol><li>因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。</li><li>如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。</li><li>在显示值里面加上 2<sup>48</sup>，目的是要保证只读事务显示的 trx_id 值比较大，正常情况下就会区别于读写事务的 id。但是，trx_id 跟 row_id 的逻辑类似，定义长度也是 8 个字节。因此，在理论上还是可能出现一个读写事务与一个只读事务显示的 trx_id 相同的情况。不过这个概率很低，并且也没有什么实质危害，可以不管它。</li></ol><p>只读事务不分配 trx_id，有什么好处呢？</p><ol><li>一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB 就只需要拷贝读写事务的 trx_id。</li><li>另一个好处是，可以减少 trx_id 的申请次数。在 InnoDB 里，即使你只是执行一个普通的 select 语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请 trx_id，就大大减少了并发事务申请 trx_id 的锁冲突。</li></ol><p>max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就可能出现 max_trx_id 达到 2<sup>48</sup>-1 的上限，然后从 0 开始的情况。</p><p>当达到这个状态后，MySQL 就会持续出现一个脏读的 bug</p><blockquote><p>脏读的 bug 复现</p><p>首先需要把当前的 max_trx_id 先修改成 248-1。注意：这个 case 里使用的是可重复读隔离级别。</p><img src="/article/undefined/%E5%A4%8D%E7%8E%B0%E8%84%8F%E8%AF%BB.png" class title="复现脏读"><p>由于已经把系统的 max_trx_id 设置成了 2<sup>48</sup>-1，所以在 session A 启动的事务 TA 的低水位就是 2<sup>48</sup>-1。</p><p>在 T2 时刻，session B 执行第一条 update 语句的事务 id 就是 2<sup>48</sup>-1，而第二条 update 语句的事务 id 就是 0 了，这条 update 语句执行后生成的数据版本上的 trx_id 就是 0。</p><p>在 T3 时刻，session A 执行 select 语句的时候，判断可见性发现，c=3 这个数据版本的 trx_id，小于事务 TA 的低水位，因此认为这个数据可见。</p><p>但，这个是脏读。</p><p>由于低水位值会持续增加，而事务 id 从 0 开始计数，就导致了系统在这个时刻之后，所有的查询都会出现脏读的。</p><p>并且，MySQL 重启时 max_trx_id 也不会清 0，也就是说重启 MySQL，这个 bug 仍然存在。</p></blockquote><h3 id="thread-id"><a href="#thread-id" class="headerlink" title="thread_id"></a>thread_id</h3><p><strong>线程 id（thread_id）</strong>才是 MySQL 中最常见的一种自增 id。</p><p>thread_id 的逻辑：系统保存了一个全局变量 ‘thread_id_counter’，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。</p><p>thread_id_counter 定义的大小是 4 个字节，因此达到 2<sup>32</sup>-1 后，它就会重置为 0，然后继续增加。</p><p><strong>但是，不会在 show processlist 里看到两个相同的 thread_id。</strong>因为 MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 的时候，逻辑代码是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql">do &#123;<br>  new_id= thread_id_counter++;<br>&#125; while (!thread_ids.insert_unique(new_id).second);<br></code></pre></td></tr></table></figure><p><strong>总结：</strong></p><ol><li>表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。</li><li>row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。</li><li>Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。</li><li>InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，脏读的例子就是一个必现的 bug。</li><li>thread_id 是最常见的，而且也是处理得最好的一个自增 id 逻辑。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;自增主键为什么不是连续的？&quot;&gt;&lt;a href=&quot;#自增主键为什么不是连续的？&quot; class=&quot;headerlink&quot; title=&quot;自增主键为什么不是连续的？&quot;&gt;&lt;/a&gt;自增主键为什么不是连续的？&lt;/h2&gt;&lt;p&gt;自增主键，由于自增主键可以让主键索引尽量地保持递增顺
      
    
    </summary>
    
      <category term="Mysql" scheme="https://boyolo.github.io/categories/Mysql/"/>
    
      <category term="面试" scheme="https://boyolo.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="实习,Mysql" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-Mysql/"/>
    
  </entry>
  
  <entry>
    <title>递归</title>
    <link href="https://boyolo.github.io/article/38362.html"/>
    <id>https://boyolo.github.io/article/38362.html</id>
    <published>2022-05-08T03:04:06.000Z</published>
    <updated>2022-05-08T14:35:50.226Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何理解“递归”？"><a href="#如何理解“递归”？" class="headerlink" title="如何理解“递归”？"></a>如何理解“递归”？</h2><h3 id="递归需要满足的三个条件"><a href="#递归需要满足的三个条件" class="headerlink" title="递归需要满足的三个条件"></a>递归需要满足的三个条件</h3><ol><li><p>一个问题的解可以分解为几个子问题的解</p><p>子问题就是数据规模更小的问题</p></li><li><p>这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样</p></li><li><p>存在递归终止条件</p><p>把问题分解为子问题，把子问题再分解为子子问题，一层一层分解下去，不能存在无限循环，这就需要有终止条件。</p></li></ol><h3 id="如何编写递归代码？"><a href="#如何编写递归代码？" class="headerlink" title="如何编写递归代码？"></a>如何编写递归代码？</h3><p>写递归代码最关键的是<strong>写出递推公式，找到终止条件</strong></p><p><strong>写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。</strong></p><h3 id="递归代码要警惕堆栈溢出"><a href="#递归代码要警惕堆栈溢出" class="headerlink" title="递归代码要警惕堆栈溢出"></a>递归代码要警惕堆栈溢出</h3><p>函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><blockquote><p><strong>问题：如何避免出现堆栈溢出呢？</strong></p><p>可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。</p><p>但这种做法并不能完全解决问题，因为最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。如果实时计算，代码过于复杂，就会影响代码的可读性。</p></blockquote><h3 id="递归代码要警惕重复计算"><a href="#递归代码要警惕重复计算" class="headerlink" title="递归代码要警惕重复计算"></a>递归代码要警惕重复计算</h3><p>为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算。</p><ol><li>在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。</li><li>在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何理解“递归”？&quot;&gt;&lt;a href=&quot;#如何理解“递归”？&quot; class=&quot;headerlink&quot; title=&quot;如何理解“递归”？&quot;&gt;&lt;/a&gt;如何理解“递归”？&lt;/h2&gt;&lt;h3 id=&quot;递归需要满足的三个条件&quot;&gt;&lt;a href=&quot;#递归需要满足的三个条件&quot; c
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="递归" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92/"/>
    
    
      <category term="数据结构与算法,递归" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>队列</title>
    <link href="https://boyolo.github.io/article/26671.html"/>
    <id>https://boyolo.github.io/article/26671.html</id>
    <published>2022-05-07T05:00:55.000Z</published>
    <updated>2022-05-07T06:28:44.777Z</updated>
    
    <content type="html"><![CDATA[<h2 id="队列：队列在线程池等有限资源池中的应用"><a href="#队列：队列在线程池等有限资源池中的应用" class="headerlink" title="队列：队列在线程池等有限资源池中的应用"></a>队列：队列在线程池等有限资源池中的应用</h2><p>CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。</p><blockquote><p>当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？</p></blockquote><p><strong>先进者先出，这就是典型的“队列”。</strong></p><p>最基本的操作也是两个：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。</p><p>队列跟栈一样，也是<strong>一种操作受限的线性表数据结构</strong>。</p><p>用数组实现的队列叫作<strong>顺序队列</strong>，用链表实现的队列叫作<strong>链式队列</strong>。</p><h3 id="基于数组的队列实现方法"><a href="#基于数组的队列实现方法" class="headerlink" title="基于数组的队列实现方法"></a>基于数组的队列实现方法</h3><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 用数组实现的队列</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ArrayQueue</span> </span>&#123;<br>  <span class="hljs-comment">// 数组：items，数组大小：n</span><br>  <span class="hljs-keyword">private</span> String[] items;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> n = <span class="hljs-number">0</span>;<br>  <span class="hljs-comment">// head表示队头下标，tail表示队尾下标</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> head = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> tail = <span class="hljs-number">0</span>;<br><br>  <span class="hljs-comment">// 申请一个大小为capacity的数组</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ArrayQueue</span><span class="hljs-params">(<span class="hljs-keyword">int</span> capacity)</span> </span>&#123;<br>    items = <span class="hljs-keyword">new</span> String[capacity];<br>    n = capacity;<br>  &#125;<br><br>  <span class="hljs-comment">// 入队</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">enqueue</span><span class="hljs-params">(String item)</span> </span>&#123;<br>    <span class="hljs-comment">// 如果tail == n 表示队列已经满了</span><br>    <span class="hljs-keyword">if</span> (tail == n) <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br>    items[tail] = item;<br>    ++tail;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// 出队</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">dequeue</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 如果head == tail 表示队列为空</span><br>    <span class="hljs-keyword">if</span> (head == tail) <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>    <span class="hljs-comment">// 为了让其他语言的同学看的更加明确，把--操作放到单独一行来写了</span><br>    String ret = items[head];<br>    ++head;<br>    <span class="hljs-keyword">return</span> ret;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p>队列需要两个指针：</p><ol><li>一个是 head 指针，指向队头；</li><li>一个是 tail 指针，指向队尾。</li></ol><blockquote><p>每次进行出队操作都相当于删除数组下标为 0 的数据，要搬移整个队列中的数据，这样出队操作的时间复杂度就会从原来的 O(1) 变为 O(n)。能不能优化一下呢？</p></blockquote><p>在出队时可以不用搬移数据。如果没有空闲空间了，我们只需要在入队时，再集中触发一次数据的搬移操作。</p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 入队操作，将item放入队尾</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">enqueue</span><span class="hljs-params">(String item)</span> </span>&#123;<br>  <span class="hljs-comment">// tail == n表示队列末尾没有空间了</span><br>  <span class="hljs-keyword">if</span> (tail == n) &#123;<br>    <span class="hljs-comment">// tail ==n &amp;&amp; head==0，表示整个队列都占满了</span><br>    <span class="hljs-keyword">if</span> (head == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br>    <span class="hljs-comment">// 数据搬移</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = head; i &lt; tail; ++i) &#123;<br>      items[i-head] = items[i];<br>    &#125;<br>    <span class="hljs-comment">// 搬移完之后重新更新head和tail</span><br>    tail -= head;<br>    head = <span class="hljs-number">0</span>;<br>  &#125;<br><br>  items[tail] = item;<br>  ++tail;<br>  <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><img src="/article/undefined/%E9%A1%BA%E5%BA%8F%E9%98%9F%E5%88%97%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB.jpg" class title="顺序队列数据迁移"></blockquote><h3 id="基于链表的队列实现方法"><a href="#基于链表的队列实现方法" class="headerlink" title="基于链表的队列实现方法"></a>基于链表的队列实现方法</h3><p>基于链表的实现，我们同样需要两个指针：head 指针和 tail 指针。它们分别指向链表的第一个结点和最后一个结点。</p><img src="/article/undefined/%E5%9F%BA%E4%BA%8E%E9%93%BE%E8%A1%A8%E7%9A%84%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0.jpg" class title="基于链表的队列实现"><p><strong>循环队列</strong></p><img src="/article/undefined/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E9%93%BE%E8%A1%A8%E7%9A%84%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0.jpg" class title="基于循环链表的队列实现"><p><strong>确定好队空和队满的判定条件：</strong></p><ol><li><p>队列为空的判断条件是 head == tail</p></li><li><p>当队满时的判断条件是 (tail+1)%n=head</p><img src="/article/undefined/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E9%98%9F%E6%BB%A1.jpg" class title="循环队列队满"><p><strong>循环队列会浪费一个数组的存储空间</strong></p></li></ol><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CircularQueue</span> </span>&#123;<br>  <span class="hljs-comment">// 数组：items，数组大小：n</span><br>  <span class="hljs-keyword">private</span> String[] items;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> n = <span class="hljs-number">0</span>;<br>  <span class="hljs-comment">// head表示队头下标，tail表示队尾下标</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> head = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> tail = <span class="hljs-number">0</span>;<br><br>  <span class="hljs-comment">// 申请一个大小为capacity的数组</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">CircularQueue</span><span class="hljs-params">(<span class="hljs-keyword">int</span> capacity)</span> </span>&#123;<br>    items = <span class="hljs-keyword">new</span> String[capacity];<br>    n = capacity;<br>  &#125;<br><br>  <span class="hljs-comment">// 入队</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">enqueue</span><span class="hljs-params">(String item)</span> </span>&#123;<br>    <span class="hljs-comment">// 队列满了</span><br>    <span class="hljs-keyword">if</span> ((tail + <span class="hljs-number">1</span>) % n == head) <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br>    items[tail] = item;<br>    tail = (tail + <span class="hljs-number">1</span>) % n;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// 出队</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">dequeue</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 如果head == tail 表示队列为空</span><br>    <span class="hljs-keyword">if</span> (head == tail) <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>    String ret = items[head];<br>    head = (head + <span class="hljs-number">1</span>) % n;<br>    <span class="hljs-keyword">return</span> ret;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><h3 id="阻塞队列和并发队列"><a href="#阻塞队列和并发队列" class="headerlink" title="阻塞队列和并发队列"></a>阻塞队列和并发队列</h3><p><strong>阻塞队列</strong>就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。</p><img src="/article/undefined/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97.jpg" class title="阻塞队列"><p><strong>并发队列</strong>是线程安全的队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。</p><blockquote><p><strong>问题：线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理？各种处理策略又是如何实现的呢？</strong></p><ol><li>第一种是非阻塞的处理方式，直接拒绝任务请求；</li><li>另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。<ol><li>基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。</li><li>而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。</li></ol></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;队列：队列在线程池等有限资源池中的应用&quot;&gt;&lt;a href=&quot;#队列：队列在线程池等有限资源池中的应用&quot; class=&quot;headerlink&quot; title=&quot;队列：队列在线程池等有限资源池中的应用&quot;&gt;&lt;/a&gt;队列：队列在线程池等有限资源池中的应用&lt;/h2&gt;&lt;p&gt;CP
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="队列" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E9%98%9F%E5%88%97/"/>
    
    
      <category term="数据结构与算法,队列" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>栈</title>
    <link href="https://boyolo.github.io/article/37273.html"/>
    <id>https://boyolo.github.io/article/37273.html</id>
    <published>2022-05-06T07:27:26.000Z</published>
    <updated>2022-05-06T08:22:41.692Z</updated>
    
    <content type="html"><![CDATA[<h2 id="栈：如何实现浏览器的前进和后退功能？"><a href="#栈：如何实现浏览器的前进和后退功能？" class="headerlink" title="栈：如何实现浏览器的前进和后退功能？"></a>栈：如何实现浏览器的前进和后退功能？</h2><blockquote><p>当你依次访问完一串页面 a-b-c 之后，点击浏览器的后退按钮，就可以查看之前浏览过的页面 b 和 a。当你后退到页面 a，点击前进按钮，就可以重新查看页面 b 和 c。但是，如果你后退到页面 b 后，点击了新的页面 d，那就无法再通过前进、后退功能查看页面 c 了。</p></blockquote><p><strong>后进者先出，先进者后出，这就是典型的“栈”结构。</strong></p><p>从栈的操作特性上来看，<strong>栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。</strong></p><h3 id="如何实现一个“栈”？"><a href="#如何实现一个“栈”？" class="headerlink" title="如何实现一个“栈”？"></a>如何实现一个“栈”？</h3><p>栈主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。</p><p>栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作<strong>顺序栈</strong>，用链表实现的栈，我们叫作<strong>链式栈</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 基于数组实现的顺序栈</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ArrayStack</span> </span>&#123;<br>  <span class="hljs-keyword">private</span> String[] items;  <span class="hljs-comment">// 数组</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> count;       <span class="hljs-comment">// 栈中元素个数</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> n;           <span class="hljs-comment">//栈的大小</span><br><br>  <span class="hljs-comment">// 初始化数组，申请一个大小为n的数组空间</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ArrayStack</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>    <span class="hljs-keyword">this</span>.items = <span class="hljs-keyword">new</span> String[n];<br>    <span class="hljs-keyword">this</span>.n = n;<br>    <span class="hljs-keyword">this</span>.count = <span class="hljs-number">0</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// 入栈操作</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">push</span><span class="hljs-params">(String item)</span> </span>&#123;<br>    <span class="hljs-comment">// 数组空间不够了，直接返回false，入栈失败。</span><br>    <span class="hljs-keyword">if</span> (count == n) <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;<br>    <span class="hljs-comment">// 将item放到下标为count的位置，并且count加一</span><br>    items[count] = item;<br>    ++count;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// 出栈操作</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 栈为空，则直接返回null</span><br>    <span class="hljs-keyword">if</span> (count == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>    <span class="hljs-comment">// 返回下标为count-1的数组元素，并且栈中元素个数count减一</span><br>    String tmp = items[count-<span class="hljs-number">1</span>];<br>    --count;<br>    <span class="hljs-keyword">return</span> tmp;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>空间复杂度是 O(1)</p><p>时间复杂度是 O(1)</p><h3 id="支持动态扩容的顺序栈"><a href="#支持动态扩容的顺序栈" class="headerlink" title="支持动态扩容的顺序栈"></a>支持动态扩容的顺序栈</h3><blockquote><p>如何来实现一个支持动态扩容的数组的？</p><p>当数组空间不够时，我们就重新申请一块更大的内存，将原来数组中数据统统拷贝过去。这样就实现了一个支持动态扩容的数组。</p></blockquote><p>要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。</p><img src="/article/undefined/%E6%94%AF%E6%8C%81%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%A0%88.jpg" class title="支持动态扩容的顺序栈"><p>对于出栈操作来说，我们不会涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍然是 O(1)。</p><p>但是，对于入栈操作来说，情况就不一样了。当栈中有空闲空间时，入栈操作的时间复杂度为 O(1)。但当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了 O(n)。<strong>对于入栈操作来说，最好情况时间复杂度是 O(1)，最坏情况时间复杂度是 O(n)。</strong></p><p>入栈操作的均摊时间复杂度为 O(1)</p><blockquote><p>假设和定义：</p><ul><li>栈空间不够时，我们重新申请一个是原来大小两倍的数组；</li><li>为了简化分析，假设只有入栈操作没有出栈操作；</li><li>定义不涉及内存搬移的入栈操作为 simple-push 操作，时间复杂度为 O(1)。</li></ul><p>如果当前栈大小为 K，并且已满，当再有新的数据要入栈时，就需要重新申请 2 倍大小的内存，并且做 K 个数据的搬移操作，然后再入栈。但是，接下来的 K-1 次入栈操作，我们都不需要再重新申请内存和搬移数据，所以这 K-1 次入栈操作都只需要一个 simple-push 操作就可以完成。</p><img src="/article/undefined/%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E6%A0%88.jpg" class title="动态扩容栈"><p>这 K 次入栈操作，总共涉及了 K 个数据的搬移，以及 K 次 simple-push 操作。将 K 个数据搬移均摊到 K 次入栈操作，那每个入栈操作只需要一个数据搬移和一个 simple-push 操作。以此类推，<strong>入栈操作的均摊时间复杂度就为 O(1)</strong>。</p></blockquote><h3 id="栈在函数调用中的应用"><a href="#栈在函数调用中的应用" class="headerlink" title="栈在函数调用中的应用"></a>栈在函数调用中的应用</h3><p>操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>   <span class="hljs-keyword">int</span> a = <span class="hljs-number">1</span>; <br>   <span class="hljs-keyword">int</span> ret = <span class="hljs-number">0</span>;<br>   <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;<br>   ret = add(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>);<br>   res = a + ret;<br>   printf(<span class="hljs-string">&quot;%d&quot;</span>, res);<br>   reuturn <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x, <span class="hljs-keyword">int</span> y)</span> </span>&#123;<br>   <span class="hljs-keyword">int</span> sum = <span class="hljs-number">0</span>;<br>   sum = x + y;<br>   <span class="hljs-keyword">return</span> sum;<br>&#125;<br></code></pre></td></tr></table></figure><p>main() 函数调用了 add() 函数，获取计算结果，并且与临时变量 a 相加，最后打印 res 的值</p><p> 函数调用栈.jpg)</p></blockquote><h3 id="栈在表达式求值中的应用"><a href="#栈在表达式求值中的应用" class="headerlink" title="栈在表达式求值中的应用"></a>栈在表达式求值中的应用</h3><blockquote><p>3+5*8-6</p></blockquote><p>编译器就是通过两个栈来实现的。</p><ol><li>其中一个保存操作数的栈，</li><li>另一个是保存运算符的栈。</li></ol><p>我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。</p><p>如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p><blockquote><img src="/article/undefined/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.jpg" class title="表达式的计算过程"></blockquote><h3 id="栈在括号匹配中的应用"><a href="#栈在括号匹配中的应用" class="headerlink" title="栈在括号匹配中的应用"></a>栈在括号匹配中的应用</h3><blockquote><p>假设表达式中只包含三种括号，圆括号 ()、方括号[]和花括号{}，并且它们可以任意嵌套。比如，{[] ()[{}]}或[{()}([])]等都为合法格式，而{[}()]或[({)]为不合法的格式。</p></blockquote><p>用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。</p><p>当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。</p><h3 id="如何实现浏览器的前进、后退功能？"><a href="#如何实现浏览器的前进、后退功能？" class="headerlink" title="如何实现浏览器的前进、后退功能？"></a>如何实现浏览器的前进、后退功能？</h3><p>使用两个栈，X 和 Y，我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入栈 Y。当我们点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。当栈 X 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;栈：如何实现浏览器的前进和后退功能？&quot;&gt;&lt;a href=&quot;#栈：如何实现浏览器的前进和后退功能？&quot; class=&quot;headerlink&quot; title=&quot;栈：如何实现浏览器的前进和后退功能？&quot;&gt;&lt;/a&gt;栈：如何实现浏览器的前进和后退功能？&lt;/h2&gt;&lt;blockquo
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="栈" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A0%88/"/>
    
    
      <category term="数据结构与算法,栈" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E6%A0%88/"/>
    
  </entry>
  
  <entry>
    <title>链表</title>
    <link href="https://boyolo.github.io/article/54862.html"/>
    <id>https://boyolo.github.io/article/54862.html</id>
    <published>2022-05-02T02:59:49.000Z</published>
    <updated>2022-05-06T05:00:43.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何实现LRU缓存淘汰算法"><a href="#如何实现LRU缓存淘汰算法" class="headerlink" title="如何实现LRU缓存淘汰算法?"></a>如何实现LRU缓存淘汰算法?</h2><p><strong>缓存</strong>是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。</p><p>缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：</p><ol><li>先进先出策略 FIFO（First In，First Out）</li><li>最少使用策略 LFU（Least Frequently Used）</li><li>最近最少使用策略 LRU（Least Recently Used）</li></ol><blockquote><p><strong>数组与链表的对比</strong></p><p>底层的存储结构</p><img src="/article/undefined/%E6%95%B0%E7%BB%84%E4%B8%8E%E9%93%BE%E8%A1%A8%E5%86%85%E5%AD%98%E5%88%86%E5%B8%83.jpg" class title="数组与链表内存分布"><p>数组需要一块连续的内存空间来存储，对内存的要求比较高。</p><p>链表并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。把内存块称为链表的“结点”。</p></blockquote><h3 id="常见的链表结构"><a href="#常见的链表结构" class="headerlink" title="常见的链表结构"></a>常见的链表结构</h3><ol><li><p>单链表</p><img src="/article/undefined/%E5%8D%95%E9%93%BE%E8%A1%A8.jpg" class title="单链表"><p>单链表是一种链式存取的数据结构，用一组地址任意的存储单元存放线性表中的数据元素。链表中的数据是以结点来表示的，每个结点的构成：<strong>元素(数据元素的映象) +指针(指示后继元素存储位置)</strong>，元素就是存储数据的存储单元，指针就是连接每个结点的地址数据。</p><p>有两个结点是比较特殊的</p><ol><li>第一个结点叫作头结点，头结点用来记录链表的基地址，有了它，我们就可以遍历得到整条链表。</li><li>最后一个结点叫作尾结点。尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。</li></ol><blockquote><p>在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。</p><hr><p>针对<strong>链表的插入和删除操作</strong>，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。</p><img src="/article/undefined/%E9%93%BE%E8%A1%A8%E7%9A%84%E6%8F%92%E5%85%A5%E5%92%8C%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C.jpg" class title="链表的插入和删除操作"><hr><p><strong>链表不能随机访问第 k 个元素</strong>。</p><p>因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。</p><p><strong>链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。</strong></p></blockquote></li><li><p>循环链表</p><img src="/article/undefined/%E5%BE%AA%E7%8E%AF%E9%93%BE%E8%A1%A8.jpg" class title="循环链表"><p>循环链表是一种特殊的单链表，它的特点是表中<strong>最后一个结点的指针域指向头结点</strong>，整个链表形成一个环。</p><p>和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。</p></li><li><p>双向链表</p><img src="/article/undefined/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8.jpg" class title="双向链表"><p>双向链表也叫双链表，是链表的一种，它的每个数据结点中都有<strong>两个指针</strong>，分别指向<strong>直接后继和直接前驱</strong>。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。一般我们都构造<strong>双向循环链表</strong>。</p><img src="/article/undefined/%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E9%93%BE%E8%A1%A8.jpg" class title="双向循环链表"><p>双向链表需要<strong>额外的两个空间</strong>来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。</p><blockquote><p>双向链表可以支持 <strong>O(1) 时间复杂度的情况下找到前驱结点</strong>，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效</p><hr><p><strong>删除操作</strong></p><ol><li><p>删除结点中“值等于某个给定值”的结点；</p><p>不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。</p><p>尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，<strong>删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)</strong>。</p></li><li><p>删除给定指针指向的结点。</p><p>单链表：已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。</p><p><strong>双链表：</strong>因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。单链表<strong>删除操作</strong>需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度。</p></li></ol><hr><p><strong>插入操作</strong></p><p>在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表需要 O(1) 时间复杂度，而单向链表需要 O(n) 的时间复杂度。</p><hr><p><strong>按值查询</strong></p><p>对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。</p></blockquote></li></ol><p><strong>用空间换时间的设计思想：</strong>当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。</p><p><strong>缓存实际上就是利用了空间换时间的设计思想。</strong>如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。</p><h3 id="如何基于链表实现-LRU-缓存淘汰算法？"><a href="#如何基于链表实现-LRU-缓存淘汰算法？" class="headerlink" title="如何基于链表实现 LRU 缓存淘汰算法？"></a>如何基于链表实现 LRU 缓存淘汰算法？</h3><p>维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。</p><ol><li>如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。</li><li>如果此数据没有在缓存链表中，又可以分为两种情况：<ol><li>如果此时缓存未满，则将此结点直接插入到链表的头部；</li><li>如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。</li></ol></li></ol><p>这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。</p><h2 id="如何轻松写出正确的链表代码？"><a href="#如何轻松写出正确的链表代码？" class="headerlink" title="如何轻松写出正确的链表代码？"></a>如何轻松写出正确的链表代码？</h2><h3 id="技巧一：理解指针或引用的含义"><a href="#技巧一：理解指针或引用的含义" class="headerlink" title="技巧一：理解指针或引用的含义"></a>技巧一：理解指针或引用的含义</h3><p>将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。</p><h3 id="技巧二：警惕指针丢失和内存泄漏"><a href="#技巧二：警惕指针丢失和内存泄漏" class="headerlink" title="技巧二：警惕指针丢失和内存泄漏"></a>技巧二：警惕指针丢失和内存泄漏</h3><blockquote><img src="/article/undefined/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E6%8F%92%E5%85%A5%E6%93%8D%E4%BD%9C.jpg" class title="单链表的插入操作"><p>在结点 a 和相邻的结点 b 之间插入结点 x，假设当前指针 p 指向结点 a</p><p>将代码实现变成下面这个样子，就会发生指针丢失和内存泄露:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">p-&gt;next = x;  <span class="hljs-comment">// 将p的next指针指向x结点；</span><br>x-&gt;next = p-&gt;next;  <span class="hljs-comment">// 将x的结点的next指针指向b结点；</span><br></code></pre></td></tr></table></figure><p>p-&gt;next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x。第 2 行代码相当于将 x 赋值给 x-&gt;next，自己指向自己。因此，整个链表也就断成了两半，从结点 b 往后的所有结点都无法访问到了。</p></blockquote><p><strong>插入结点时，一定要注意操作的顺序</strong></p><blockquote><p>要先将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏</p></blockquote><p><strong>删除链表结点时，也一定要记得手动释放内存空间</strong></p><h3 id="技巧三：利用哨兵简化实现难度"><a href="#技巧三：利用哨兵简化实现难度" class="headerlink" title="技巧三：利用哨兵简化实现难度"></a>技巧三：利用哨兵简化实现难度</h3><p><strong>针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理</strong></p><p><strong>引入哨兵结点</strong>，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫<strong>带头链表</strong>。相反，没有哨兵结点的链表就叫作不带头链表。</p><p><strong>哨兵结点是不存储数据的</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何实现LRU缓存淘汰算法&quot;&gt;&lt;a href=&quot;#如何实现LRU缓存淘汰算法&quot; class=&quot;headerlink&quot; title=&quot;如何实现LRU缓存淘汰算法?&quot;&gt;&lt;/a&gt;如何实现LRU缓存淘汰算法?&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;缓存&lt;/strong&gt;是一种提高
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="链表" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/"/>
    
    
      <category term="数据结构与算法,链表" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>数组</title>
    <link href="https://boyolo.github.io/article/32766.html"/>
    <id>https://boyolo.github.io/article/32766.html</id>
    <published>2022-05-02T02:05:55.000Z</published>
    <updated>2022-05-02T02:59:32.099Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/100017301?tab=catalog">参考学习自·数据结构与算法之美</a></p><h2 id="数组：为什么很多编程语言中数组都从0开始编号？"><a href="#数组：为什么很多编程语言中数组都从0开始编号？" class="headerlink" title="数组：为什么很多编程语言中数组都从0开始编号？"></a>数组：为什么很多编程语言中数组都从0开始编号？</h2><p>数组（Array）是一种<strong>线性表</strong>数据结构。它用一组<strong>连续</strong>的内存空间，来存储一组具有<strong>相同类型</strong>的数据。</p><ol><li><p>线性表（Linear List）</p><p>线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。</p></li><li><p>连续的内存空间和相同类型的数据</p></li></ol><blockquote><img src="/article/undefined/%E5%86%85%E5%AD%98%E5%9D%97%E5%9C%B0%E5%9D%80.jpg" class title="内存块地址"></blockquote><p>计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs wiki">a[i]_address = base_address + i * data_type_size<br></code></pre></td></tr></table></figure><p><strong>数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)</strong></p><h3 id="低效的“插入”和“删除”"><a href="#低效的“插入”和“删除”" class="headerlink" title="低效的“插入”和“删除”"></a>低效的“插入”和“删除”</h3><p>数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效</p><p><strong>插入操作</strong></p><blockquote><p>假设数组的长度为 n，现在，如果需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，需要将第 k～n 这部分的元素都顺序地往后挪一位。</p><p>最好时间复杂度： O(1)</p><p>最坏时间复杂度： O(n)</p><p>平均情况时间复杂度: (1+2+…n)/n=O(n)</p><p>如果数组中的数据是<strong>有序</strong>的，在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。</p><hr><p>但是，如果数组中存储的数据并<strong>没有任何规律</strong>，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，<strong>直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置</strong>。</p></blockquote><p><strong>删除操作</strong></p><blockquote><p>要删除第 k 个位置的数据</p><p>最好时间复杂度： O(1)</p><p>最坏时间复杂度： O(n)</p><p>平均情况时间复杂度: (1+2+…n)/n=O(n)</p></blockquote><p>在某些特殊场景下，我们并不一定非得追求数组中数据的连续性</p><blockquote><p>数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。依次删除 a，b，c 三个元素。</p><p>为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作<strong>并不是真正地搬移数据</strong>，只是<strong>记录数据已经被删除</strong>。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。</p></blockquote><h3 id="警惕数组的访问越界问题"><a href="#警惕数组的访问越界问题" class="headerlink" title="警惕数组的访问越界问题"></a>警惕数组的访问越界问题</h3><blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>* argv[])</span></span>&#123;<br>    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">int</span> arr[<span class="hljs-number">3</span>] = &#123;<span class="hljs-number">0</span>&#125;;<br>    <span class="hljs-keyword">for</span>(; i&lt;=<span class="hljs-number">3</span>; i++)&#123;<br>        arr[i] = <span class="hljs-number">0</span>;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world\n&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”</p><p>因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i&lt;=3 而非 i&lt;3，所以当 i=3 时，数组 a[3]访问越界。</p><p>在 <strong>C 语言</strong>中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。</p><p><strong>数组越界在 C 语言中是一种未决行为</strong>，并没有规定数组访问越界时编译器应该如何处理。因为，<strong>访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误</strong>。</p></blockquote><h3 id="容器能否完全替代数组？"><a href="#容器能否完全替代数组？" class="headerlink" title="容器能否完全替代数组？"></a>容器能否完全替代数组？</h3><p>ArrayList 最大的优势就是可以将很多数组操作的细节封装起来，还有一个优势，就是支持动态扩容。</p><p>数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。</p><p>如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。</p><blockquote><p>因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。</p></blockquote><ol><li>Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。</li><li>如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。</li><li>当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList&lt;ArrayList<object> &gt; array。</object></li></ol><h3 id="为什么大多数编程语言中，数组要从-0-开始编号，而不是从-1-开始呢？"><a href="#为什么大多数编程语言中，数组要从-0-开始编号，而不是从-1-开始呢？" class="headerlink" title="为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？"></a>为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？</h3><p>从数组存储的内存模型上来看，“下标”最确切的定义应该是<strong>“偏移（offset）”</strong>。</p><p>如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">a[k]_address = base_address + k * type_size<br></code></pre></td></tr></table></figure><blockquote><p>但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">a[k]_address = base_address + (k-1)*type_size<br></code></pre></td></tr></table></figure><p>从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。</p></blockquote><p>数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以<strong>为了减少一次减法操作</strong>，数组选择了从 0 开始编号，而不是从 1 开始。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/100017301?tab=catalog&quot;&gt;参考学习自·数据结构与算法之美&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;数组：为什么很多编程语言中数组都从0开始编号？&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="数组" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/"/>
    
    
      <category term="数据结构与算法,数组" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E6%95%B0%E7%BB%84/"/>
    
  </entry>
  
  <entry>
    <title>复杂度分析</title>
    <link href="https://boyolo.github.io/article/54635.html"/>
    <id>https://boyolo.github.io/article/54635.html</id>
    <published>2022-04-30T00:56:03.000Z</published>
    <updated>2022-05-02T06:00:26.595Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/100017301?tab=catalog">参考学习自·数据结构与算法之美</a></p><p><strong>事后统计法</strong></p><p>这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。</p><p>局限性:</p><ol><li>测试结果非常依赖测试环境</li><li>测试结果受数据规模的影响很大</li></ol><p>我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。</p><h2 id="大-O-复杂度表示法"><a href="#大-O-复杂度表示法" class="headerlink" title="大 O 复杂度表示法"></a>大 O 复杂度表示法</h2><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">cal</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> sum = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">for</span> (; i &lt;= n; ++i) &#123;<br>    sum = sum + i;<br>  &#125;<br>  <span class="hljs-keyword">return</span> sum;<br>&#125;<br></code></pre></td></tr></table></figure><p>从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：<strong>读数据-运算-写数据</strong>。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。</p><p>第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n<em>unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)</em>unit_time。</p><p><strong>所有代码的执行时间 T(n) 与每行代码的执行次数成正比</strong></p></blockquote><p><strong>所有代码的执行时间 T(n) 与每行代码的执行次数 f(n) 成正比</strong></p><p><strong>大 O 时间复杂度表示法</strong></p><img src="/article/undefined/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E5%85%AC%E5%BC%8F.png" class title="复杂度分析公式"><ol><li>T(n) 表示代码执行的时间；</li><li>n 表示数据规模的大小；</li><li>f(n) 表示每行代码执行的次数总和。</li><li>公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比</li></ol><p>大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作<strong>渐进时间复杂度</strong>（asymptotic time complexity），简称<strong>时间复杂度</strong>。</p><h2 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h2><h3 id="如何分析一段代码的时间复杂度？"><a href="#如何分析一段代码的时间复杂度？" class="headerlink" title="如何分析一段代码的时间复杂度？"></a>如何分析一段代码的时间复杂度？</h3><ol><li><p>只关注循环执行次数最多的一段代码</p><p>大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会<strong>忽略</strong>掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，在分析一个算法、一段代码的时间复杂度的时候，也<strong>只关注循环执行次数最多</strong>的那一段代码就可以了。</p></li><li><p>加法法则：总复杂度等于量级最大的那段代码的复杂度</p><p><strong>总的时间复杂度就等于量级最大的那段代码的时间复杂度</strong></p><p>如果 T1(n)=O(f(n))，T2(n)=O(g(n))，那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))</p></li><li><p>乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积</p><p>如果 T1(n)=O(f(n))，T2(n)=O(g(n))，那么 T(n)=T1(n)<em>T2(n)=O(f(n))</em>O(g(n))=O(f(n)*g(n))</p></li></ol><h3 id="几种常见时间复杂度实例分析"><a href="#几种常见时间复杂度实例分析" class="headerlink" title="几种常见时间复杂度实例分析"></a>几种常见时间复杂度实例分析</h3><img src="/article/undefined/%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%87%8F%E7%BA%A7.jpg" class title="复杂度量级"><p>多项式量级和非多项式量级，其中，非多项式量级只有两个：O(2<sup>n</sup>) 和 O(n!)</p><p><strong>越高阶复杂度的算法，执行效率越低</strong></p><p>时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题</p><p>当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。</p><ol><li><p>O(1)</p><p>O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码</p><p>只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)</p></li><li><p>O(logn)、O(nlogn)</p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">i=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span> (i &lt;= n)  &#123;<br>  i = i * <span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>变量 i 的值从 1 开始取，每循环一次就乘以 2，当大于 n 时，循环结束</p><p><img src="/article/变量 i 的取值就是一个等比数列.jpg"><span class="image-caption">变量 i 的取值就是一个等比数列</span></p><p>通过 2<sup>x</sup>=n 求解 x，x=log<sub>2</sub>n</p><p>所以，这段代码的时间复杂度就是 O(log<sub>2</sub>n)</p></blockquote><p><strong>在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))</strong></p><blockquote><p>log<sub>3</sub>n 就等于 log<sub>3</sub>2 <em> log<sub>2</sub>n，所以 O(log<sub>3</sub>n) = O(C </em> log<sub>2</sub>n)，其中 C=log<sub>3</sub>2 是一个常量。可以直接忽略</p><p>O(log<sub>2</sub>n) 就可以直接表示为 O(logn)</p></blockquote><p>因此，在对数阶时间复杂度的表示方法里，我们<strong>忽略对数的“底”，统一表示为 O(logn)。</strong></p></li><li><p>O(m+n)、O(m*n)</p><p><strong>代码的复杂度由两个数据的规模来决定</strong></p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">cal</span><span class="hljs-params">(<span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> sum_1 = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">for</span> (; i &lt; m; ++i) &#123;<br>    sum_1 = sum_1 + i;<br>  &#125;<br><br>  <span class="hljs-keyword">int</span> sum_2 = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">for</span> (; j &lt; n; ++j) &#123;<br>    sum_2 = sum_2 + j;<br>  &#125;<br><br>  <span class="hljs-keyword">return</span> sum_1 + sum_2;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p>m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)</p></li></ol><h2 id="空间复杂度分析"><a href="#空间复杂度分析" class="headerlink" title="空间复杂度分析"></a>空间复杂度分析</h2><p>空间复杂度全称就是<strong>渐进空间复杂度</strong>（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。</p><blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span>[] a = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[n];<br>  <span class="hljs-keyword">for</span> (i; i &lt;n; ++i) &#123;<br>    a[i] = i * i;<br>  &#125;<br><br>  <span class="hljs-keyword">for</span> (i = n<span class="hljs-number">-1</span>; i &gt;= <span class="hljs-number">0</span>; --i) &#123;<br>    print out a[i]<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>第 2 行代码中，申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。</p><p>第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。</p></blockquote><p>常见的空间复杂度就是 O(1)、O(n)、O(n2 )</p><h2 id="浅析最好、最坏、平均、均摊时间复杂度"><a href="#浅析最好、最坏、平均、均摊时间复杂度" class="headerlink" title="浅析最好、最坏、平均、均摊时间复杂度"></a>浅析最好、最坏、平均、均摊时间复杂度</h2><h3 id="最好、最坏情况时间复杂度"><a href="#最好、最坏情况时间复杂度" class="headerlink" title="最好、最坏情况时间复杂度"></a>最好、最坏情况时间复杂度</h3><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// n表示数组array的长度</span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">find</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] array, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> x)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> pos = -<span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">for</span> (; i &lt; n; ++i) &#123;<br>    <span class="hljs-keyword">if</span> (array[i] == x) &#123;<br>       pos = i;<br>       <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> pos;<br>&#125;<br></code></pre></td></tr></table></figure><p>要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。</p></blockquote><p><strong>最好情况时间复杂度</strong>就是，在最理想的情况下，执行这段代码的时间复杂度。</p><p><strong>最坏情况时间复杂度</strong>就是，在最糟糕的情况下，执行这段代码的时间复杂度。</p><h3 id="平均情况时间复杂度"><a href="#平均情况时间复杂度" class="headerlink" title="平均情况时间复杂度"></a>平均情况时间复杂度</h3><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// n表示数组array的长度</span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">find</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] array, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> x)</span> </span>&#123;<br>  <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">int</span> pos = -<span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">for</span> (; i &lt; n; ++i) &#123;<br>    <span class="hljs-keyword">if</span> (array[i] == x) &#123;<br>       pos = i;<br>       <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> pos;<br>&#125;<br></code></pre></td></tr></table></figure><p>要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：</p><img src="/article/undefined/%E5%B9%B3%E5%9D%87%E6%83%85%E5%86%B5.jpg" class title="平均情况"><p>时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，这个公式简化之后，得到的平均时间复杂度就是 O(n)</p></blockquote><p><strong>加权平均时间复杂度</strong>或者<strong>期望时间复杂度</strong></p><blockquote><p>要查找的变量 x，要么在数组里，要么就不在数组里。</p><p>假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。</p><img src="/article/undefined/%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6.jpg" class title="加权平均时间复杂度"><p>这个值就是概率论中的<strong>加权平均值</strong>，也叫作<strong>期望值</strong>，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者<strong>期望时间复杂度</strong>。</p><p>引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。</p></blockquote><h3 id="均摊时间复杂度"><a href="#均摊时间复杂度" class="headerlink" title="均摊时间复杂度"></a>均摊时间复杂度</h3><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// array表示一个长度为n的数组</span><br><span class="hljs-comment">// 代码中的array.length就等于n</span><br><span class="hljs-keyword">int</span>[] array = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[n];<br><span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-keyword">int</span> val)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (count == array.length) &#123;<br>    <span class="hljs-keyword">int</span> sum = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; array.length; ++i) &#123;<br>      sum = sum + array[i];<br>    &#125;<br>    array[<span class="hljs-number">0</span>] = sum;<br>    count = <span class="hljs-number">1</span>;<br>  &#125;<br><br>  array[count] = val;<br>  ++count;<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码实现了一个往数组中插入数据的功能</p><p>当数组满了之后，也就是代码中的 count == array.length 时，用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。</p><p><strong>最好情况时间复杂度:</strong>最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。</p><p><strong>最坏情况时间复杂度:</strong>最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。</p><p><strong>平均情况时间复杂度：</strong>假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：</p><img src="/article/undefined/%E6%95%B0%E7%BB%84%E4%B8%AD%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE.jpg" class title="数组中插入数据"></blockquote><p><strong>摊还分析法</strong>，通过摊还分析得到的时间复杂度我们起了一个名字，叫<strong>均摊时间复杂度</strong></p><blockquote><p>每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。</p></blockquote><p>对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，<strong>在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度</strong>。</p><p><strong>均摊时间复杂度就是一种特殊的平均时间复杂度</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/100017301?tab=catalog&quot;&gt;参考学习自·数据结构与算法之美&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事后统计法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种方法主要是通过
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
      <category term="复杂度分析" scheme="https://boyolo.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据结构与算法,复杂度分析" scheme="https://boyolo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Mysql45讲-实践（三）</title>
    <link href="https://boyolo.github.io/article/10821.html"/>
    <id>https://boyolo.github.io/article/10821.html</id>
    <published>2022-04-26T09:41:18.000Z</published>
    <updated>2022-05-13T02:31:50.511Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何判断一个数据库是不是出问题了？"><a href="#如何判断一个数据库是不是出问题了？" class="headerlink" title="如何判断一个数据库是不是出问题了？"></a>如何判断一个数据库是不是出问题了？</h2><h3 id="select-1-判断"><a href="#select-1-判断" class="headerlink" title="select 1 判断"></a>select 1 判断</h3><p>select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mysql">set global innodb_thread_concurrency=3;<br><br>CREATE TABLE `t` (<br>  `id` int(11) NOT NULL,<br>  `c` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`)<br>) ENGINE=InnoDB;<br><br>insert into t values(1,1)<br></code></pre></td></tr></table></figure><p><img src="/article/查询 blocked.png"><span class="image-caption">查询 blocked</span></p><p>设置 innodb_thread_concurrency 参数的目的是，控制 InnoDB 的并发线程上限。</p></blockquote><p>select 1 是能执行成功的，但是查询表 t 的语句会被堵住。</p><p>如果用 select 1 来检测实例是否正常的话，是检测不出问题的。</p><p>通常情况下，建议把 innodb_thread_concurrency 设置为 64~128 之间的值。</p><blockquote><p><strong>并发连接和并发查询</strong>，并不是同一个概念：</p><p>在 <code>show processlist</code> 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。</p><p>并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。</p><p><strong>在线程进入锁等待以后，并发线程的计数会减一</strong></p></blockquote><p>在这个例子中，同时在执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。</p><p>因此，我们使用 select 1 的判断逻辑要修改一下。</p><h3 id="查表判断"><a href="#查表判断" class="headerlink" title="查表判断"></a>查表判断</h3><p>为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from mysql.health_check; <br></code></pre></td></tr></table></figure><p>使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。</p><blockquote><p>问题：更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。</p><p>因此，我们还是把这条监控语句再改进一下。把查询语句改成更新语句。</p></blockquote><h3 id="更新判断"><a href="#更新判断" class="headerlink" title="更新判断"></a>更新判断</h3><p>既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; update mysql.health_check set t_modified=now();<br></code></pre></td></tr></table></figure><p>节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。</p><p>但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。</p><p>但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以，现在看来 mysql.health_check 这个表就不能只有一行数据了。</p><p><strong>为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; CREATE TABLE `health_check` (<br>  `id` int(11) NOT NULL,<br>  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,<br>  PRIMARY KEY (`id`)<br>) ENGINE=InnoDB;<br><br>/* 检测命令 */<br>insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();<br></code></pre></td></tr></table></figure><p>由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。</p><blockquote><p>问题：更新判断是一个相对比较常用的方案了，不过依然存在一些“判定慢”的问题。</p><p>涉及到的是服务器 IO 资源分配的问题</p><p>首先，所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。</p><p>IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO 资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。</p><p>检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。</p><p>也就是说，这时候在业务系统上正常的 SQL 语句已经执行得很慢了，但是 DBA 上去一看，HA 系统还在正常工作，并且认为主库现在处于可用状态。</p><p><strong>根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。</strong></p></blockquote><h3 id="内部统计"><a href="#内部统计" class="headerlink" title="内部统计"></a>内部统计</h3><p>在 MySQL 内部发现数据库问题的方法</p><p>MySQL 5.6 版本以后提供的 <code>performance_schema 库</code>，就在 <code>file_summary_by_event_name</code> 表里统计了每次 IO 请求的时间。</p><blockquote><p><code>event_name=&#39;wait/io/file/innodb/innodb_log_file’</code></p><p><img src="/article/performance_schema.file_summary_by_event_name 的一行.png"><span class="image-caption">performance_schema.file_summary_by_event_name 的一行</span></p><p>图中这一行表示统计的是 redo log 的写入时间，第一列 EVENT_NAME 表示统计的类型。</p><p>接下来的三组数据，显示的是 redo log 操作的时间统计。</p><p>第一组五列，是所有 IO 类型的统计。其中，COUNT_STAR 是所有 IO 的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀 SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。</p><p>第二组六列，是读操作的统计。最后一列 SUM_NUMBER_OF_BYTES_READ 统计的是，总共从 redo log 里读了多少个字节。</p><p>第三组六列，统计的是写操作。</p><p>最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对 fsync 的统计。</p><p>在 <code>performance_schema 库</code>的 <code>file_summary_by_event_name</code> 表里，binlog 对应的是 <code>event_name = &quot;wait/io/file/sql/binlog&quot;</code>这一行。各个字段的统计逻辑，与 redo log 的各个字段完全相同。</p><p>每一次操作数据库，performance_schema 都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗。如果打开所有的 performance_schema 项，性能大概会下降 10% 左右。</p><p><strong>建议只打开自己需要的项进行统计</strong></p><p>把这个信息用在实例状态诊断上：可以通过 MAX_TIMER 的值来判断数据库是否出问题了</p></blockquote><h2 id="误删数据后除了跑路，还能怎么办？"><a href="#误删数据后除了跑路，还能怎么办？" class="headerlink" title="误删数据后除了跑路，还能怎么办？"></a>误删数据后除了跑路，还能怎么办？</h2><p>对 MySQL 相关的误删数据，做下分类：</p><ol><li>使用 delete 语句误删数据行；</li><li>使用 drop table 或者 truncate table 语句误删数据表；</li><li>使用 drop database 语句误删数据库；</li><li>使用 rm 命令误删整个 MySQL 实例。</li></ol><h3 id="误删行"><a href="#误删行" class="headerlink" title="误删行"></a>误删行</h3><p>如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。</p><p>Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。</p><p><strong>需要确保 <code>binlog_format=row</code> 和 <code>binlog_row_image=FULL</code></strong></p><p>具体恢复数据时，对单个事务做如下处理：</p><ol><li>对于 insert 语句，对应的 binlog event 类型是 <code>Write_rows event</code>，把它改成 <code>Delete_rows event</code> 即可；</li><li>同理，对于 delete 语句，也是将 <code>Delete_rows event</code> 改为 <code>Write_rows event</code>；</li><li>而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。</li></ol><p>如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行</p><p><strong>不建议你直接在主库上执行这些操作</strong>:恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。</p><p><strong>更重要是要做到事前预防:</strong></p><ol><li><p>把 <code>sql_safe_updates</code> 参数设置为 <code>on</code>。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。</p><blockquote><p>如果你确定这个删除操作没问题的话，可以在 delete 语句中加上 where 条件，比如 where id&gt;=0。</p><p>但是，delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，你应该优先考虑使用 <code>truncate table</code> 或者 <code>drop table</code> 命令。</p><p>使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 <code>truncate /drop table</code> 和 <code>drop database</code> 命令删除的数据，就没办法通过 Flashback 来恢复了</p><p>因为，即使我们配置了 <code>binlog_format=row</code>，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate/drop 语句，这些信息是恢复不出数据的。</p></blockquote></li><li><p>代码上线前，必须经过 SQL 审计。</p></li></ol><h3 id="误删库-表"><a href="#误删库-表" class="headerlink" title="误删库 / 表"></a>误删库 / 表</h3><p>这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog。</p><blockquote><p>假如有人中午 12 点误删了一个库，恢复数据的流程如下：</p><ol><li>取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；</li><li>用备份恢复出一个临时库；</li><li>从日志备份里面，取出凌晨 0 点之后的日志；</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库。</li></ol><p><img src="/article/数据恢复流程 -mysqlbinlog 方法.png"><span class="image-caption">数据恢复流程 -mysqlbinlog 方法</span></p></blockquote><ol><li>为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个<code>–database</code> 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况。</li><li>在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：<ol><li>如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用<code>–stop-position</code> 参数执行到误操作之前的日志，然后再用<code>–start-position</code> 从误操作之后的日志继续执行；</li><li>如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 <code>set gtid_next=gtid1;begin;commit;</code> 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。</li></ol></li></ol><p><strong>使用 mysqlbinlog 方法恢复数据还是不够快</strong>，主要原因有两个：</p><ol><li>如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志；</li><li>用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。</li></ol><p><strong>一种加速的方法是</strong>，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：</p><ol><li>在 <code>start slave</code> 之前，先通过执行﻿﻿<code>change replication filter replicate_do_table = (tbl_name)</code> 命令，就可以让临时库只同步误操作的表；</li><li>这样做也可以用上并行复制技术，来加速整个数据恢复过程。</li></ol><p>不论是把 mysqlbinlog 工具解析出的 binlog 文件应用到临时库，还是把临时库接到备库上，这两个方案的共同点是：<strong>误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用 binlog 的方式。</strong></p><p>这两个方案都要求备份系统定期备份全量日志，而且需要确保 binlog 在被从本地删除之前已经做了备份。</p><h4 id="延迟复制备库"><a href="#延迟复制备库" class="headerlink" title="延迟复制备库"></a>延迟复制备库</h4><blockquote><p>虽然可以通过利用并行复制来加速恢复数据的过程，但是这个方案仍然存在“恢复时间不可控”的问题。</p><p>如果一个库的备份特别大，或者误操作的时间距离上一个全量备份的时间较长，比如一周一备的实例，在备份之后的第 6 天发生误操作，那就需要恢复 6 天的日志，这个恢复时间可能是要按天来计算的。</p></blockquote><p><strong>缩短恢复数据需要的时间:</strong></p><p>如果有非常核心的业务，不允许太长的恢复时间，我们可以考虑<strong>搭建延迟复制的备库</strong>。这个功能是 MySQL 5.6 版本引入的。</p><p>延迟复制的备库是一种特殊的备库，通过 <code>CHANGE MASTER TO MASTER_DELAY = N</code> 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。</p><h4 id="预防误删库-表的方法"><a href="#预防误删库-表的方法" class="headerlink" title="预防误删库 / 表的方法"></a>预防误删库 / 表的方法</h4><ol><li>账号分离，避免写错命令<ol><li>只给业务开发 DML 权限，而不给 truncate/drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。</li><li>即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</li></ol></li><li>制定操作规范，是避免写错要删除的表名<ol><li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。</li><li>改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。</li></ol></li></ol><h3 id="rm-删除数据"><a href="#rm-删除数据" class="headerlink" title="rm 删除数据"></a>rm 删除数据</h3><p>对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。</p><h2 id="为什么还有kill不掉的语句？"><a href="#为什么还有kill不掉的语句？" class="headerlink" title="为什么还有kill不掉的语句？"></a>为什么还有kill不掉的语句？</h2><p>在 MySQL 中有两个 kill 命令:</p><ol><li>kill query + 线程 id，表示终止这个线程中正在执行的语句；</li><li>kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。</li></ol><blockquote><p>问题：使用了 kill 命令，却没能断开这个连接。再执行 show processlist 命令，看到这条语句的 Command 列显示的是 Killed</p></blockquote><h3 id="收到-kill-以后，线程做什么？"><a href="#收到-kill-以后，线程做什么？" class="headerlink" title="收到 kill 以后，线程做什么？"></a>收到 kill 以后，线程做什么？</h3><p>kill 并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。</p><p>当用户执行 kill 时，MySQL 里处理 kill 命令的线程做了两件事：</p><ol><li>把运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；</li><li>给执行线程发一个信号。</li></ol><p>所以：</p><ol><li>一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD::KILL_QUERY，才开始进入语句终止逻辑；</li><li>如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；</li><li>语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。</li></ol><p>在执行 show processlist 的时候，有一个特别的逻辑：<strong>如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed</strong>。即使是客户端退出了，这个线程的状态仍然是在等待中。只有等到满足进入 InnoDB 的条件后，才有可能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION，再进入终止逻辑阶段。</p><p><strong>kill 无效：</strong></p><ol><li>线程没有执行到判断线程状态的逻辑</li><li>由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态</li><li>终止逻辑耗时较长<ol><li>超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。</li><li>大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。</li><li>DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。</li></ol></li></ol><h4 id="两个关于客户端的误解"><a href="#两个关于客户端的误解" class="headerlink" title="两个关于客户端的误解"></a>两个关于客户端的误解</h4><ol><li><p>如果库里面的表特别多，连接就会很慢</p><blockquote><p>当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作：</p><ol><li>执行 show databases；</li><li>切到库，执行 show tables；</li><li>把这两个命令的结果用于构建一个本地的哈希表。</li></ol></blockquote><p>在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。所以，当一个库中的表个数非常多的时候，这一步就会花比较长的时间。</p><p><strong>我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。</strong></p><blockquote><p>如果在连接命令中加上 <code>-A</code>，就可以关掉这个自动补全的功能，然后客户端就可以快速返回了。</p></blockquote></li><li><p><code>–quick</code> 引起误会的参数</p><p>加<code>–quick</code>(或者简写为 <code>-q</code>) 参数，也可以关掉这个自动补全的功能</p><p>设置了这个参数可能会降低服务端的性能</p><blockquote><p>MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：</p><ol><li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。</li><li>另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法。</li></ol><p>MySQL 客户端默认采用第一种方式，而如果加上–quick 参数，就会使用第二种不缓存的方式。</p></blockquote><p>采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。</p><p>使用<code>–quick</code>参数可以达到以下三点效果：</p><ol><li>第一点，就是前面提到的，跳过表名自动补全功能。</li><li>第二点，mysql_store_result 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能；</li><li>第三点，是不会把执行命令记录到本地的命令历史文件。</li></ol><p><code>–quick</code>参数的意思，是让客户端变得更快</p></li></ol><h2 id="我查这么多数据，会不会把数据库内存打爆？"><a href="#我查这么多数据，会不会把数据库内存打爆？" class="headerlink" title="我查这么多数据，会不会把数据库内存打爆？"></a>我查这么多数据，会不会把数据库内存打爆？</h2><h3 id="全表扫描对-server-层的影响"><a href="#全表扫描对-server-层的影响" class="headerlink" title="全表扫描对 server 层的影响"></a>全表扫描对 server 层的影响</h3><blockquote><p>假设，我们现在要对一个 200G 的 InnoDB 表 db1.t，执行一个全表扫描。当然，你要把扫描结果保存在客户端，会使用类似这样的命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql -h<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.982ex" height="2.343ex" style="vertical-align: -0.505ex;" viewbox="0 -791.3 3867.4 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">host -P</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"/><path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"/><path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/><path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-68" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-6F" x="576" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="1062" y="0"/> <use xlink:href="#E1-MJMATHI-74" x="1531" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="2115" y="0"/> <use xlink:href="#E1-MJMATHI-50" x="3115" y="0"/></g></svg>port -u<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.562ex" height="2.343ex" style="vertical-align: -0.671ex;" viewbox="0 -719.6 3686.4 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">user -p</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"/><path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"/><path stroke-width="1" id="E1-MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-75" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-73" x="572" y="0"/> <use xlink:href="#E1-MJMATHI-65" x="1042" y="0"/> <use xlink:href="#E1-MJMATHI-72" x="1508" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="2182" y="0"/> <use xlink:href="#E1-MJMATHI-70" x="3182" y="0"/></g></svg>pwd -e &quot;select * from db1.t&quot; &gt; $target_file<br></code></pre></td></tr></table></figure><p>InnoDB 的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表 t 的主键索引。这条查询语句由于没有其他的判断条件，所以查到的每一行都可以直接放到<strong>结果集</strong>里面，然后返回给客户端。</p><p>实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：</p><ol><li>获取一行，写到 net_buffer 中。这块内存的大小是由参数 <code>net_buffer_length</code> 定义的，默认是 16k。</li><li>重复获取行，直到 net_buffer 写满，调用网络接口发出去。</li><li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。</li><li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。</li></ol><img src="/article/undefined/%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.jpg" class title="查询结果发送流程"><ol><li>一个查询在发送过程中，占用的 MySQL 内部的内存最大就是 net_buffer_length 这么大，并不会达到 200G；</li><li>socket send buffer 也不可能达到 200G（默认定义 /proc/sys/net/core/wmem_default），如果 socket send buffer 被写满，就会暂停读数据的流程。</li></ol></blockquote><p>MySQL 是<strong>“边读边发的”</strong>。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。</p><p>对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。</p><h3 id="全表扫描对-InnoDB-的影响"><a href="#全表扫描对-InnoDB-的影响" class="headerlink" title="全表扫描对 InnoDB 的影响"></a>全表扫描对 InnoDB 的影响</h3><p>内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。</p><p>Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：<strong>内存命中率</strong>。</p><blockquote><p>可以在 <code>show engine innodb status</code> 结果中，查看一个系统当前的 BP 命中率。一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。</p></blockquote><p>InnoDB Buffer Pool 的大小是由参数 <code>innodb_buffer_pool_size</code> 确定的，一般建议设置成可用物理内存的 60%~80%。</p><p>InnoDB 内存管理用的是<strong>最近最少使用 (Least Recently Used, LRU) 算法</strong>，这个算法的核心就是淘汰最久未使用的数据。</p><blockquote><p><strong>基础的未改进的LRU算法</strong></p><p><img src="/article/基本 LRU 算法.jpg"><span class="image-caption">基本 LRU 算法</span></p><ol><li>在状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；</li><li>这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；</li><li>状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。</li><li>从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。</li></ol><hr><p><strong>问题：</strong>假设按照这个算法，我们要扫描一个 200G 的表，而这个表是一个历史数据表，平时没有业务访问它。那么，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。</p></blockquote><p><strong>InnoDB 对 LRU 算法做了改进</strong></p><blockquote><p><strong>改进的 LRU 算法</strong></p><p><img src="/article/改进的 LRU 算法.png"><span class="image-caption">改进的 LRU 算法</span></p><p>在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。</p><ol><li>图中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。</li><li>之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。</li><li>处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：<ol><li>若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；</li><li>如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 <code>innodb_old_blocks_time</code> 控制的。其默认值是 1000，单位毫秒。</li></ol></li></ol></blockquote><h2 id="到底可不可以使用join？"><a href="#到底可不可以使用join？" class="headerlink" title="到底可不可以使用join？"></a>到底可不可以使用join？</h2><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t2` (<br>  `id` int(11) NOT NULL,<br>  `a` int(11) DEFAULT NULL,<br>  `b` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  KEY `a` (`a`)<br>) ENGINE=InnoDB;<br><br>drop procedure idata;<br>delimiter ;;<br>create procedure idata()<br>begin<br>  declare i int;<br>  set i=1;<br>  while(i&lt;=1000)do<br>    insert into t2 values(i, i, i);<br>    set i=i+1;<br>  end while;<br>end;;<br>delimiter ;<br>call idata();<br><br>create table t1 like t2;<br>insert into t1 (select * from t2 where id&lt;=100)<br></code></pre></td></tr></table></figure><p>这两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引。存储过程 idata() 往表 t2 里插入了 1000 行数据，在表 t1 里插入的是 100 行数据。</p></blockquote><h3 id="Index-Nested-Loop-Join"><a href="#Index-Nested-Loop-Join" class="headerlink" title="Index Nested-Loop Join"></a>Index Nested-Loop Join</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from t1 straight_join t2 on (t1.a=t2.a);<br></code></pre></td></tr></table></figure><p>如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。</p><p>所以，为了便于分析执行过程中的性能问题，改用 <code>straight_join</code> 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。</p><p>执行流程：</p><ol><li>从表 t1 中读入一行数据 R；</li><li>从数据行 R 中，取出 a 字段到表 t2 里去查找；</li><li>取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；</li><li>重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。</li></ol><p>这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“<strong>Index Nested-Loop Join</strong>”，简称 NLJ。</p><p><img src="/article/Index Nested-Loop Join 算法的执行流程.jpg"><span class="image-caption">Index Nested-Loop Join 算法的执行流程</span></p><p>在这个流程里：</p><ol><li>对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；</li><li>而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；</li><li>所以，整个执行流程，总扫描行数是 200。</li></ol></blockquote><p><strong>使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；</strong></p><p><strong>如果使用 join 语句的话，需要让小表做驱动表（前提是“可以使用被驱动表的索引”）。</strong></p><h3 id="Simple-Nested-Loop-Join"><a href="#Simple-Nested-Loop-Join" class="headerlink" title="Simple Nested-Loop Join"></a>Simple Nested-Loop Join</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from t1 straight_join t2 on (t1.a=t2.b);<br></code></pre></td></tr></table></figure><p>由于表 t2 的字段 b 上没有索引，每次到 t2 去匹配的时候，就要做一次全表扫描。</p><p>由于表 t2 的字段 b 上没有索引，因此再用图 2 的执行流程时，每次到 t2 去匹配的时候，就要做一次全表扫描。</p><p>这样算来，这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100*1000=10 万行。</p></blockquote><h3 id="Block-Nested-Loop-Join"><a href="#Block-Nested-Loop-Join" class="headerlink" title="Block Nested-Loop Join"></a>Block Nested-Loop Join</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from t1 straight_join t2 on (t1.a=t2.b);<br></code></pre></td></tr></table></figure><p>被驱动表上没有可用的索引，算法的流程是这样的：</p><ol><li>把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；</li><li>扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。</li></ol><p><img src="/article/Block Nested-Loop Join 算法的执行流程.jpg"><span class="image-caption">Block Nested-Loop Join 算法的执行流程</span></p><p>在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次</p><p>如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从<strong>时间复杂度上来说，这两个算法是一样</strong>的。但是，<strong>Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好</strong>。</p></blockquote><p><strong>驱动表选择：</strong></p><p>假设小表的行数是 N，大表的行数是 M，那么在这个算法里：</p><ol><li>两个表都做一次全表扫描，所以总的扫描行数是 M+N；</li><li>内存中的判断次数是 M*N。</li></ol><p>可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候<strong>选择大表还是小表做驱动表，执行耗时是一样的。</strong></p><blockquote><p><strong>问题：要是表 t1 是一个大表，join_buffer 放不下怎么办呢？</strong></p><p>join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是<strong>分段放</strong>。</p><p>执行过程就变成了：</p><ol><li>扫描表 t1，顺序读取数据行放入 join_buffer 中，中途join_buffer 满了，继续第 2 步；</li><li>扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；</li><li>清空 join_buffer；</li><li>继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。</li></ol><p><img src="/article/Block Nested-Loop Join -- 两段.jpg"><span class="image-caption">Block Nested-Loop Join -- 两段</span></p></blockquote><p><strong>驱动表选择：</strong></p><p>假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。</p><p>注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1)。</p><p>所以，在这个算法的执行过程中：</p><ol><li>扫描行数是 N+λ<em>N</em>M；</li><li>内存判断 N*M 次。</li></ol><p><strong>应该让小表当驱动表。</strong></p><hr><blockquote><p><strong>Simple Nested Loop Join 的性能问题</strong></p><p>虽然 BNL 算法和 Simple Nested Loop Join 算法都是要判断 M*N 次（M 和 N 分别是 join 的两个表的行数），但是 Simple Nested Loop Join 算法的每轮判断都要走全表扫描，因此性能上 BNL 算法执行起来会快很多。</p><blockquote><p>BNL 算法的执行逻辑是：</p><ol><li>首先，将驱动表的数据全部读入内存 join_buffer 中，这里 join_buffer 是无序数组；</li><li>然后，顺序遍历被驱动表的所有行，每一行数据都跟 join_buffer 中的数据进行匹配，匹配成功则作为结果集的一部分返回。</li></ol></blockquote><blockquote><p>Simple Nested Loop Join 算法的执行逻辑是：</p><p>顺序取出驱动表中的每一行数据，到被驱动表去做全表扫描匹配，匹配成功则作为结果集的一部分返回。</p></blockquote><blockquote><p>MySQL 中索引结构和 Buffer Pool 的相关知识点：</p><ol><li><p>在对被驱动表做全表扫描的时候，如果数据没有在 Buffer Pool 中，就需要等待这部分数据从磁盘读入；</p><p>从磁盘读入数据到内存中，会影响正常业务的 Buffer Pool 命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到 Buffer Pool 的头部；</p></li><li><p>即使被驱动表数据都在内存中，每次查找“下一个记录的操作”，都是类似指针操作。而 join_buffer 中是数组，遍历的成本更低。</p></li></ol></blockquote><p><strong>所以说，BNL 算法的性能会更好</strong></p></blockquote><hr><h3 id="能不能使用-join-语句？"><a href="#能不能使用-join-语句？" class="headerlink" title="能不能使用 join 语句？"></a>能不能使用 join 语句？</h3><ol><li>如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；</li><li>如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。</li></ol><blockquote><p>所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。</p></blockquote><h3 id="如果要使用-join，应该选择大表做驱动表还是选择小表做驱动表？"><a href="#如果要使用-join，应该选择大表做驱动表还是选择小表做驱动表？" class="headerlink" title="如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？"></a>如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？</h3><ol><li>如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；</li><li>如果是 Block Nested-Loop Join 算法：<ol><li>在 join_buffer_size 足够大的时候，是一样的；</li><li>在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。</li></ol></li></ol><p><strong>在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。</strong></p><h2 id="join语句怎么优化？"><a href="#join语句怎么优化？" class="headerlink" title="join语句怎么优化？"></a>join语句怎么优化？</h2><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table t1(id int primary key, a int, b int, index(a));<br>create table t2 like t1;<br>drop procedure idata;<br>delimiter ;;<br>create procedure idata()<br>begin<br>  declare i int;<br>  set i=1;<br>  while(i&lt;=1000)do<br>    insert into t1 values(i, 1001-i, i);<br>    set i=i+1;<br>  end while;<br>  <br>  set i=1;<br>  while(i&lt;=1000000)do<br>    insert into t2 values(i, i, i);<br>    set i=i+1;<br>  end while;<br><br>end;;<br>delimiter ;<br>call idata();<br></code></pre></td></tr></table></figure><p>在表 t1 里，插入了 1000 行数据，每一行的 a=1001-id 的值。也就是说，表 t1 中字段 a 是逆序的。同时，在表 t2 中插入了 100 万行数据。</p></blockquote><h3 id="Multi-Range-Read-优化"><a href="#Multi-Range-Read-优化" class="headerlink" title="Multi-Range Read 优化"></a>Multi-Range Read 优化</h3><p><strong>Multi-Range Read 优化 (MRR)：这个优化的主要目的是尽量使用顺序读盘。</strong></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from t1 where a&gt;=1 and a&lt;=100;<br></code></pre></td></tr></table></figure><p>主键索引是一棵 B+ 树，在这棵树上，每次只能根据一个主键 id 查到一行数据。因此，回表肯定是一行行搜索主键索引的，基本流程如图所示</p><img src="/article/undefined/%E5%9F%BA%E6%9C%AC%E5%9B%9E%E8%A1%A8%E6%B5%81%E7%A8%8B.png" class title="基本回表流程"><p>如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。(a虽然是倒叙存放在表中，但a上有B+tree索引，是顺序存储的，但是a索引的叶子节点存放的id的值是倒叙的，a索引的范围查询通过id回表查询，b+tree索引都是顺序存储的，那么通过a索引获取到的ID是倒序的，不是按照索引顺序查询就变成了随机查询。)</p></blockquote><p><strong>因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</strong></p><blockquote><p>使用 MRR 优化，语句的执行流程变成了这样：</p><ol><li>根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;</li><li>将 read_rnd_buffer 中的 id 进行递增排序；</li><li>排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。</li></ol><p>read_rnd_buffer 的大小是由 <code>read_rnd_buffer_size</code> 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。</p></blockquote><p>如果你想要稳定地使用 MRR 优化的话，需要设置<code>set optimizer_switch=&quot;mrr_cost_based=off&quot;</code></p><p><strong>MRR 能够提升性能的核心</strong>在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p><h3 id="Batched-Key-Access"><a href="#Batched-Key-Access" class="headerlink" title="Batched Key Access"></a>Batched Key Access</h3><p>MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法。是对 NLJ 算法的优化。</p><blockquote><p>NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。</p></blockquote><blockquote><p>把表 t1 的数据取出来一部分，先放到一个临时内存(join_buffer)，<strong>复用 join_buffer 到 BKA 算法中</strong></p><p><img src="/article/Batched Key Access 流程.png"><span class="image-caption">Batched Key Access 流程</span></p></blockquote><p>如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">set optimizer_switch=&#x27;mrr=on,mrr_cost_based=off,batched_key_access=on&#x27;;<br></code></pre></td></tr></table></figure><p>前两个参数的作用是要启用 MRR</p><h3 id="BNL-算法的性能问题"><a href="#BNL-算法的性能问题" class="headerlink" title="BNL 算法的性能问题"></a>BNL 算法的性能问题</h3><p>大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。</p><p><strong>为了减少这种影响，你可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数</strong></p><p>BNL 算法对系统的影响主要包括三个方面：</p><ol><li>可能会多次扫描被驱动表，占用磁盘 IO 资源；</li><li>判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；</li><li>可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。</li></ol><p><strong>优化</strong>的常见做法是，给被驱动表的 join 字段加上索引，<strong>把 BNL 算法转成 BKA 算法</strong>。</p><p>让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>BKA 优化是 MySQL 已经内置支持的，建议你默认使用；</li><li>BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；</li><li>基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；</li><li>MySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。</li></ol><hr><blockquote><p><strong>问题：如果用 left join 的话，左边的表一定是驱动表吗？</strong></p><p><strong>问题：如果两个表的 join 包含多个条件的等值匹配，是都要写到 on 里面呢，还是只把一个条件写到 on 里面，其他条件写到 where 部分？</strong></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table a(f1 int, f2 int, index(f1))engine=innodb;<br>create table b(f1 int, f2 int)engine=innodb;<br>insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);<br>insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);<br></code></pre></td></tr></table></figure><p>表 a 和 b 都有两个字段 f1 和 f2，不同的是表 a 的字段 f1 上有索引。然后，往两个表中都插入了 6 条记录，其中在表 a 和 b 中同时存在的数据有 4 行。</p></blockquote><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/<br>select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/<br></code></pre></td></tr></table></figure><p>第二个问题的两种写法</p><p><img src="/article/两个 join 的查询结果.png"><span class="image-caption">两个 join 的查询结果</span></p><ol><li><p>语句 Q1 返回的数据集是 6 行，表 a 中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表 b 的各个字段值填成 NULL。</p><blockquote><p><img src="/article/Q1 的 explain 结果.jpg"><span class="image-caption">Q1 的 explain 结果</span></p><ol><li>驱动表是表 a，被驱动表是表 b；</li><li>由于表 b 的 f1 字段上没有索引，所以使用的是 Block Nested Loop Join（简称 BNL） 算法。</li></ol></blockquote><blockquote><p>这条语句的执行流程:</p><ol><li>把表 a 的内容读入 join_buffer 中。因为是 select * ，所以字段 f1 和 f2 都被放入 join_buffer 了。</li><li>顺序扫描表 b，对于每一行数据，判断 join 条件（也就是 (a.f1=b.f1) and (a.f1=1)）是否满足，满足条件的记录, 作为结果集的一行返回。如果语句中有 where 子句，需要先判断 where 部分满足条件后，再返回。</li><li>表 b 扫描完成后，对于没有被匹配的表 a 的行（在这个例子中就是 (1,1)、(2,2) 这两行），把剩余字段补上 NULL，再放入结果集中。</li></ol><p><img src="/article/left join -BNL 算法.jpg"><span class="image-caption">left join -BNL 算法</span></p></blockquote></li><li><p>语句 Q2 返回的是 4 行。从逻辑上可以这么理解，最后的两行，由于表 b 中没有匹配的字段，结果集里面 b.f2 的值是空，不满足 where 部分的条件判断，因此不能作为结果集的一部分。</p><blockquote><p><img src="/article/Q2 的 explain 结果.jpg"><span class="image-caption">Q2 的 explain 结果</span></p><ol><li>这条语句是以表 b 为驱动表的</li><li>如果一条 join 语句的 Extra 字段什么都没写的话，就表示使用的是 Index Nested-Loop Join（简称 NLJ）算法。</li></ol></blockquote><blockquote><p>语句 Q2 的执行流程:</p><ol><li>顺序扫描表 b，每一行用 b.f1 到表 a 中去查</li><li>匹配到记录后判断 a.f2=b.f2 是否满足，满足条件的话就作为结果集的一部分返回。</li></ol><p>语句 Q2 里面 where a.f2=b.f2 表示，查询结果里面不会包含 b.f2 是 NULL 的行，这样这个 left join 的语义就是“找到这两个表里面，f1、f2 对应相同的行。对于表 a 中存在，而表 b 中匹配不到的行，就放弃”。</p></blockquote><blockquote><p>这条语句虽然用的是 left join，但是语义跟 join 是一致的</p><p>因此，优化器就把这条语句的 left join 改写成了 join，然后因为表 a 的 f1 上有索引，就把表 b 作为驱动表，这样就可以用上 NLJ 算法。在执行 explain 之后，再执行 show warnings，就能看到这个改写的结果:</p><p><img src="/article/Q2 的改写结果.jpg"><span class="image-caption">Q2 的改写结果</span></p></blockquote><p>这个例子说明，即使我们在 SQL 语句中写成 left join，执行过程还是有可能不是从左到右连接的。也就是说，<strong>使用 left join 时，左边的表不一定是驱动表。</strong></p></li></ol></blockquote><p><strong>如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。</strong></p><p><strong>join 将判断条件是否全部放在 on 部分没有区别</strong></p></blockquote><h2 id="为什么临时表可以重名？"><a href="#为什么临时表可以重名？" class="headerlink" title="为什么临时表可以重名？"></a>为什么临时表可以重名？</h2><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create temporary table temp_t like t1;<br>alter table temp_t add index(b);<br>insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;<br>select * from t1 join temp_t on (t1.b=temp_t.b);<br></code></pre></td></tr></table></figure></blockquote><ol><li>内存表，指的是使用 Memory 引擎的表，建表语法是 <code>create table … engine=memory</code>。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。</li><li>临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。</li></ol><h3 id="临时表的特性"><a href="#临时表的特性" class="headerlink" title="临时表的特性"></a>临时表的特性</h3><p>临时表在使用上有以下几个特点：</p><ol><li>建表语法是 <code>create temporary table …</code>。</li><li>一个临时表只能被创建它的 session 访问，对其他线程不可见。由于临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。</li><li>临时表可以与普通表同名。</li><li>有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。</li><li>show tables 命令不显示临时表。</li></ol><blockquote><p>临时表就特别适合我们文章开头的 join 优化这种场景:</p><ol><li>不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</li><li>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。</li></ol></blockquote><h3 id="临时表的应用"><a href="#临时表的应用" class="headerlink" title="临时表的应用"></a>临时表的应用</h3><p>由于不用担心线程之间的重名冲突，临时表经常会被用在<strong>复杂查询的优化过程</strong>中。其中，分库分表系统的跨库查询就是一个典型的使用场景。</p><blockquote><p>一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。比如。将一个大表 ht，按照字段 f，拆分成 1024 个分表，然后分布到 32 个数据库实例上。如下图所示：</p><img src="/article/undefined/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AE%80%E5%9B%BE.jpg" class title="分库分表简图"><p>一般情况下，这种分库分表系统都有一个中间层 proxy。不过，也有一些方案会让客户端直接连接数据库，也就是没有 proxy 这一层。</p><p>在这个架构中，分区 key 的选择是以“减少跨库和跨表查询”为依据的。如果大部分的语句都会包含 f 的等值条件，那么就要用 f 做分区键。这样，在 proxy 这一层解析完 SQL 语句以后，就能确定将这条语句路由到哪个分表做查询。</p><p>比如下面这条语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select v from ht where f=N;<br></code></pre></td></tr></table></figure><p>这时，我们就可以通过分表规则（比如，N%1024) 来确认需要的数据被放在了哪个分表上。这种语句只需要访问一个分表，是分库分表方案最欢迎的语句形式了。</p><p>但是，如果这个表上还有另外一个索引 k，并且查询语句是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select v from ht where k &gt;= M order by t_modified desc limit 100;<br></code></pre></td></tr></table></figure><p>这时候，由于查询条件里面没有用到分区字段 f，只能到所有的分区中去查找满足条件的所有行，然后统一做 order by 的操作。这种情况下，有两种比较常用的思路。</p><p><strong>第一种思路是</strong>，在 proxy 层的进程代码中实现排序。</p><p>这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。不过，这个方案的缺点也比较明显：</p><ol><li>需要的开发工作量比较大。我们举例的这条语句还算是比较简单的，如果涉及到复杂的操作，比如 group by，甚至 join 这样的操作，对中间层的开发能力要求比较高；</li><li>对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题。</li></ol><p><strong>另一种思路就是</strong>，把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。</p><p>比如上面这条语句，执行流程可以类似这样：</p><ol><li><p>在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified；</p></li><li><p>在各个分库上执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select v,k,t_modified from ht_x where k &gt;= M order by t_modified desc limit 100;<br></code></pre></td></tr></table></figure></li><li><p>把分库执行的结果插入到 temp_ht 表中；</p></li><li><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select v from temp_ht order by t_modified desc limit 100;<br></code></pre></td></tr></table></figure></li><li><p>得到结果。</p></li></ol><img src="/article/undefined/%E8%B7%A8%E5%BA%93%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" class title="跨库查询流程示意图"><p>在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放到 32 个分库中的某一个上。</p></blockquote><h3 id="为什么临时表可以重名？-1"><a href="#为什么临时表可以重名？-1" class="headerlink" title="为什么临时表可以重名？"></a>为什么临时表可以重名？</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create temporary table temp_t(id int primary key)engine=innodb;<br></code></pre></td></tr></table></figure><p>这个语句的时候，MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。</p><p>这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程 id}<em>{线程 id}</em> 序列号”。你可以使用 <code>select @@tmpdir</code> 命令，来显示实例的临时文件目录</p></blockquote><p>而关于表中数据的存放方式，在不同的 MySQL 版本中有着不同的处理方式：</p><ol><li>在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；</li><li>而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。</li></ol><blockquote><p>从文件名的前缀规则，我们可以看到，其实创建一个叫作 t1 的 InnoDB 临时表，MySQL 在存储上认为我们创建的表名跟普通表 t1 是不同的，因此同一个库下面已经有普通表 t1 的情况下，还是可以再创建一个临时表 t1 的。</p></blockquote><p>MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。</p><ol><li>一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。</li><li>而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。</li></ol><p>在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 <code>“DROP TEMPORARY TABLE + 表名”</code>操作。</p><h3 id="临时表和主备复制"><a href="#临时表和主备复制" class="headerlink" title="临时表和主备复制"></a>临时表和主备复制</h3><p>binlog 中也记录了 <code>DROP TEMPORARY TABLE</code> 这条命令</p><p><strong>既然写 binlog，就意味着备库需要。</strong></p><p>如果当前的 <code>binlog_format=row</code>，那么跟临时表有关的语句，就不会记录到 binlog 里。也就是说，只在 <code>binlog_format=statment/mixed</code> 的时候，binlog 中才会记录临时表的操作。</p><p>这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 <code>DROP TEMPORARY TABLE</code> 传给备库执行。</p><hr><blockquote><p><strong>问题：主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？</strong></p><p>MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key。</p><p>由于 table_def_key 不同，所以这两个表在备库的应用线程里面是不会冲突的。</p></blockquote><hr><blockquote><p><strong>问题：为什么不能用 rename 修改临时表的改名。</strong></p><p>在实现上，执行 rename table 语句的时候，要求按照“库名 / 表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的 frm 文件是放在 tmpdir 目录下的，并且文件名的规则是“#sql{进程 id}<em>{线程 id}</em> 序列号.frm”，因此会报“找不到文件名”的错误。</p></blockquote><h2 id="什么时候会使用内部临时表？"><a href="#什么时候会使用内部临时表？" class="headerlink" title="什么时候会使用内部临时表？"></a>什么时候会使用内部临时表？</h2><h3 id="union-执行流程"><a href="#union-执行流程" class="headerlink" title="union 执行流程"></a>union 执行流程</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table t1(id int primary key, a int, b int, index(a));<br>delimiter ;;<br>create procedure idata()<br>begin<br>  declare i int;<br><br>  set i=1;<br>  while(i&lt;=1000)do<br>    insert into t1 values(i, i, i);<br>    set i=i+1;<br>  end while;<br>end;;<br>delimiter ;<br>call idata();<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">(select 1000 as f) union (select id from t1 order by id desc limit 2);<br></code></pre></td></tr></table></figure><p>这条语句用到了 union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。</p><p>下图是这个语句的 explain 结果:</p><p><img src="/article/union 语句 explain 结果.png"><span class="image-caption">union 语句 explain 结果</span></p><ol><li>第二行的 key=PRIMARY，说明第二个子句用到了索引 id。</li><li>第三行的 Extra 字段，表示在对子查询的结果集做 union 的时候，使用了临时表 (Using temporary)。</li></ol><p>这个语句的执行流程是这样的：</p><ol><li>创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。</li><li>执行第一个子查询，得到 1000 这个值，并存入临时表中。</li><li>执行第二个子查询：<ol><li>拿到第一行 id=1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；</li><li>取到第二行 id=999，插入临时表成功。</li></ol></li><li>从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000 和 999。</li></ol><p><img src="/article/union 执行流程.jpg"><span class="image-caption">union 执行流程</span></p><p>这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键 id 的唯一性约束，实现了 union 的语义。</p><blockquote><p>如果把上面这个语句中的 union 改成 union all 的话，就没有了“去重”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。</p></blockquote></blockquote><h3 id="group-by-执行流程"><a href="#group-by-执行流程" class="headerlink" title="group by 执行流程"></a>group by 执行流程</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select id%10 as m, count(*) as c from t1 group by m;<br></code></pre></td></tr></table></figure><p>这个语句的逻辑是把表 t1 里的数据，按照 id%10 进行分组统计，并按照 m 的结果排序后输出。它的 explain 结果如下：</p><p><img src="/article/group by 的 explain 结果.png"><span class="image-caption">group by 的 explain 结果</span></p><ol><li>Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表；</li><li>Using temporary，表示使用了临时表；</li><li>Using filesort，表示需要排序。</li></ol><p>这个语句的执行流程是这样的：</p><ol><li>创建内存临时表，表里有两个字段 m 和 c，主键是 m；</li><li>扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；<ol><li>如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);</li><li>如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；</li></ol></li><li>遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。</li></ol><p><img src="/article/group by 执行流程.jpg"><span class="image-caption">group by 执行流程</span></p><p>图中最后一步，对内存临时表的排序</p><img src="/article/undefined/%E5%86%85%E5%AD%98%E4%B8%B4%E6%97%B6%E8%A1%A8%E6%8E%92%E5%BA%8F%E6%B5%81%E7%A8%8B.jpg" class title="内存临时表排序流程"></blockquote><h3 id="group-by-优化方法-–-索引"><a href="#group-by-优化方法-–-索引" class="headerlink" title="group by 优化方法 – 索引"></a>group by 优化方法 – 索引</h3><p>group by 逻辑需要构造一个带唯一索引的表，执行代价是比较高的</p><blockquote><p>执行 group by 语句为什么需要临时表？</p><p>group by 的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的 id%100 的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。</p></blockquote><p>group by 优化方法 : 扫描过程中可以保证出现的数据是有序的</p><p><strong>InnoDB 的索引，就可以满足这个输入有序的条件</strong></p><blockquote><p>在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新。你可以用下面的方法创建一个列 z，然后在 z 列上创建一个索引（如果是 MySQL 5.6 及之前的版本，你也可以创建普通列和索引，来解决这个问题）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">alter table t1 add column z int generated always as(id % 100), add index(z);<br></code></pre></td></tr></table></figure><p>上面的 group by 语句就可以改成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select z, count(*) as c from t1 group by z;<br></code></pre></td></tr></table></figure><p>优化后的 group by 语句的 explain 结果，如下图所示：</p><p><img src="/article/group by 优化的 explain 结果.png"><span class="image-caption">group by 优化的 explain 结果</span></p></blockquote><h3 id="group-by-优化方法-–-直接排序"><a href="#group-by-优化方法-–-直接排序" class="headerlink" title="group by 优化方法 – 直接排序"></a>group by 优化方法 – 直接排序</h3><p>在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。</p><blockquote><p>MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;<br></code></pre></td></tr></table></figure><p>执行流程就是这样的：</p><ol><li>初始化 sort_buffer，确定放入一个整型字段，记为 m；</li><li>扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中；</li><li>扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）；</li><li>排序完成后，就得到了一个有序数组。</li></ol><p><img src="/article/使用 SQL_BIG_RESULT 的执行流程图.jpg"><span class="image-caption">使用 SQL_BIG_RESULT 的执行流程图</span></p><p><img src="/article/使用 SQL_BIG_RESULT 的 explain 结果.png"><span class="image-caption">使用 SQL_BIG_RESULT 的 explain 结果</span></p><p>从 Extra 字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。</p></blockquote><h3 id="group-by-使用的指导原则"><a href="#group-by-使用的指导原则" class="headerlink" title="group by 使用的指导原则"></a>group by 使用的指导原则</h3><ol><li>如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；</li><li>尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；</li><li>如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；</li><li>如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。</li></ol><h3 id="MySQL-什么时候会使用内部临时表？"><a href="#MySQL-什么时候会使用内部临时表？" class="headerlink" title="MySQL 什么时候会使用内部临时表？"></a>MySQL 什么时候会使用内部临时表？</h3><ol><li>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</li><li>join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；</li><li>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。</li></ol><hr><blockquote><p><strong>问题：如果只需要去重，不需要执行聚合函数，distinct 和 group by 哪种效率高一些呢？</strong></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select a from t group by a order by null;<br>select distinct a from t;<br></code></pre></td></tr></table></figure><p>表 t 的字段 a 上没有索引</p></blockquote><p><strong>不需要执行聚合函数时，distinct 和 group by 这两条语句的语义和执行流程是相同的，因此执行性能也相同。</strong></p><blockquote><p>这两条语句的执行流程是下面这样的:</p><ol><li>创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引；</li><li>遍历表 t，依次取数据插入临时表中：<ol><li>如果发现唯一键冲突，就跳过；</li><li>否则插入成功；</li></ol></li><li>遍历完成后，将临时表作为结果集返回给客户端。</li></ol></blockquote></blockquote><hr><h2 id="都说InnoDB好，那还要不要使用Memory引擎？"><a href="#都说InnoDB好，那还要不要使用Memory引擎？" class="headerlink" title="都说InnoDB好，那还要不要使用Memory引擎？"></a>都说InnoDB好，那还要不要使用Memory引擎？</h2><h3 id="内存表的数据组织结构"><a href="#内存表的数据组织结构" class="headerlink" title="内存表的数据组织结构"></a>内存表的数据组织结构</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create table t1(id int primary key, c int) engine=Memory;<br>create table t2(id int primary key, c int) engine=innodb;<br>insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);<br>insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);<br></code></pre></td></tr></table></figure><p>表 t1 使用 Memory 引擎， 表 t2 使用 InnoDB 引擎。</p><p>分别执行 select <em> from t1 和 select </em> from t2</p><p><img src="/article/两个查询结果 -0 的位置.png"><span class="image-caption">两个查询结果 -0 的位置</span></p><p>内存表 t1 的返回结果里面 0 在最后一行，而 InnoDB 表 t2 的返回结果里 0 在第一行。</p></blockquote><p><strong>InnoDB 引擎</strong>，它的主键索引 id 的组织方式：InnoDB 表的数据就放在<strong>主键索引树上</strong>，<strong>主键索引是 B+ 树</strong>。所以表 t2 的数据组织方式如下图所示：</p><p><img src="/article/表 t2 的数据组织.jpg"><span class="image-caption">表 t2 的数据组织</span></p><p><strong>主键索引上的值是有序存储的</strong></p><blockquote><p>在执行 select * 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。</p></blockquote><p><strong>Memory 引擎</strong>的数据和索引是分开的</p><blockquote><p><img src="/article/表 t1 的数据组织.jpg"><span class="image-caption">表 t1 的数据组织</span></p></blockquote><p>内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。<strong>主键 id 是 hash 索引</strong>，可以看到索引上的 key 并不是有序的。</p><blockquote><p>在内存表 t1 中，当执行 select * 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。</p></blockquote><p><strong>InnoDB 和 Memory 引擎的数据组织方式是不同的：</strong></p><ol><li>InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。</li><li>Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。</li></ol><p><strong>两个引擎的一些典型不同：</strong></p><ol><li>InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li><li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li><li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；</li><li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li><li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。</li></ol><h3 id="hash-索引和-B-Tree-索引"><a href="#hash-索引和-B-Tree-索引" class="headerlink" title="hash 索引和 B-Tree 索引"></a>hash 索引和 B-Tree 索引</h3><p><strong>内存表也是支持 B-Tree 索引的。</strong></p><blockquote><p>在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">alter table t1 add index a_btree_index using btree (id);<br></code></pre></td></tr></table></figure><p>表 t1 的数据组织形式就变成了这样：</p><p><img src="/article/表 t1 的数据组织 -- 增加 B-Tree 索引.jpg"><span class="image-caption">表 t1 的数据组织 -- 增加 B-Tree 索引</span></p><p><img src="/article/使用 B-Tree 和 hash 索引查询返回结果对比.png"><span class="image-caption">使用 B-Tree 和 hash 索引查询返回结果对比</span></p></blockquote><h3 id="为什么不建议生产环境上使用内存表"><a href="#为什么不建议生产环境上使用内存表" class="headerlink" title="为什么不建议生产环境上使用内存表?"></a>为什么不建议生产环境上使用内存表?</h3><ol><li><p>锁粒度问题；</p><p>内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。</p></li><li><p>数据持久化问题。</p><p>数据库重启的时候，所有的内存表都会被清空。</p><p>由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双 M 架构，还可能导致主库的内存表数据被删掉。</p></li></ol><p>内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：</p><ol><li>临时表不会被其他线程访问，没有并发性的问题；</li><li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li><li>备库的临时表也不会影响主库的用户线程。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何判断一个数据库是不是出问题了？&quot;&gt;&lt;a href=&quot;#如何判断一个数据库是不是出问题了？&quot; class=&quot;headerlink&quot; title=&quot;如何判断一个数据库是不是出问题了？&quot;&gt;&lt;/a&gt;如何判断一个数据库是不是出问题了？&lt;/h2&gt;&lt;h3 id=&quot;selec
      
    
    </summary>
    
      <category term="Mysql" scheme="https://boyolo.github.io/categories/Mysql/"/>
    
      <category term="面试" scheme="https://boyolo.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="实习,Mysql" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-Mysql/"/>
    
  </entry>
  
  <entry>
    <title>函数式编程</title>
    <link href="https://boyolo.github.io/article/62985.html"/>
    <id>https://boyolo.github.io/article/62985.html</id>
    <published>2022-04-25T02:34:35.000Z</published>
    <updated>2022-04-29T07:09:08.891Z</updated>
    
    <content type="html"><![CDATA[<p><strong>函数式编程关心数据的映射，命令式编程关心解决问题的步骤</strong></p><p>函数式编程是种编程方式，它将电脑运算视为函数的计算。函数编程语言最重要的基础是λ演算（lambda calculus），而且λ演算的函数可以接受函数当作输入（参数）和输出（返回值）。</p><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p>Lambda 表达式（lambda expression）是一个<a href="https://baike.baidu.com/item/匿名函数/4337265">匿名函数</a>，Lambda表达式基于数学中的<a href="https://baike.baidu.com/item/λ演算">λ演算</a>得名，直接对应于其中的lambda抽象（lambda abstraction），是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示<a href="https://baike.baidu.com/item/闭包/10908873">闭包</a>（注意和数学传统意义上的不同）。</p><p><strong>核心原则：可推导可省略</strong></p><p><strong>基本格式：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">(参数列表)-&gt;(代码)<br></code></pre></td></tr></table></figure><blockquote><p>实例一：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> <span class="hljs-keyword">new</span> Thread(<span class="hljs-keyword">new</span> Runnable() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">run</span><span class="hljs-params">()</span> </span>&#123;<br>        System.out.println(<span class="hljs-string">&quot;新线程中run方法被执行了&quot;</span>);<br>      &#125;     <br>    &#125;).start();<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>Lambda表达式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> <span class="hljs-keyword">new</span> Thread(() -&gt; System.out.println(<span class="hljs-string">&quot;新线程中run方法被执行了&quot;</span>)).start();<br>  &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p> 实例二：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.IntBinaryOperator;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> <span class="hljs-keyword">int</span> i = calculateNum(<span class="hljs-keyword">new</span> IntBinaryOperator() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">applyAsInt</span><span class="hljs-params">(<span class="hljs-keyword">int</span> left, <span class="hljs-keyword">int</span> right)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> left + right;<br>      &#125;<br>    &#125;);<br>    System.out.println(i);<br>   <br>   <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">calculateNum</span><span class="hljs-params">(IntBinaryOperator operator)</span> </span>&#123;<br> <span class="hljs-keyword">int</span> a = <span class="hljs-number">10</span>;<br>   <span class="hljs-keyword">int</span> b = <span class="hljs-number">20</span>;<br>    <span class="hljs-keyword">return</span> operator.applyAsInt(a, b);<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>Lambda表达式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.IntBinaryOperator;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br><span class="hljs-keyword">int</span> i = calculateNum((<span class="hljs-keyword">int</span> left, <span class="hljs-keyword">int</span> right) -&gt; &#123;<br>     <span class="hljs-keyword">return</span> left + right;<br>   &#125;);<br>    System.out.println(i);<br>   &#125;<br>   <br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">calculateNum</span><span class="hljs-params">(IntBinaryOperator operator)</span> </span>&#123;<br> <span class="hljs-keyword">int</span> a = <span class="hljs-number">10</span>;<br>   <span class="hljs-keyword">int</span> b = <span class="hljs-number">20</span>;<br>    <span class="hljs-keyword">return</span> operator.applyAsInt(a, b);<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>实例三：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> printNum(<span class="hljs-keyword">new</span> IntPredicate() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">test</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> value % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>;<br>      &#125;<br>    &#125;);<br>   &#125;<br>   <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printNum</span><span class="hljs-params">(IntPredicate predicate)</span> </span>&#123;<br>   <span class="hljs-keyword">int</span> arr[] = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>&#125;;<br>   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i : arr) &#123;<br>      <span class="hljs-keyword">if</span> (predicate.test(i)) &#123;<br>        System.out.println(i);<br>      &#125;<br>    &#125;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>Lambda表达式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>printNum((<span class="hljs-keyword">int</span> value) -&gt; &#123;<br>     <span class="hljs-keyword">return</span> value % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>;<br>   &#125;);<br>   &#125;<br>   <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printNum</span><span class="hljs-params">(IntPredicate predicate)</span> </span>&#123;<br>   <span class="hljs-keyword">int</span> arr[] = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>&#125;;<br>   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i : arr) &#123;<br>      <span class="hljs-keyword">if</span> (predicate.test(i)) &#123;<br>        System.out.println(i);<br>      &#125;<br>    &#125;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p> 实例四：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.Function;<br><span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> Integer integer = typeConver(<span class="hljs-keyword">new</span> Function&lt;String, Integer&gt;() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">apply</span><span class="hljs-params">(String s)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> Integer.valueOf(s);<br>      &#125;<br>    &#125;);<br>    System.out.println(integer);<br>   &#125;<br>   <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;R&gt; <span class="hljs-function">R <span class="hljs-title">typeConver</span><span class="hljs-params">(Function&lt;String,R&gt; function)</span></span>&#123;<br>   String str = <span class="hljs-string">&quot;1235&quot;</span>;<br>   R result = function.apply(str);<br>    <span class="hljs-keyword">return</span> result;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>Lambda表达式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.Function;<br><span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> Integer integer = typeConver((String s) -&gt; &#123;<br>     <span class="hljs-keyword">return</span> Integer.valueOf(s);<br>    &#125;);<br>    System.out.println(integer);<br>   &#125;<br>   <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;R&gt; <span class="hljs-function">R <span class="hljs-title">typeConver</span><span class="hljs-params">(Function&lt;String,R&gt; function)</span></span>&#123;<br>   String str = <span class="hljs-string">&quot;1235&quot;</span>;<br>   R result = function.apply(str);<br>    <span class="hljs-keyword">return</span> result;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p> 实例五：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.Function;<br><span class="hljs-keyword">import</span> java.util.function.IntConsumer;<br><span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> foreachArr(<span class="hljs-keyword">new</span> IntConsumer() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">accept</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>        System.out.println(value);<br>      &#125;<br>    &#125;);<br>   &#125;<br>   <br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">foreachArr</span><span class="hljs-params">(IntConsumer consumer)</span> </span>&#123;<br> <span class="hljs-keyword">int</span>[] arr = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>&#125;;<br>   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i :<br>         arr) &#123;<br>      consumer.accept(i);<br>    &#125;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure><p>Lambda表达式:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">&gt;<span class="hljs-keyword">import</span> java.util.function.Function;<br><span class="hljs-keyword">import</span> java.util.function.IntConsumer;<br><span class="hljs-keyword">import</span> java.util.function.IntPredicate;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LambdaDemo01</span> </span>&#123;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br> foreachArr(<span class="hljs-keyword">new</span> IntConsumer() &#123;<br>     <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">accept</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;<br>        System.out.println(value);<br>      &#125;<br>    &#125;);<br>   &#125;<br>   <br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">foreachArr</span><span class="hljs-params">(IntConsumer consumer)</span> </span>&#123;<br> <span class="hljs-keyword">int</span>[] arr = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>&#125;;<br>   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i :<br>         arr) &#123;<br>      consumer.accept(i);<br>    &#125;<br>   &#125;<br>   &#125;<br></code></pre></td></tr></table></figure></blockquote><p><strong>省略规则：</strong></p><ol><li>参数类型可以省略</li><li>方法体只有一句代码时打括号return和唯一一句代码的分号可以省略</li><li>方法体只有一个参数时小括号可以省略</li></ol><h2 id="Stream流"><a href="#Stream流" class="headerlink" title="Stream流"></a>Stream流</h2><ol><li>stream不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果；</li><li>stream不会改变数据源，通常情况下会产生一个新的集合；</li><li>stream具有延迟执行特性，只有调用终端操作时，中间操作才会执行。</li><li>对stream操作分为终端操作和中间操作，那么这两者分别代表什么呢？<ol><li>终端操作：会消费流，这种操作会产生一个结果的，如果一个流被消费过了，那它就不能被重用的。</li><li>中间操作：中间操作会产生另一个流。因此中间操作可以用来创建执行一系列动作的管道。一个特别需要注意的点是:中间操作不是立即发生的。相反，当在中间操作创建的新流上执行完终端操作后，中间操作指定的操作才会发生。所以中间操作是延迟发生的，中间操作的延迟行为主要是让流API能够更加高效地执行。</li></ol></li><li>stream不可复用，对一个已经进行过终端操作的流再次调用，会抛出异常。</li></ol><blockquote><p>实例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> lombok.AllArgsConstructor;<br><span class="hljs-keyword">import</span> lombok.Data;<br><span class="hljs-keyword">import</span> lombok.EqualsAndHashCode;<br><span class="hljs-keyword">import</span> lombok.NoArgsConstructor;<br><span class="hljs-meta">@Data</span><br><span class="hljs-meta">@AllArgsConstructor</span><br><span class="hljs-meta">@NoArgsConstructor</span><br><span class="hljs-meta">@EqualsAndHashCode</span><span class="hljs-comment">//用于后期的去重使用</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Book</span> </span>&#123;<br>  <span class="hljs-comment">//id</span><br>  <span class="hljs-keyword">private</span> Long id;<br>  <span class="hljs-comment">//书名</span><br>  <span class="hljs-keyword">private</span> String name;<br>  <span class="hljs-comment">//分类</span><br>  <span class="hljs-keyword">private</span> String category;<br>  <span class="hljs-comment">//评分</span><br>  <span class="hljs-keyword">private</span> Integer score;<br>  <span class="hljs-comment">//简介</span><br>  <span class="hljs-keyword">private</span> String intro;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> lombok.AllArgsConstructor;<br><span class="hljs-keyword">import</span> lombok.Data;<br><span class="hljs-keyword">import</span> lombok.EqualsAndHashCode;<br><span class="hljs-keyword">import</span> lombok.NoArgsConstructor;<br><span class="hljs-keyword">import</span> java.util.List;<br><span class="hljs-keyword">import</span> java.util.Objects;<br><span class="hljs-meta">@Data</span><br><span class="hljs-meta">@NoArgsConstructor</span><br><span class="hljs-meta">@AllArgsConstructor</span><br><span class="hljs-meta">@EqualsAndHashCode</span><span class="hljs-comment">//用于后期的去重使用</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Author</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Comparable</span>&lt;<span class="hljs-title">Author</span>&gt;</span>&#123;<br>  <span class="hljs-comment">//id</span><br>  <span class="hljs-keyword">private</span> Long id;<br>  <span class="hljs-comment">//姓名</span><br>  <span class="hljs-keyword">private</span> String name;<br>  <span class="hljs-comment">//年龄</span><br>  <span class="hljs-keyword">private</span> Integer age;<br>  <span class="hljs-comment">//简介</span><br>  <span class="hljs-keyword">private</span> String intro;<br>  <span class="hljs-comment">//作品</span><br>  <span class="hljs-keyword">private</span> List&lt;Book&gt; books;<br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compareTo</span><span class="hljs-params">(Author o)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> o.getAge()-<span class="hljs-keyword">this</span>.getAge();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.*;<br><span class="hljs-keyword">import</span> java.util.function.*;<br><span class="hljs-keyword">import</span> java.util.stream.Collectors;<br><span class="hljs-keyword">import</span> java.util.stream.Stream;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StreamDemo</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>    List&lt;Author&gt; authors = getAuthors();<br>    test01(authors);<br>  &#125;<br><br>  <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test01</span><span class="hljs-params">(List&lt;Author&gt; authors)</span> </span>&#123;<br>    <span class="hljs-comment">//把集合转换成流</span><br>    authors.stream()<br>      .distinct()<br>      .filter(author -&gt; &#123;<br>        System.out.println(<span class="hljs-string">&quot;test&quot;</span>);<br>        <span class="hljs-keyword">return</span> author.getAge() &lt; <span class="hljs-number">18</span>;<br>      &#125;)<br>      .forEach(author -&gt; System.out.println(author.getName()));<br>  &#125;<br>  <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> List&lt;Author&gt; <span class="hljs-title">getAuthors</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">//数据初始化</span><br>    Author author = <span class="hljs-keyword">new</span> Author(<span class="hljs-number">1L</span>,<span class="hljs-string">&quot;蒙多&quot;</span>,<span class="hljs-number">33</span>,<span class="hljs-string">&quot;一个从菜刀中明悟哲理的祖安人&quot;</span>,<span class="hljs-keyword">null</span>);<br>    Author author2 = <span class="hljs-keyword">new</span> Author(<span class="hljs-number">2L</span>,<span class="hljs-string">&quot;亚拉索&quot;</span>,<span class="hljs-number">15</span>,<span class="hljs-string">&quot;狂风也追逐不上他的思考速度&quot;</span>,<span class="hljs-keyword">null</span>);<br>    Author author3 = <span class="hljs-keyword">new</span> Author(<span class="hljs-number">3L</span>,<span class="hljs-string">&quot;易&quot;</span>,<span class="hljs-number">14</span>,<span class="hljs-string">&quot;是这个世界在限制他的思维&quot;</span>,<span class="hljs-keyword">null</span>);<br>    Author author4 = <span class="hljs-keyword">new</span> Author(<span class="hljs-number">3L</span>,<span class="hljs-string">&quot;易&quot;</span>,<span class="hljs-number">14</span>,<span class="hljs-string">&quot;是这个世界在限制他的思维&quot;</span>,<span class="hljs-keyword">null</span>);<br><br>    <span class="hljs-comment">//书籍列表</span><br>    List&lt;Book&gt; books1 = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    List&lt;Book&gt; books2 = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    List&lt;Book&gt; books3 = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br><br>    books1.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">1L</span>,<span class="hljs-string">&quot;刀的两侧是光明与黑暗&quot;</span>,<span class="hljs-string">&quot;哲学,爱情&quot;</span>,<span class="hljs-number">88</span>,<span class="hljs-string">&quot;用一把刀划分了爱恨&quot;</span>));<br>    books1.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">2L</span>,<span class="hljs-string">&quot;一个人不能死在同一把刀下&quot;</span>,<span class="hljs-string">&quot;个人成长,爱情&quot;</span>,<span class="hljs-number">99</span>,<span class="hljs-string">&quot;讲述如何从失败中明悟真理&quot;</span>));<br><br>    books2.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">3L</span>,<span class="hljs-string">&quot;那风吹不到的地方&quot;</span>,<span class="hljs-string">&quot;哲学&quot;</span>,<span class="hljs-number">85</span>,<span class="hljs-string">&quot;带你用思维去领略世界的尽头&quot;</span>));<br>    books2.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">3L</span>,<span class="hljs-string">&quot;那风吹不到的地方&quot;</span>,<span class="hljs-string">&quot;哲学&quot;</span>,<span class="hljs-number">85</span>,<span class="hljs-string">&quot;带你用思维去领略世界的尽头&quot;</span>));<br>    books2.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">4L</span>,<span class="hljs-string">&quot;吹或不吹&quot;</span>,<span class="hljs-string">&quot;爱情,个人传记&quot;</span>,<span class="hljs-number">56</span>,<span class="hljs-string">&quot;一个哲学家的恋爱观注定很难把他所在的时代理解&quot;</span>));<br><br>    books3.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">5L</span>,<span class="hljs-string">&quot;你的剑就是我的剑&quot;</span>,<span class="hljs-string">&quot;爱情&quot;</span>,<span class="hljs-number">56</span>,<span class="hljs-string">&quot;无法想象一个武者能对他的伴侣这么的宽容&quot;</span>));<br>    books3.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">6L</span>,<span class="hljs-string">&quot;风与剑&quot;</span>,<span class="hljs-string">&quot;个人传记&quot;</span>,<span class="hljs-number">100</span>,<span class="hljs-string">&quot;两个哲学家灵魂和肉体的碰撞会激起怎么样的火花呢？&quot;</span>));<br>    books3.add(<span class="hljs-keyword">new</span> Book(<span class="hljs-number">6L</span>,<span class="hljs-string">&quot;风与剑&quot;</span>,<span class="hljs-string">&quot;个人传记&quot;</span>,<span class="hljs-number">100</span>,<span class="hljs-string">&quot;两个哲学家灵魂和肉体的碰撞会激起怎么样的火花呢？&quot;</span>));<br><br>    author.setBooks(books1);<br>    author2.setBooks(books2);<br>    author3.setBooks(books3);<br>    author4.setBooks(books3);<br><br>    List&lt;Author&gt; authorList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;(Arrays.asList(author,author2,author3,author4));<br>    <span class="hljs-keyword">return</span> authorList;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><blockquote><ol><li><code>Sequence of elements（元素序列）</code>：简单来说，就是我们操作的集合中的所有元素</li><li><code>source（数据源）</code> ：Stream流的作用就是操作数据，那么source 就是为Stream提供可操作的<code>源数据</code>(一般，集合、数组或I/OI/O resources 都可以成为Stream的source )</li><li><code>Data processing operations（数据处理操作）</code>：上面菜单程序代码中出现的<strong>filter、sorted、map、collect</strong>，以及<strong>reduce、find、match</strong>等都属于Stream 的一些操作数据的方法接口。这些操作可以顺序进行，也可以并行执行。</li><li><code>Pipelining（管道、流水线）</code>：Stream对数据的操作类似数据库查询，也像电子厂的生产流线一样，Stream的每一个中间操作（后面解释什么是中间操作）比如上面的filter、sorted、map，每一步都会返回一个新的流，这些操作全部连起来就是想是一个工厂得生产流水线 ：<br><a href="https://img2020.cnblogs.com/blog/2026387/202011/2026387-20201126155856126-577400707.jpg"><img src="https://img2020.cnblogs.com/blog/2026387/202011/2026387-20201126155856126-577400707.jpg"><span class="image-caption">img</span></a></li><li><code>Internal iteration（内部迭代）</code>：Stream API 实现了对数据迭代的封装，不用你再像操作集合一样，手动写for循环显示迭代数据。</li></ol></blockquote><p><strong>Stream最主要的三组成部分</strong></p><ol><li>创建流，也就是Stream开始的地方，负责创建一个Stream实例</li><li>中间操作，主要是一些对数据的过滤筛选，添加删除等等操作，形成一个流程链。</li><li>收尾，也就是终端操作，我感觉更适合叫终结操作，终端操作会从流的流水线（中间操作）生成结果</li></ol><p><strong>Stream流的生命周期:</strong>同一个流只能遍历一次，遍历完后，这个流就已经被消费掉了。你如果还需要在遍历，可以从原始数据源那里再获得一个新的流来重新遍历一遍。</p><p><strong>Stream操作分类</strong></p><img src="/article/undefined/Stream%E6%93%8D%E4%BD%9C%E5%88%86%E7%B1%BB.png" class title="Stream操作分类"><p><strong>常用中间操作</strong></p><table><thead><tr><th style="text-align:center">操作</th><th style="text-align:center">类型</th><th style="text-align:center">返回类型</th><th style="text-align:center">操作参数</th><th style="text-align:center">函数描述符</th></tr></thead><tbody><tr><td style="text-align:center">filter</td><td style="text-align:center">中间</td><td style="text-align:center">Stream<T></T></td><td style="text-align:center">Predicate<T></T></td><td style="text-align:center">T-&gt;boolean</td></tr><tr><td style="text-align:center">map</td><td style="text-align:center">中间</td><td style="text-align:center">Stream<R></R></td><td style="text-align:center">Function&lt;T,R&gt;</td><td style="text-align:center">T-&gt;R</td></tr><tr><td style="text-align:center">limit</td><td style="text-align:center">中间</td><td style="text-align:center">Stream<T></T></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">sorted</td><td style="text-align:center">中间</td><td style="text-align:center">Stream<T></T></td><td style="text-align:center">Comparator<T></T></td><td style="text-align:center">(T,T)-&gt;int</td></tr><tr><td style="text-align:center">distinct</td><td style="text-align:center">中间</td><td style="text-align:center">Stream<T></T></td><td style="text-align:center"></td></tr></tbody></table><p><strong>常用终端操作</strong></p><table><thead><tr><th style="text-align:center">操作</th><th style="text-align:center">类型</th><th style="text-align:center">目的</th></tr></thead><tbody><tr><td style="text-align:center">forEach</td><td style="text-align:center">终端</td><td style="text-align:center">消费流中的每个元素并对其应用Lambda，返回void</td></tr><tr><td style="text-align:center">count</td><td style="text-align:center">终端</td><td style="text-align:center">返回流中元素的个数(long)</td></tr><tr><td style="text-align:center">collect</td><td style="text-align:center">终端</td><td style="text-align:center">把流归约成一个集合，如List、Map、Integer</td></tr></tbody></table><h3 id="流的常用创建方法"><a href="#流的常用创建方法" class="headerlink" title="流的常用创建方法"></a>流的常用创建方法</h3><ol><li><p>使用Collection下的 stream() 和 parallelStream() 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">List&lt;String&gt; list = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>Stream&lt;String&gt; stream = list.stream(); <span class="hljs-comment">//获取一个顺序流</span><br>Stream&lt;String&gt; parallelStream = list.parallelStream(); <span class="hljs-comment">//获取一个并行流</span><br></code></pre></td></tr></table></figure></li><li><p>使用Arrays 中的 stream() 方法，将数组转成流</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">Integer[] nums = <span class="hljs-keyword">new</span> Integer[<span class="hljs-number">10</span>];<br>Stream&lt;Integer&gt; stream = Arrays.stream(nums);<br></code></pre></td></tr></table></figure></li><li><p>使用Stream中的静态方法：of()、iterate()、generate()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java">Stream&lt;Integer&gt; stream = Stream.of(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>);<br> <br>Stream&lt;Integer&gt; stream2 = Stream.iterate(<span class="hljs-number">0</span>, (x) -&gt; x + <span class="hljs-number">2</span>).limit(<span class="hljs-number">6</span>);<br>stream2.forEach(System.out::println); <span class="hljs-comment">// 0 2 4 6 8 10</span><br> <br>Stream&lt;Double&gt; stream3 = Stream.generate(Math::random).limit(<span class="hljs-number">2</span>);<br>stream3.forEach(System.out::println);<br></code></pre></td></tr></table></figure></li><li><p>使用 BufferedReader.lines() 方法，将每行内容转成流</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">BufferedReader reader = <span class="hljs-keyword">new</span> BufferedReader(<span class="hljs-keyword">new</span> FileReader(<span class="hljs-string">&quot;F:\\test_stream.txt&quot;</span>));<br>Stream&lt;String&gt; lineStream = reader.lines();<br>lineStream.forEach(System.out::println);<br></code></pre></td></tr></table></figure></li><li><p>使用 Pattern.splitAsStream() 方法，将字符串分隔成流</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java">Pattern pattern = Pattern.compile(<span class="hljs-string">&quot;,&quot;</span>);<br>Stream&lt;String&gt; stringStream = pattern.splitAsStream(<span class="hljs-string">&quot;a,b,c,d&quot;</span>);<br>stringStream.forEach(System.out::println);<br></code></pre></td></tr></table></figure></li></ol><h3 id="流的中间操作"><a href="#流的中间操作" class="headerlink" title="流的中间操作"></a>流的中间操作</h3><ol><li><p>过滤通过 filter() 方法可以从流中筛选出我们想要的元素</p><p>distinct() 方法是一个中间操作（去重），它会返回一个新的流（没有共同元素）</p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test01</span><span class="hljs-params">(List&lt;Author&gt; authors)</span> </span>&#123;<br>  authors.stream()<span class="hljs-comment">//把集合转换成流</span><br>    .distinct()<br>    .filter(author -&gt; &#123;<br>      System.out.println(<span class="hljs-string">&quot;test&quot;</span>);<br>      <span class="hljs-keyword">return</span> author.getAge() &lt; <span class="hljs-number">18</span>;<br>    &#125;)<br>    .forEach(author -&gt; System.out.println(author.getName()));<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p>filter() 方法接收的是一个 Predicate（Java 8 新增的一个函数式接口，接受一个输入参数返回一个布尔值结果）类型的参数，因此，我们可以直接将一个 Lambda 表达式传递给该方法。</p></li></ol><ol start="2"><li><p>如果想通过某种操作把一个流中的元素转化成新的流中的元素，可以使用 map() 方法</p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test05</span><span class="hljs-params">()</span> </span>&#123;<br>  <span class="hljs-comment">//        打印所有作家的姓名</span><br>  List&lt;Author&gt; authors = getAuthors();<br><br>  authors.stream()<br>    .map(<span class="hljs-keyword">new</span> Function&lt;Author, String&gt;() &#123;<br>      <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">apply</span><span class="hljs-params">(Author author)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> author.getName();<br>      &#125;<br>    &#125;)<br>    .forEach(s -&gt; System.out.println(s));<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p>map() 方法接收的是一个 Function（Java 8 新增的一个函数式接口，接受一个输入参数 T，返回一个结果 R）类型的参数，此时参数 为 String 类的 length 方法，也就是把 Stream<Author> 的流转成一个 Stream<Integer> 的流。</Integer></Author></p></li></ol><ol start="3"><li><p>sorted() 方法按自然顺序排序</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test07</span><span class="hljs-params">()</span> </span>&#123;<br>  List&lt;Author&gt; authors = getAuthors();<br>  <span class="hljs-comment">//对流中的元素按照年龄进行降序排序，并且要求不能有重复的元素。</span><br>  authors.stream()<br>    .distinct()<br>    .sorted(<span class="hljs-keyword">new</span> Comparator&lt;Author&gt;() &#123;<br>      <span class="hljs-meta">@Override</span><br>      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compare</span><span class="hljs-params">(Author o1, Author o2)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> o2.getAge() - o1.getAge();<br>      &#125;<br>    &#125;)<br>    .forEach(author -&gt; System.out.println(author.getAge()));<br>&#125;<br></code></pre></td></tr></table></figure><p>返回由该流的元素组成的流，按自然顺序排序。如果此流的元素不是 Comparable，则在执行终端操作时可能会抛出 java.lang.ClassCastException。对于有序流，排序是稳定的。对于无序流，不保证稳定性。</p><p>(如果调用空参的 sorted() 方法，需要流中的元素是实现了 Comparable 接口)</p></li></ol><p><a href="https://zhuanlan.zhihu.com/p/339038230">https://zhuanlan.zhihu.com/p/339038230</a></p><p><a href="https://baijiahao.baidu.com/s?id=1662741032559775199&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1662741032559775199&amp;wfr=spider&amp;for=pc</a></p><p><a href="https://www.cnblogs.com/MrYuChen-Blog/p/14042801.html">https://www.cnblogs.com/MrYuChen-Blog/p/14042801.html</a></p><p><a href="https://blog.csdn.net/y_k_y/article/details/84633001?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&amp;utm_relevant_index=1">https://blog.csdn.net/y_k_y/article/details/84633001?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&amp;utm_relevant_index=1</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;函数式编程关心数据的映射，命令式编程关心解决问题的步骤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;函数式编程是种编程方式，它将电脑运算视为函数的计算。函数编程语言最重要的基础是λ演算（lambda calculus），而且λ演算的函数可以接受函数当作输入（参数）和输出
      
    
    </summary>
    
      <category term="Java" scheme="https://boyolo.github.io/categories/Java/"/>
    
      <category term="函数式编程" scheme="https://boyolo.github.io/categories/Java/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="函数式编程,Java" scheme="https://boyolo.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B-Java/"/>
    
  </entry>
  
  <entry>
    <title>Mysql45讲-实践（二）</title>
    <link href="https://boyolo.github.io/article/9788.html"/>
    <id>https://boyolo.github.io/article/9788.html</id>
    <published>2022-04-14T04:47:30.000Z</published>
    <updated>2022-04-25T16:28:56.672Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL有哪些“饮鸩止渴”提高性能的方法？"><a href="#MySQL有哪些“饮鸩止渴”提高性能的方法？" class="headerlink" title="MySQL有哪些“饮鸩止渴”提高性能的方法？"></a>MySQL有哪些“饮鸩止渴”提高性能的方法？</h2><p>业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。</p><h3 id="短连接风暴"><a href="#短连接风暴" class="headerlink" title="短连接风暴"></a>短连接风暴</h3><blockquote><p>正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。</p><p>如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。</p></blockquote><p>MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。</p><p><strong>短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。</strong></p><p><code>max_connections</code> 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。</p><blockquote><p>调高 max_connections 的值:</p><p>因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。</p></blockquote><ol><li><p>第一种方法：先处理掉那些占着连接但是不工作的线程。</p><p>对于那些不需要保持的连接，我们可以通过 kill connection 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。</p><p><strong>但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep 的线程，可能是有损的。</strong></p><p><strong>应该优先断开事务外空闲的连接。</strong></p><blockquote><p>看事务具体状态的话，你可以查 <code>information_schema</code> 库的 <code>innodb_trx</code> 表。</p><p><code>trx_mysql_thread_id=n</code>，表示 id=n 的线程还处在事务中。</p></blockquote><p>如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。</p><blockquote><p>从服务端断开连接使用的是 <code>kill connection + id</code> 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。</p></blockquote><p>从数据库端主动断开连接可能是<strong>有损的</strong>，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。</p></li><li><p>第二种方法：减少连接过程的消耗。</p><p>有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是<strong>让数据库跳过权限验证阶段</strong>。</p><p>跳过权限验证的方法是：重启数据库，并使用<code>–skip-grant-tables</code> 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。</p><p><strong>风险极高，特别不建议使用</strong></p></li></ol><h3 id="慢查询性能问题"><a href="#慢查询性能问题" class="headerlink" title="慢查询性能问题"></a>慢查询性能问题</h3><p>在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：</p><ol><li><p>索引没有设计好；</p><p>这种场景一般就是通过紧急创建索引来解决。</p><blockquote><p>MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。</p></blockquote><p>比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：</p><ol><li>在备库 B 上执行 <code>set sql_log_bin=off</code>，也就是不写 binlog，然后执行 alter table 语句加上索引；</li><li>执行主备切换；</li><li>这时候主库是 B，备库是 A。在 A 上执行 <code>set sql_log_bin=off</code>，然后执行 alter table 语句加上索引。</li></ol></li><li><p>SQL 语句没写好；</p><p>我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 <code>query_rewrite</code> 功能，可以把输入的一种语句改写成另外一种模式。</p></li><li><p>MySQL 选错了索引。</p><p>使用查询重写功能，给原来的语句加上 force index</p></li></ol><h3 id="预先发现问题"><a href="#预先发现问题" class="headerlink" title="预先发现问题"></a>预先发现问题</h3><ol><li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；</li><li>在测试表里插入模拟线上的数据，做一遍回归测试；</li><li>观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。</li></ol><h3 id="QPS-突增问题"><a href="#QPS-突增问题" class="headerlink" title="QPS 突增问题"></a>QPS 突增问题</h3><blockquote><p>有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。</p></blockquote><p>由一个新功能的 bug 导致的，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。</p><ol><li><p>一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。</p></li><li><p>如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。</p></li><li><p>如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成 <code>select 1</code> 返回。</p><p>副作用:</p><ol><li>如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；</li><li>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 <code>select 1</code> 的结果返回的话，可能会导致后面的业务逻辑一起失败。</li></ol><p><strong>风险极高，特别不建议使用</strong></p></li></ol><h2 id="MySQL是怎么保证数据不丢的？"><a href="#MySQL是怎么保证数据不丢的？" class="headerlink" title="MySQL是怎么保证数据不丢的？"></a>MySQL是怎么保证数据不丢的？</h2><p>只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。</p><h3 id="binlog-的写入机制"><a href="#binlog-的写入机制" class="headerlink" title="binlog 的写入机制"></a>binlog 的写入机制</h3><p>事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p><p><strong>一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入</strong></p><p><strong>binlog cache 的保存</strong>：</p><p>系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</p><p>事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。</p><p><img src="/article/binlog 写盘状态.png"><span class="image-caption">binlog 写盘状态</span></p><p>每个线程有自己 binlog cache，但是共用同一份 binlog 文件</p><ol><li>图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。</li><li>图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。</li></ol><blockquote><ol><li>sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；</li><li>sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；</li><li>sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。(对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。)</li></ol></blockquote><h3 id="redo-log-的写入机制"><a href="#redo-log-的写入机制" class="headerlink" title="redo log 的写入机制"></a>redo log 的写入机制</h3><p>事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。</p><ol><li><p>redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？</p><p>不需要</p><p>如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。</p></li><li><p>事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？</p><p>有可能</p><p><img src="/article/MySQL redo log 存储状态.png"><span class="image-caption">MySQL redo log 存储状态</span></p><ol><li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；</li><li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；</li><li>持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。</li></ol><blockquote><p>为了控制 redo log 的写入策略，InnoDB 提供了 <code>innodb_flush_log_at_trx_commit</code> 参数，它有三种可能取值：</p><ol><li>设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;</li><li>设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；</li><li>设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。</li></ol></blockquote><p>InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。</p><p><strong>注意</strong>，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。</p></li></ol><pre><code>实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。1. 一种是，redo log buffer 占用的空间即将达到 `innodb_log_buffer_size `**一半**的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。2. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 `innodb_flush_log_at_trx_commit` 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘&gt; 如果把 `innodb_flush_log_at_trx_commit` 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。&gt;&gt; 每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。</code></pre><p><strong>MySQL 的“双 1”配置</strong></p><p><code>sync_binlog</code> 和 <code>innodb_flush_log_at_trx_commit</code> 都设置成 1</p><p>一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。</p><h3 id="组提交（group-commit）机制"><a href="#组提交（group-commit）机制" class="headerlink" title="组提交（group commit）机制"></a>组提交（group commit）机制</h3><p><strong>日志逻辑序列号（log sequence number，LSN）</strong>:LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。</p><p>LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。</p><blockquote><p><img src="/article/redo log 组提交.png"><span class="image-caption">redo log 组提交</span></p><p>三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。</p><ol><li>trx1 是第一个到达的，会被选为这组的 leader；</li><li>等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；</li><li>trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；</li><li>这时候 trx2 和 trx3 就可以直接返回了。</li></ol></blockquote><p>一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。</p><p>但如果只有单线程压测，那就只能一个事务对应一次持久化操作。</p><blockquote><p>为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间</p><img src="/article/undefined/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%BB%86%E5%8C%96.png" class title="两阶段提交细化"><p>把 redo log 做 fsync 的时间拖到了步骤 1 之后</p><p>在执行第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。</p><p>不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。</p><p><strong>提升 binlog 组提交的效果:</strong></p><p>可以通过设置 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> 来实现。</p><ol><li><code>binlog_group_commit_sync_delay</code> 参数，表示延迟多少微秒后才调用 fsync;</li><li><code>binlog_group_commit_sync_no_delay_count</code> 参数，表示累积多少次以后才调用 fsync。</li></ol><p>只要有一个满足条件就会调用 fsync</p></blockquote><p>WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，磁盘读写次数为什么没变少？</p><p>WAL 机制主要得益于两个方面：</p><ol><li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li><li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li></ol><h3 id="IO性能瓶颈，提升性能"><a href="#IO性能瓶颈，提升性能" class="headerlink" title="IO性能瓶颈，提升性能"></a>IO性能瓶颈，提升性能</h3><ol><li>设置 <code>binlog_group_commit_sync_delay</code> 和 <code>binlog_group_commit_sync_no_delay_count</code> 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。</li><li>将 <code>sync_binlog</code> 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li><li>将 <code>innodb_flush_log_at_trx_commit</code> 设置为 2。这样做的风险是，主机掉电的时候会丢数据。(不建议把 <code>innodb_flush_log_at_trx_commit</code> 设置成 0,因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。)</li></ol><hr><p><strong>问题：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？</strong></p><blockquote><p>MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。</p><p>而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</p></blockquote><hr><h2 id="MySQL是怎么保证主备一致的？"><a href="#MySQL是怎么保证主备一致的？" class="headerlink" title="MySQL是怎么保证主备一致的？"></a>MySQL是怎么保证主备一致的？</h2><h3 id="MySQL-主备的基本原理"><a href="#MySQL-主备的基本原理" class="headerlink" title="MySQL 主备的基本原理"></a>MySQL 主备的基本原理</h3><p><strong>基本的主备切换流程</strong></p><p><img src="/article/MySQL 主备切换流程.png"><span class="image-caption">MySQL 主备切换流程</span></p><p>在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。</p><p>当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。</p><blockquote><p>在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：</p><ol><li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</li><li>防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；</li><li>可以用 readonly 状态，来判断节点的角色。</li></ol><p><strong>readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。</strong></p></blockquote><blockquote><p><strong>节点 A 到 B 这条线的内部流程是什么样的?</strong></p><p>一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图</p><img src="/article/undefined/%E4%B8%BB%E5%A4%87%E6%B5%81%E7%A8%8B%E5%9B%BE.png" class title="主备流程图"><p>主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog</p><p>备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：</p><ol><li>在备库 B 上通过 <code>change master</code> 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。</li><li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 <strong>io_thread</strong> 和 <strong>sql_thread</strong>。其中 io_thread 负责与主库建立连接。</li><li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。</li><li>备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。</li><li>sql_thread 读取中转日志，解析出日志里的命令，并执行。</li></ol></blockquote><h3 id="binlog-的三种格式对比"><a href="#binlog-的三种格式对比" class="headerlink" title="binlog 的三种格式对比"></a>binlog 的三种格式对比</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; CREATE TABLE `t` (<br>  `id` int(11) NOT NULL,<br>  `a` int(11) DEFAULT NULL,<br>  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,<br>  PRIMARY KEY (`id`),<br>  KEY `a` (`a`),<br>  KEY `t_modified`(`t_modified`)<br>) ENGINE=InnoDB;<br><br>insert into t values(1,1,&#x27;2018-11-13&#x27;);<br>insert into t values(2,2,&#x27;2018-11-12&#x27;);<br>insert into t values(3,3,&#x27;2018-11-11&#x27;);<br>insert into t values(4,4,&#x27;2018-11-10&#x27;);<br>insert into t values(5,5,&#x27;2018-11-09&#x27;);<br></code></pre></td></tr></table></figure></blockquote><p>在表中删除一行数据的话， delete 语句的 binlog 是怎么记录的?</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; delete from t /*comment*/  where a&gt;=4 and t_modified&lt;=&#x27;2018-11-10&#x27; limit 1;<br></code></pre></td></tr></table></figure><ol><li><p>当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文</p><blockquote><p>执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; show binlog events in &#x27;master.000001&#x27;;<br></code></pre></td></tr></table></figure><p>查看 binlog 中的内容</p><p><img src="/article/statement 格式 binlog 示例.png"><span class="image-caption">statement 格式 binlog 示例</span></p><ol><li>第一行 SET @@SESSION.GTID_NEXT=’ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；</li><li>第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；</li><li>第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。</li><li>最后一行是一个 COMMIT。（XID是用来联系bin log和redo log的。比如redo log里面有一个事务是prepare状态，但是不知道是不是commit状态，那就可以用XID去bin log里面查询该事务到底有没有提交。有提交则是commit状态，若没有提交则回滚该事务。）</li></ol></blockquote></li><li><p>当 binlog_format=row 时，binlog 里面记录的就是 事件</p><blockquote><p><img src="/article/row 格式 binlog 示例.png"><span class="image-caption">row 格式 binlog 示例</span></p><p>与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。</p><ol><li>Table_map event，用于说明接下来要操作的表是 test 库的表 t;</li><li>Delete_rows event，用于定义删除的行为。</li></ol><p>看不到详细信息需要借助 mysqlbinlog 工具，用命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysqlbinlog  -vv data/master.000001 --start-position=8900;<br></code></pre></td></tr></table></figure><p>解析和查看 binlog 中的内容</p><p><img src="/article/row 格式 binlog 示例的详细信息.png"><span class="image-caption">row 格式 binlog 示例的详细信息</span></p><ol><li>server id 1，表示这个事务是在 server_id=1 的这个库上执行的</li><li>每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32</li><li>Table_map event 显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。</li><li>我们在 mysqlbinlog 的命令中，使用了 <code>-vv</code> 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。</li><li>最后的 Xid event，用于表示事务被正确地提交了。</li></ol></blockquote></li><li><p>为什么会有 mixed 格式的 binlog？</p><ol><li>因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。</li><li>但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。</li><li>所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。</li></ol></li></ol><h3 id="循环复制问题"><a href="#循环复制问题" class="headerlink" title="循环复制问题"></a>循环复制问题</h3><p>实际生产上使用比较多的是双 M 结构</p><p><img src="/article/MySQL 主备切换流程 -- 双 M 结构.png"><span class="image-caption">MySQL 主备切换流程 -- 双 M 结构</span></p><p>节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。</p><p><strong>循环复制问题:</strong></p><blockquote><p>业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。</p><p>那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是<strong>循环复制</strong>了。</p></blockquote><p><strong>解决两个节点间的循环复制的问题：</strong></p><p>MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。</p><ol><li>规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；</li><li>一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；</li><li>每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。</li></ol><h2 id="MySQL是怎么保证高可用的？"><a href="#MySQL是怎么保证高可用的？" class="headerlink" title="MySQL是怎么保证高可用的？"></a>MySQL是怎么保证高可用的？</h2><p><img src="/article/MySQL 主备切换流程 -- 双 M 结构.png"><span class="image-caption">MySQL 主备切换流程 -- 双 M 结构</span></p><h3 id="主备延迟"><a href="#主备延迟" class="headerlink" title="主备延迟"></a>主备延迟</h3><blockquote><p> 与数据同步有关的时间点主要包括以下三个：</p><ol><li>主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;</li><li>之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;</li><li>备库 B 执行完成这个事务，我们把这个时刻记为 T3。</li></ol><p><strong>主备延迟</strong>，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">show slave status<br></code></pre></td></tr></table></figure><p>返回结果里面会显示 <code>seconds_behind_master</code>，用于表示当前备库延迟了多少秒</p><ol><li>每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；</li><li>备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。</li></ol></blockquote><p>主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。</p><h3 id="主备延迟的来源"><a href="#主备延迟的来源" class="headerlink" title="主备延迟的来源"></a>主备延迟的来源</h3><ol><li><p>有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。</p></li><li><p>备库的压力大</p><blockquote><p>因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。</p></blockquote><p>备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。</p><p><strong>处理</strong>:</p><ol><li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。</li><li>通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。</li></ol></li><li><p>大事务</p><blockquote><p>因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。</p></blockquote></li><li><p>备库的并行复制能力</p></li></ol><h3 id="可靠性优先策略"><a href="#可靠性优先策略" class="headerlink" title="可靠性优先策略"></a>可靠性优先策略</h3><blockquote><p>在双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：</p><ol><li>判断备库 B 现在的 <code>seconds_behind_master</code>，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li><li>把主库 A 改成只读状态，即把 readonly 设置为 true；</li><li>判断备库 B 的 <code>seconds_behind_master</code> 的值，直到这个值变成 0 为止；</li><li>把备库 B 改成可读写状态，也就是把 readonly 设置为 false；</li><li>把业务请求切到备库 B。</li></ol><p><img src="/article/MySQL 可靠性优先主备切换流程.png"><span class="image-caption">MySQL 可靠性优先主备切换流程</span></p><p>这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。</p></blockquote><h3 id="可用性优先策略"><a href="#可用性优先策略" class="headerlink" title="可用性优先策略"></a>可用性优先策略</h3><p>把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。</p><p>把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。</p><ol><li>使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。</li><li>主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，建议使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。</li></ol><h2 id="备库为什么会延迟好几个小时？"><a href="#备库为什么会延迟好几个小时？" class="headerlink" title="备库为什么会延迟好几个小时？"></a>备库为什么会延迟好几个小时？</h2><blockquote><img src="/article/undefined/%E4%B8%BB%E5%A4%87%E6%B5%81%E7%A8%8B%E5%9B%BE1.png" class title="主备流程图1"><p>一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。</p><p>如果用箭头的粗细来代表并行度的话，第一个箭头要明显粗于第二个箭头。</p><p>日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成<strong>主备延迟</strong>。</p></blockquote><blockquote><p>在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。</p></blockquote><p><strong>MySQL 多线程复制</strong></p><img src="/article/undefined/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" class title="多线程模型"><p>把只有一个线程的 sql_thread，拆成多个线程。</p><p>coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 <code>slave_parallel_workers</code> 决定的。</p><p>coordinator 在分发的时候，需要满足以下这两个基本要求：</p><ol><li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。</li><li>同一个事务不能被拆开，必须放到同一个 worker 中。</li></ol><h3 id="按表分发策略"><a href="#按表分发策略" class="headerlink" title="按表分发策略"></a>按表分发策略</h3><img src="/article/undefined/%E6%8C%89%E8%A1%A8%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%A8%8B%E6%A8%A1%E5%9E%8B.png" class title="按表并行复制程模型"><p>每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。<strong>hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。</strong></p><p>每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</p><ol><li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;</li><li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；</li><li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。</li></ol><p>问题：如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。</p><h3 id="按行分发策略"><a href="#按行分发策略" class="headerlink" title="按行分发策略"></a>按行分发策略</h3><p>要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。</p><p><strong>这个模式要求 binlog 格式必须是 row。</strong></p><p>基于行的策略，事务 hash 表中还需要考虑唯一键，即 <strong>key 应该是“库名 + 表名 + 索引名 + 该索引的值”。</strong></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t1` (<br>  `id` int(11) NOT NULL,<br>  `a` int(11) DEFAULT NULL,<br>  `b` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  UNIQUE KEY `a` (`a`)<br>) ENGINE=InnoDB;<br><br>insert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);<br></code></pre></td></tr></table></figure><img src="/article/undefined/%E5%94%AF%E4%B8%80%E9%94%AE%E5%86%B2%E7%AA%81%E7%A4%BA%E4%BE%8B.png" class title="唯一键冲突示例"><ol><li>key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。</li><li>key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。</li><li>key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。</li></ol></blockquote><p><strong>相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。</strong></p><p>这两个方案其实都有一些约束条件：</p><ol><li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；</li><li>表必须有主键；不能有外键。</li><li>表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。</li></ol><h3 id="MySQL-5-6-版本的并行复制策略"><a href="#MySQL-5-6-版本的并行复制策略" class="headerlink" title="MySQL 5.6 版本的并行复制策略"></a>MySQL 5.6 版本的并行复制策略</h3><p><strong>用于决定分发策略的 hash 表里，key 就是数据库名。</strong></p><p>相比于按表和按行分发，这个策略有两个优势：</p><ol><li>构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。</li><li>不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。</li></ol><h3 id="MariaDB-的并行复制策略"><a href="#MariaDB-的并行复制策略" class="headerlink" title="MariaDB 的并行复制策略"></a>MariaDB 的并行复制策略</h3><ol><li>在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；</li><li>commit_id 直接写到 binlog 里面；</li><li>传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；</li><li>这一组全部执行完成后，coordinator 再去取下一批。</li></ol><p>这个方案很容易被大事务拖后腿</p><h3 id="MySQL-5-7-的并行复制策略"><a href="#MySQL-5-7-的并行复制策略" class="headerlink" title="MySQL 5.7 的并行复制策略"></a>MySQL 5.7 的并行复制策略</h3><p>由参数 <code>slave-parallel-type</code> 来控制并行复制策略：</p><ol><li>配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；</li><li>配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略</li></ol><p>MySQL 5.7 并行复制策略的思想是：</p><ol><li>同时处于 prepare 状态的事务，在备库执行时是可以并行的；</li><li>处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。</li></ol><h3 id="MySQL-5-7-22-的并行复制策略"><a href="#MySQL-5-7-22-的并行复制策略" class="headerlink" title="MySQL 5.7.22 的并行复制策略"></a>MySQL 5.7.22 的并行复制策略</h3><p>基于 WRITESET 的并行复制</p><p>新增了一个参数 <code>binlog-transaction-dependency-tracking</code>，用来控制是否启用这个新策略。参数的可选值有以下三种：</p><ol><li><code>COMMIT_ORDER</code>，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。</li><li><code>WRITESET</code>，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。(hash 值是通过“库名 + 表名 + 索引名 + 值”计算)</li><li><code>WRITESET_SESSION</code>，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li></ol><p><strong>优势:</strong></p><ol><li>writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；</li><li>不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；</li><li>由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。</li></ol><p><strong>约束：</strong></p><p>对于“表上没主键”和“外键约束”的场景，WRITESET 策略是没法并行的，也会暂时退化为单线程模型。</p><h2 id="主库出问题了，从库怎么办？"><a href="#主库出问题了，从库怎么办？" class="headerlink" title="主库出问题了，从库怎么办？"></a>主库出问题了，从库怎么办？</h2><blockquote><img src="/article/undefined/%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84.png" class title="一主多从基本结构"><p>虚线箭头表示的是主备关系，也就是 A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。</p></blockquote><blockquote><p>主库发生故障，主备切换后的结果</p><p><img src="/article/一主多从基本结构 -- 主备切换.png"><span class="image-caption">一主多从基本结构 -- 主备切换</span></p><p>一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。正是由于多了从库 B、C、D 重新指向的这个过程，所以主备切换的复杂性也相应增加了。</p></blockquote><h3 id="基于位点的主备切换"><a href="#基于位点的主备切换" class="headerlink" title="基于位点的主备切换"></a>基于位点的主备切换</h3><blockquote><p>当把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CHANGE MASTER TO <br>MASTER_HOST=$host_name <br>MASTER_PORT=$port <br>MASTER_USER=$user_name <br>MASTER_PASSWORD=$password <br>MASTER_LOG_FILE=$master_log_name <br>MASTER_LOG_POS=$master_log_pos  <br></code></pre></td></tr></table></figure><ol><li>MASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。</li><li>参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。</li></ol></blockquote><p><strong>同步位点</strong></p><p>节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志<strong>，A 的位点和 A’的位点是不同的</strong>。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。</p><p>考虑到切换过程中不能丢数据，所以总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。</p><p><strong>主动跳过错误</strong></p><p>在进行主从切换时，由于同步位点找的并不是很精确，就会出现如 主键冲突，停止同步 的错误</p><p>通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法</p><ol><li><p>主动跳过一个事务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">set global sql_slave_skip_counter=1;<br>start slave;<br></code></pre></td></tr></table></figure><p>因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。</p></li><li><p>通过设置 <code>slave_skip_errors</code> 参数，直接设置跳过指定的错误</p><p>在执行主备切换时，有这么两类错误，是经常会遇到的：</p><ol><li>1062 错误是插入数据时唯一键冲突；</li><li>1032 错误是删除数据时找不到行。</li></ol><p>可以把 <code>slave_skip_errors</code> 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过</p><p>这种直接跳过指定错误的方法，<strong>针对</strong>的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。</p></li></ol><h3 id="GTID"><a href="#GTID" class="headerlink" title="GTID"></a>GTID</h3><p>MySQL 5.6 版本引入了 GTID</p><p>GTID 的全称是 <em>Global Transaction Identifier</em>，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">GTID=server_uuid:gno<br></code></pre></td></tr></table></figure><ul><li>server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；</li><li>gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。</li></ul><p>GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 <code>gtid_mode=on</code> 和 <code>enforce_gtid_consistency=on</code></p><p>在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 <code>gtid_next</code> 的值。</p><ol><li><p>如果 <code>gtid_next=automatic</code>，代表使用默认值。这时，MySQL 就会把 <code>server_uuid:gno</code> 分配给这个事务。</p><ol><li><p>记录 binlog 的时候，先记录一行 SET </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">@@SESSION.GTID_NEXT=‘server_uuid:gno’;<br></code></pre></td></tr></table></figure></li><li><p>把这个 GTID 加入本实例的 GTID 集合。</p></li></ol></li><li><p>如果 gtid_next 是一个指定的 GTID 的值，比如通过 set <code>gtid_next=&#39;current_gtid’</code> 指定为 current_gtid，那么就有两种可能：</p><ol><li>如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；</li><li>如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。</li></ol></li></ol><p>一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。</p><h3 id="基于-GTID-的主备切换"><a href="#基于-GTID-的主备切换" class="headerlink" title="基于 GTID 的主备切换"></a>基于 GTID 的主备切换</h3><p>在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs MYSQL">CHANGE MASTER TO <br>MASTER_HOST=$host_name <br>MASTER_PORT=$port <br>MASTER_USER=$user_name <br>MASTER_PASSWORD=$password <br>master_auto_position=1 <br></code></pre></td></tr></table></figure><p><code>master_auto_position=1</code> 就表示这个主备关系使用的是 GTID 协议。</p><blockquote><p>实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。</p><p>我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：</p><ol><li>实例 B 指定主库 A’，基于主备协议建立连接。</li><li>实例 B 把 set_b 发给主库 A’。</li><li>实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。<ol><li>如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；</li><li>如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；</li></ol></li><li>之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。</li></ol></blockquote><p>在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。</p><h2 id="读写分离有哪些坑？"><a href="#读写分离有哪些坑？" class="headerlink" title="读写分离有哪些坑？"></a>读写分离有哪些坑？</h2><blockquote><p><strong>读写分离基本结构</strong></p><img src="/article/undefined/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84.png" class title="读写分离基本结构"><p><strong>带 proxy 的读写分离架构</strong></p><p><img src="/article/带 proxy 的读写分离架构.jpg"><span class="image-caption">带 proxy 的读写分离架构</span></p></blockquote><ol><li>客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。</li><li>带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。</li></ol><p><strong>过期读问题：</strong>由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。</p><p><strong>处理过期读的方案：</strong></p><ol><li>强制走主库方案；</li><li>sleep 方案；</li><li>判断主备无延迟方案；</li><li>配合 semi-sync 方案；</li><li>等主库位点方案；</li><li>等 GTID 方案。</li></ol><h3 id="强制走主库方案"><a href="#强制走主库方案" class="headerlink" title="强制走主库方案"></a>强制走主库方案</h3><p>强制走主库方案其实就是，将查询请求做分类</p><ol><li>对于必须要拿到最新结果的请求，强制将其发到主库上。</li><li>对于可以读到旧数据的请求，才将其发到从库上。</li></ol><h3 id="Sleep-方案"><a href="#Sleep-方案" class="headerlink" title="Sleep 方案"></a>Sleep 方案</h3><p>主库更新后，读从库之前先 sleep 一下。</p><blockquote><p>假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。</p></blockquote><h3 id="判断主备无延迟方案"><a href="#判断主备无延迟方案" class="headerlink" title="判断主备无延迟方案"></a>判断主备无延迟方案</h3><p><code>show slave status</code> 结果里的 <code>seconds_behind_master</code> 参数的值，可以用来衡量主备延迟时间的长短。</p><ol><li><p>每次从库执行查询请求前，先判断 <code>seconds_behind_master</code> 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。</p></li><li><p>对比位点确保主备无延迟</p><ol><li><code>Master_Log_File</code> 和 <code>Read_Master_Log_Pos</code>，表示的是读到的主库的最新位点；</li><li><code>Relay_Master_Log_File</code> 和 <code>Exec_Master_Log_Pos</code>，表示的是备库执行的最新位点。</li></ol><p>如果 <code>Master_Log_File</code> 和 <code>Relay_Master_Log_File</code>、<code>Read_Master_Log_Pos</code> 和 <code>Exec_Master_Log_Pos</code> 这两组值完全相同，就表示接收到的日志已经同步完成。</p></li><li><p>对比 GTID 集合确保主备无延迟</p><ol><li>Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。</li><li>Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；</li><li>Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。</li></ol><p>如果这两个集合相同，也表示备库接收到的日志都已经同步完成。</p><blockquote><p>问题：有时，binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p></blockquote></li></ol><h3 id="配合-semi-sync"><a href="#配合-semi-sync" class="headerlink" title="配合 semi-sync"></a>配合 semi-sync</h3><p>semi-sync 引入半同步复制，也就是 <strong>semi-sync replication</strong></p><ol><li>事务提交的时候，主库把 binlog 发给从库；</li><li>从库收到 binlog 以后，发回给主库一个 ack，表示收到了；</li><li>主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。</li></ol><p>如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。</p><p><strong>semi-sync+ 位点判断的方案，只对一主一备的场景是成立的</strong>，在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。这时，在从库上执行查询请求，就有两种情况：</p><ol><li>如果查询是落在这个响应了 ack 的从库上，是能够确保读到最新数据；</li><li>但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</li></ol><p>semi-sync 配合判断主备无延迟的方案，存在两个问题：</p><ol><li>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</li><li>在持续延迟的情况下，可能出现过度等待的问题。</li></ol><h3 id="等主库位点方案"><a href="#等主库位点方案" class="headerlink" title="等主库位点方案"></a>等主库位点方案</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select master_pos_wait(file, pos[, timeout]);<br></code></pre></td></tr></table></figure><ol><li>它是在从库执行的；</li><li>参数 file 和 pos 指的是主库上的文件名和位置；</li><li>timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。</li></ol><p>这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。</p><p>除了正常返回一个正整数 M 外，这条命令还会返回一些其他结果，包括：</p><ol><li>如果执行期间，备库同步线程发生异常，则返回 NULL；</li><li>如果等待超过 N 秒，就返回 -1；</li><li>如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。</li></ol></blockquote><h3 id="GTID-方案"><a href="#GTID-方案" class="headerlink" title="GTID 方案"></a>GTID 方案</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select wait_for_executed_gtid_set(gtid_set, 1);<br></code></pre></td></tr></table></figure><ol><li>等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；</li><li>超时返回 1。</li></ol></blockquote><p>在前面等位点的方案中，我们执行完事务后，还要主动去主库执行 show master status。而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。</p><p><strong>让 MySQL 在执行事务后，返回包中带上 GTID</strong></p><p>需要将参数 <code>session_track_gtids</code> 设置为 OWN_GTID，然后通过 API 接口 <code>mysql_session_track_get_first</code> 从返回包解析出 GTID 的值即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;MySQL有哪些“饮鸩止渴”提高性能的方法？&quot;&gt;&lt;a href=&quot;#MySQL有哪些“饮鸩止渴”提高性能的方法？&quot; class=&quot;headerlink&quot; title=&quot;MySQL有哪些“饮鸩止渴”提高性能的方法？&quot;&gt;&lt;/a&gt;MySQL有哪些“饮鸩止渴”提高性能的方
      
    
    </summary>
    
      <category term="Mysql" scheme="https://boyolo.github.io/categories/Mysql/"/>
    
      <category term="面试" scheme="https://boyolo.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="实习,Mysql" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-Mysql/"/>
    
  </entry>
  
  <entry>
    <title>SpringSecurity</title>
    <link href="https://boyolo.github.io/article/52913.html"/>
    <id>https://boyolo.github.io/article/52913.html</id>
    <published>2022-04-04T01:18:58.000Z</published>
    <updated>2022-04-12T08:05:52.609Z</updated>
    
    <content type="html"><![CDATA[<p>学习源于<a href="https://www.bilibili.com/video/BV1mm4y1X7Hc?p=8&amp;spm_id_from=pageDriver">三更草堂</a></p><h2 id="SpringSecurity"><a href="#SpringSecurity" class="headerlink" title="SpringSecurity"></a>SpringSecurity</h2><p>Spring Security是一个功能强大且高度可定制的身份验证和访问控制框架。这是保护基于Spring的应用程序的事实上的标准。</p><p>Spring Security是一个专注于为Java应用程序提供身份验证和授权的框架。像所有Spring项目一样，Spring Security的真正力量在于它有多容易被扩展以满足自定义要求。</p><p><strong>认证：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户</strong></p><p><strong>授权：经过认证后判断当前用户是否有权限进行某个操作</strong></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p><code>pom.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.5.6<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.projectlombok<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>lombok<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">optional</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">optional</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p><strong>基础项目</strong></p><p><code>SecurityApplication.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.boyolo;<br><span class="hljs-keyword">import</span> org.springframework.boot.SpringApplication;<br><span class="hljs-keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;<br><br><span class="hljs-meta">@SpringBootApplication</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SecurityApplication</span> </span>&#123;<br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>    SpringApplication.run(SecurityApplication.class, args);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>HelloController.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.boyolo.controller;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.annotation.RestController;<br><br><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HelloController</span> </span>&#123;<br>  <span class="hljs-meta">@RequestMapping(&quot;/hello&quot;)</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">helloController</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;hello&quot;</span>;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>测试</strong></p><p>访问 <code>http://localhost:8080/hello</code></p><p>跳转页面</p><img src="/article/52913/SpringSecurity%E5%85%A5%E9%97%A8.png" class title="image-20220404100727005"><p>默认用户名：user</p><p>默认密码：后台运行复制</p><h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><img src="/article/52913/%E7%99%BB%E5%BD%95%E6%A0%A1%E9%AA%8C%E6%B5%81%E7%A8%8B.png" class title="登录校验流程"><h3 id="SpringSecurity完整流程"><a href="#SpringSecurity完整流程" class="headerlink" title="SpringSecurity完整流程"></a>SpringSecurity完整流程</h3><p>SpringSecurity其实就是一个过滤器链，内部包含了各种功能的过滤器。</p><p><strong>基础流程图</strong></p><img src="/article/52913/%E6%B5%81%E7%A8%8B%E5%9B%BE-9039561.png" class title="流程图"><p><strong>UsernamePasswordAuthenticationFilter</strong>:负责处理我们在登陆页面填写了用户名密码后的登陆请求。入门案例的认证工作主要有它负责。</p><p><strong>ExceptionTranslationFilter：</strong> 处理过滤器链中抛出的任何AccessDeniedException和AuthenticationException 。</p><p><strong>FilterSecurityInterceptor：</strong> 负责权限校验的过滤器。</p><p>SpringSecurity过滤器链中有哪些过滤器及它们的顺序：</p><img src="/article/52913/SpringSecurity%E8%BF%87%E6%BB%A4%E5%99%A8%E9%93%BE.png" class title="SpringSecurity过滤器链"><h3 id="认证流程详解"><a href="#认证流程详解" class="headerlink" title="认证流程详解"></a>认证流程详解</h3><img src="/article/52913/%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3-9040230.png" class title="认证流程详解"><p><strong>Authentication接口</strong>: 它的实现类，表示当前访问系统的用户，封装了用户相关信息。</p><p><strong>AuthenticationManager接口</strong>：定义了认证Authentication的方法</p><p><strong>UserDetailsService接口</strong>：加载用户特定数据的核心接口。里面定义了一个根据用户名查询用户信息的方法。</p><p><strong>UserDetails接口</strong>：提供核心用户信息。通过UserDetailsService根据用户名获取处理的用户信息要封装成UserDetails对象返回。然后将这些信息封装到Authentication对象中。</p><ol><li><p>自定义登录验证</p><img src="/article/52913/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81.png" class title="自定义登录验证"><ol><li><p>自定义登录接口</p><p>调用ProviderManager的方法进行认证 如果认证通过生成jwt</p><p>使用userId作为Key，用户信息作为Value，把用户信息存入redis中</p></li><li><p>自定义UserDetailsService</p><p>在这个实现类中去查询数据库</p></li></ol></li><li><p>校验</p><p>定义Jwt认证过滤器，获取token，解析token获取其中的userid，从redis中获取用户信息，存入SecurityContextHolder</p></li></ol><h2 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h2><h3 id="授权基本流程"><a href="#授权基本流程" class="headerlink" title="授权基本流程"></a>授权基本流程</h3><p>在 SpringSecurity 中，会使用默认的 FilterSecurityInterceptor 来进行权限校验。在 FilterSecurityInterceptor 中会从 SecurityContextHolder 获取其中的 Authentication ，然后获取其中的权限信息。当前用户是否拥有访问当前资源所需的权限。</p><p>所以我们在项目中只需要把当前登录用户的权限信息也存入Authentication。</p><p>然后设置我们的资源所需要的权限即可。</p><h3 id="授权实现"><a href="#授权实现" class="headerlink" title="授权实现"></a>授权实现</h3><p><strong>限制访问资源所需权限</strong></p><p>可以使用注解去指定访问对应的资源所需的权限</p><ol><li><p>需要先开启相关配置 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@EnableGlobalMethodSecurity(prePostEnabled = true)</span><br></code></pre></td></tr></table></figure></li><li><p>在方法中使用注解配置权限</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@PreAuthorize(&quot;hasAuthority(&#x27;权限&#x27;)&quot;)</span><br></code></pre></td></tr></table></figure></li></ol><p><strong>封装权限信息</strong></p><h2 id="自定义失败处理"><a href="#自定义失败处理" class="headerlink" title="自定义失败处理"></a>自定义失败处理</h2><p>希望在认证失败或者是授权失败的情况下也能和我们的接口一样返回相同结构的json，这样可以让前端能对响应进行统一的处理。</p><p>在 SpringSecurity 中，如果我们在认证或者授权的过程中出现了异常会被 ExceptionTranslationFilter 捕获到。在 ExceptionTranslationFilter 中会去判断是认证失败还是授权失败出现的异常。</p><p>如果是认证过程中出现的异常会被封装成 AuthenticationException 然后调用 <strong>AuthenticationEntryPoint</strong>  对象的方法去进行异常处理。</p><p>如果是授权过程中出现的异常会被封装成 AccessDeniedException 然后调用 <strong>AccessDeniedHandler</strong> 对象的方法去进行异常处理。</p><h2 id="跨域"><a href="#跨域" class="headerlink" title="跨域"></a>跨域</h2><p>浏览器出于安全的考虑，使用 XMLHttpRequest 对象发起 HTTP 请求时必须遵守同源策略，否则就是跨域的 HTTP 请求，默认情况下是被禁止的。 同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致。</p><ol><li><p>先对SpringBoot配置，运行跨域请求</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CorsConfig</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">WebMvcConfigurer</span> </span>&#123;<br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addCorsMappings</span><span class="hljs-params">(CorsRegistry registry)</span> </span>&#123;<br>    <span class="hljs-comment">// 设置允许跨域的路径</span><br>    registry.addMapping(<span class="hljs-string">&quot;/**&quot;</span>)<br>      <span class="hljs-comment">// 设置允许跨域请求的域名</span><br>      .allowedOriginPatterns(<span class="hljs-string">&quot;*&quot;</span>)<br>      <span class="hljs-comment">// 是否允许cookie</span><br>      .allowCredentials(<span class="hljs-keyword">true</span>)<br>      <span class="hljs-comment">// 设置允许的请求方式</span><br>      .allowedMethods(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;POST&quot;</span>, <span class="hljs-string">&quot;DELETE&quot;</span>, <span class="hljs-string">&quot;PUT&quot;</span>)<br>      <span class="hljs-comment">// 设置允许的header属性</span><br>      .allowedHeaders(<span class="hljs-string">&quot;*&quot;</span>)<br>      <span class="hljs-comment">// 跨域允许时间</span><br>      .maxAge(<span class="hljs-number">3600</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>开启 SpringSecurity 的跨域访问</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">configure</span><span class="hljs-params">(HttpSecurity http)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>  <span class="hljs-comment">//允许跨域</span><br>  http.cors();<br>&#125;<br></code></pre></td></tr></table></figure></li></ol><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="CSRF"><a href="#CSRF" class="headerlink" title="CSRF"></a>CSRF</h3><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。</p><p>SpringSecurit 去防止 CSRF 攻击的方式就是通过 csrf_token 。后端会生成一个 csrf_token ，前端发起请求的时候需要携带这个 csrf_token ,后端会有过滤器进行校验，如果没有携带或者是伪造的就不允许访问。</p><p>CSRF 攻击依靠的是 cookie 中所携带的认证信息。但是在前后端分离的项目中我们的认证信息其实是 token ，而 token 并不是存储中 cookie 中，并且需要前端代码去把token 设置到请求头中才可以，所以CSRF攻击也就不用担心了。</p><p>3566930579</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学习源于&lt;a href=&quot;https://www.bilibili.com/video/BV1mm4y1X7Hc?p=8&amp;amp;spm_id_from=pageDriver&quot;&gt;三更草堂&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;SpringSecurity&quot;&gt;&lt;a href=&quot;#S
      
    
    </summary>
    
      <category term="Java" scheme="https://boyolo.github.io/categories/Java/"/>
    
      <category term="SpringSecurity" scheme="https://boyolo.github.io/categories/Java/SpringSecurity/"/>
    
      <category term="SpringSecurity" scheme="https://boyolo.github.io/categories/SpringSecurity/"/>
    
    
      <category term="实习,SpringSecurity" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-SpringSecurity/"/>
    
  </entry>
  
  <entry>
    <title>Mysql45讲-实践（一）</title>
    <link href="https://boyolo.github.io/article/46662.html"/>
    <id>https://boyolo.github.io/article/46662.html</id>
    <published>2022-03-30T06:49:39.000Z</published>
    <updated>2022-04-13T15:28:31.252Z</updated>
    
    <content type="html"><![CDATA[<h2 id="普通索引和唯一索引，应该怎么选择？"><a href="#普通索引和唯一索引，应该怎么选择？" class="headerlink" title="普通索引和唯一索引，应该怎么选择？"></a>普通索引和唯一索引，应该怎么选择？</h2><h3 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a>更新过程</h3><p><strong>change buffer</strong></p><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些<strong>更新操作</strong>缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p><p>需要说明的是，虽然名字叫作 change buffer，实际上它是<strong>可以持久化的数据</strong>。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。</p><p>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 <strong>merge</strong>。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。</p><blockquote><p>merge 的执行流程是这样的：</p><ol><li>从磁盘读入数据页到内存（老版本的数据页）；</li><li>从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；</li><li>写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。</li></ol><p>这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</p></blockquote><p>显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够<strong>避免占用内存，提高内存利用率。</strong></p><blockquote><p><strong>问题：什么条件下可以使用 change buffer 呢？</strong></p><p>对于<strong>唯一索引</strong>来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。</p><p><strong>唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。</strong></p></blockquote><p>change buffer 用的是 buffer pool 里的内存，因此<strong>不能无限增大</strong>。change buffer 的大小，可以通过参数 <code>innodb_change_buffer_max_size</code> 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</p><p><strong>在表中插入一个新纪录，InnoDB处理流程：</strong></p><ol><li>这个记录要更新的目标页在内存中<ol><li>对于唯一索引来说，找到位置，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，找到位置，插入这个值，语句执行结束。</li></ol></li><li><strong>这个记录要更新的目标页不在内存中</strong><ol><li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</li></ol></li></ol><p>将数据从磁盘读入内存涉及<strong>随机 IO 的访问，是数据库里面成本最高的操作之一</strong>。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p><blockquote><p>对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p><p>反过来，假设一个业务的更新模式是<strong>写入之后马上会做查询</strong>，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</p></blockquote><h3 id="索引选择和实践"><a href="#索引选择和实践" class="headerlink" title="索引选择和实践"></a>索引选择和实践</h3><p><strong>建议尽量选择普通索引</strong></p><p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。</p><ol><li>首先，业务正确性优先。</li><li>然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。</li></ol><h3 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change buffer 和 redo log"></a>change buffer 和 redo log</h3><p>如果要简单地对比这两个机制在提升更新性能上的收益的话</p><p><strong>redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写）</strong>，</p><p><strong>change buffer 主要节省的则是随机读磁盘的 IO 消耗</strong></p><hr><p><strong>问题：change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？</strong></p><blockquote><p><strong>不会丢失</strong></p><p>虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。</p></blockquote><hr><h2 id="MySQL为什么有时候会选错索引？"><a href="#MySQL为什么有时候会选错索引？" class="headerlink" title="MySQL为什么有时候会选错索引？"></a>MySQL为什么有时候会选错索引？</h2><h3 id="优化器的逻辑"><a href="#优化器的逻辑" class="headerlink" title="优化器的逻辑"></a>优化器的逻辑</h3><p><strong>选择索引是优化器的工作。</strong></p><p>而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。</p><p><strong>扫描行数</strong>并不是唯一的判断标准，优化器还会结合<strong>是否使用临时表、是否排序</strong>等因素进行综合判断。</p><h3 id="扫描行数是怎么判断的？"><a href="#扫描行数是怎么判断的？" class="headerlink" title="扫描行数是怎么判断的？"></a>扫描行数是怎么判断的？</h3><p><strong>区分度</strong></p><p>MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据<strong>统计信息</strong>来估算记录数。这个统计信息就是索引的“<strong>区分度</strong>”。</p><p><strong>基数</strong></p><p>显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“<strong>基数</strong>”（cardinality）。也就是说，这个基数越大，索引的区分度越好。</p><p><strong>采样统计</strong></p><p>为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。</p><p>采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数</p><p>而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。</p><p>在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 <code>innodb_stats_persistent</code> 的值来选择：</p><ol><li>设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。</li><li>设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。</li></ol><p>对于由于索引统计信息不准确导致的问题，你可以用 <code>analyze table</code> 来解决。</p><h3 id="索引选择异常和处理"><a href="#索引选择异常和处理" class="headerlink" title="索引选择异常和处理"></a>索引选择异常和处理</h3><p><strong>原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？</strong></p><ol><li><p>采用 <code>force index</code> 强行选择一个索引</p><p>MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</p></li><li><p>考虑修改语句，引导 MySQL 使用我们期望的索引</p></li><li><p>在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引</p></li></ol><h2 id="怎么给字符串字段加索引？"><a href="#怎么给字符串字段加索引？" class="headerlink" title="怎么给字符串字段加索引？"></a>怎么给字符串字段加索引？</h2><p><strong>用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</strong></p><blockquote><p>当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？</p></blockquote><p>我们在建立索引时关注的是<strong>区分度</strong>，区分度越高越好。因为区分度越高，意味着重复的键值越少。</p><p>使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例。</p><h3 id="前缀索引对覆盖索引的影响"><a href="#前缀索引对覆盖索引的影响" class="headerlink" title="前缀索引对覆盖索引的影响"></a>前缀索引对覆盖索引的影响</h3><ol><li><p>使用前缀索引可能会增加扫描行数</p></li><li><p>使用前缀索引就用不上覆盖索引对查询性能的优化</p><blockquote><p>即使查询到的信息已经包含了所有的信息，但是系统并不确定前缀索引的定义是否截断了完整信息，依然需要回到主键索引再查一次</p></blockquote></li></ol><h3 id="其他方式"><a href="#其他方式" class="headerlink" title="其他方式"></a>其他方式</h3><ol><li>使用倒序存储</li><li>使用 hash 字段</li></ol><blockquote><p>使用倒序存储和使用 hash 字段这两种方法的<strong>异同点</strong></p><ol><li>相同点：都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的。同样地，hash 字段的方式也只能支持等值查询。</li><li>区别：<ol><li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</li><li>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。</li><li>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li></ol></li></ol></blockquote><h2 id="为什么我的MySQL会“抖”一下？"><a href="#为什么我的MySQL会“抖”一下？" class="headerlink" title="为什么我的MySQL会“抖”一下？"></a>为什么我的MySQL会“抖”一下？</h2><p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。</p><p>内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</p><p><strong>不论是脏页还是干净页，都在内存中。</strong></p><p>InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</p><p>第一种是，还没有使用的；</p><p>第二种是，使用了并且是干净页；</p><p>第三种是，使用了并且是脏页。</p><p>InnoDB 的策略是<strong>尽量使用内存</strong>，因此对于一个长时间运行的库来说，未被使用的页面很少。</p><p>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</p><blockquote><p>刷脏页出现以下这两种情况，都是会明显影响性能的：</p><ol><li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li><li>日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的</li></ol></blockquote><h3 id="InnoDB-刷脏页的控制策略"><a href="#InnoDB-刷脏页的控制策略" class="headerlink" title="InnoDB 刷脏页的控制策略"></a>InnoDB 刷脏页的控制策略</h3><p><code>innodb_io_capacity</code> 这个参数，会告诉 InnoDB 你的磁盘能力。建议设置成磁盘的 IOPS。</p><p>测试磁盘随机读写的命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest <br></code></pre></td></tr></table></figure><p>InnoDB 的刷盘速度就是要参考这两个因素：</p><ol><li>一个是脏页比例</li><li>一个是 redo log 写盘速度</li></ol><blockquote><p>InnoDB 会根据这两个因素先单独算出两个数字</p><p>参数 <code>innodb_max_dirty_pages_pct</code> 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的<strong>脏页比例（假设为 M）</strong>，算出一个范围在 0 到 100 之间的数字：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">F1(M)<br>&#123;<br>  if M&gt;=innodb_max_dirty_pages_pct then<br>      return 100;<br>  return 100*M/innodb_max_dirty_pages_pct;<br>&#125;<br></code></pre></td></tr></table></figure><p>InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的<strong>差值，我们假设为 N</strong>。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。</p><p>根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 <strong>R</strong>，之后引擎就可以按照 <code>innodb_io_capacity</code> 定义的能力<strong>乘以 R%</strong> 来控制刷脏页的速度。</p></blockquote><p>InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。</p><p><strong>要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例(Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total)，不要让它经常接近 75%。</strong></p><h2 id="为什么表数据删掉一半，表文件大小不变？"><a href="#为什么表数据删掉一半，表文件大小不变？" class="headerlink" title="为什么表数据删掉一半，表文件大小不变？"></a>为什么表数据删掉一半，表文件大小不变？</h2><p>一个 InnoDB 表包含两部分，即：<strong>表结构定义和数据</strong>。在 MySQL 8.0 版本以前，表结构是存在以 <code>.frm</code> 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。</p><p>表结构定义占用的空间很小</p><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 <code>innodb_file_per_table</code> 控制的：</p><ol><li>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</li><li>这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 <code>.ibd</code> 为后缀的文件中。</li></ol><p>建议将这个值设置为 ON:因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 <code>drop table</code> 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的</p><h3 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h3><p>InnoDB 里的数据都是用 B+ 树的结构组织的,如果我们删掉了一个数据页上的记录，InnoDB 引擎只会把删除的记录标记为删除，如果之后要再插入一个记录时，可能会复用这个位置<strong>（记录的复用，只限于符合范围条件的数据）</strong>。</p><p>如果删掉了一个数据页上的所有记录，整个数据页就可以被复用了<strong>（当整个页从 B+ 树里面摘掉以后，可以复用到任何位置）</strong>。</p><p><strong>delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。</strong></p><h3 id="重建表"><a href="#重建表" class="headerlink" title="重建表"></a>重建表</h3><p>不止是删除数据会造成空洞，插入数据也会造成空洞。</p><p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。</p><blockquote><p>经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而<strong>重建表</strong> <code>alter table</code>，就可以达到这样的目的。</p></blockquote><p>Online DDL 之后，重建表的流程：</p><ol><li>建立一个临时文件，扫描表 A 主键的所有数据页；</li><li>用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；</li><li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中；</li><li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件；</li><li>用临时文件替换表 A 的数据文件。</li></ol><h2 id="count-这么慢，我该怎么办？"><a href="#count-这么慢，我该怎么办？" class="headerlink" title="count(*)这么慢，我该怎么办？"></a>count(*)这么慢，我该怎么办？</h2><p><strong>count(*) 的实现方式</strong></p><ol><li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</li><li>InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li></ol><p>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。</p><p>对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。<strong>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</strong></p><blockquote><p><strong>问题：<code>TABLE_ROWS</code> 能代替 count(*) 吗？</strong></p><p>索引统计的值是通过采样来估算的。TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。</p><p>官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。</p></blockquote><h3 id="用缓存系统保存计数"><a href="#用缓存系统保存计数" class="headerlink" title="用缓存系统保存计数"></a>用缓存系统保存计数</h3><p>对于更新很频繁的库来说,可以用一个 Redis 服务来保存这个表的总行数。</p><blockquote><p><strong>问题1：缓存系统可能会丢失更新</strong></p><p>Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。</p><hr><p><strong>问题2：将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。</strong></p><ol><li>一种是，查到的结果里面有最新插入记录，而 Redis 的计数里还没加 1；</li><li>另一种是，查到的结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。</li></ol><p>在并发系统里面，我们是无法精确控制不同线程的执行时刻的。</p></blockquote><h3 id="在数据库保存计数"><a href="#在数据库保存计数" class="headerlink" title="在数据库保存计数"></a>在数据库保存计数</h3><p>把这个计数直接放到数据库里单独的一张计数表中</p><ol><li>解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的；</li><li>解决计数不精确的问题，利用“事务”这个特性，解决问题。</li></ol><h3 id="不同的-count-用法"><a href="#不同的-count-用法" class="headerlink" title="不同的 count 用法"></a>不同的 count 用法</h3><p>count() 的语义：</p><p>count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。</p><p>count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。</p><blockquote><p>分析性能差别的时候，三个原则：</p><ol><li>server 层要什么就给什么；</li><li>InnoDB 只给必要的值；</li><li>现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。</li></ol></blockquote><ol><li><p><code>count(主键 id)</code> </p><p>InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</p></li><li><p><code>count(1)</code></p><p>InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</p></li><li><p><code>count(字段)</code></p><ol><li>如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；</li><li>如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。</li></ol></li><li><p><code>count(*)</code></p><p>不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。</p></li></ol><p>按照效率排序的话，<strong>count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)</strong></p><p>所以尽量使用 count(*)。</p><h2 id="“order-by”是怎么工作的？"><a href="#“order-by”是怎么工作的？" class="headerlink" title="“order by”是怎么工作的？"></a>“order by”是怎么工作的？</h2><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer</p><p>排序时，可能在内存 sort_buffer 中排序 ，也可能需要使用外部排序，<strong>这取决于排序所需的内存和参数 sort_buffer_size。</strong></p><p>sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</p><blockquote><p>通过查看 <code>OPTIMIZER_TRACE</code> 的结果来确认</p><p><code>number_of_tmp_files</code> 表示是否使用了临时文件：</p><ol><li>如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。</li><li>如果 sort_buffer_size 太小，number_of_tmp_files 就是 n，表示排序过程中使用 n 个临时文件。</li></ol></blockquote><p>sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。</p><h3 id="rowid-排序"><a href="#rowid-排序" class="headerlink" title="rowid 排序"></a>rowid 排序</h3><p>全字段排序<strong>问题</strong>：如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。</p><p><strong>解决：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">SET max_length_for_sort_data = 16;<br></code></pre></td></tr></table></figure><p><code>max_length_for_sort_data</code> ，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。</p><p><strong>新的算法放入 sort_buffer 的字段，只有要排序的列和主键 id。</strong></p><p>最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。</p><h3 id="全字段排序-VS-rowid-排序"><a href="#全字段排序-VS-rowid-排序" class="headerlink" title="全字段排序 VS rowid 排序"></a>全字段排序 VS rowid 排序</h3><ol><li>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。</li><li>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。</li></ol><p><strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p><blockquote><p>对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。</p></blockquote><h2 id="如何正确地显示随机消息？"><a href="#如何正确地显示随机消息？" class="headerlink" title="如何正确地显示随机消息？"></a>如何正确地显示随机消息？</h2><h3 id="内存临时表"><a href="#内存临时表" class="headerlink" title="内存临时表"></a>内存临时表</h3><p>用 order by rand() 来实现</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select word from words order by rand() limit 3;<br></code></pre></td></tr></table></figure><p>对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。</p><p><strong>rowid:每个引擎用来唯一标识数据行的信息</strong></p><ol><li><p>对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；</p></li><li><p>对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的。</p></li></ol><p><strong>order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</strong></p><h3 id="磁盘临时表"><a href="#磁盘临时表" class="headerlink" title="磁盘临时表"></a>磁盘临时表</h3><p><code>tmp_table_size</code> 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 <code>tmp_table_size</code>，那么内存临时表就会转成磁盘临时表。</p><p>磁盘临时表使用的引擎默认是 InnoDB，是由参数 <code>internal_tmp_disk_storage_engine</code> 控制的。</p><p>当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。</p><p><strong>优先队列排序算法</strong></p><p>（当存在 limit 时，并且 limit 需要的维护的最大堆的大小小于 sort_buffer，就会使用这个算法。）</p><ol><li>对于这 n 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；</li><li>取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；</li><li>重复第 2 步，直到第 n 个 (R’,rowid’) 完成比较。</li></ol><h2 id="为什么我只查一行的语句，也执行这么慢？"><a href="#为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="为什么我只查一行的语句，也执行这么慢？"></a>为什么我只查一行的语句，也执行这么慢？</h2><h3 id="第一类：查询长时间不返回"><a href="#第一类：查询长时间不返回" class="headerlink" title="第一类：查询长时间不返回"></a>第一类：查询长时间不返回</h3><blockquote><p>出现情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from t where id=1;<br></code></pre></td></tr></table></figure><p>一般碰到这种情况的话，大概率是表 t 被锁住了。</p></blockquote><p>查看当前语句处于什么状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">show processlist;<br></code></pre></td></tr></table></figure><ol><li><p>等 MDL 锁</p><p>使用 show processlist 命令查看 Waiting for table metadata lock</p><p>表示的是，现在有一个线程正在请求或者持有 MDL 写锁，把 select 语句堵住了。</p><p><strong>处理方法：找到谁持有 MDL 写锁，然后把它 kill 掉</strong></p><p>(MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失，建议可以开启mysql的 performance_schema 功能，这个可以定位被锁的线程情况)</p><p>通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。</p></li><li><p>等 flush</p><blockquote><p>mysql&gt; select * from information_schema.processlist where id=1;</p></blockquote><p>查出来这个线程的状态是 <strong>Waiting for table flush</strong></p><p>这个状态表示的是，现在有一个线程正要做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">#如果指定表 t 的话，代表的是只关闭表 t；<br>flush tables t with read lock;<br>#如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。<br>flush tables with read lock;<br></code></pre></td></tr></table></figure><p>但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。</p><p>所以，出现 <strong>Waiting for table flush</strong> 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。</p></li><li><p>等行锁</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from t where id=1 lock in share mode; <br>#读锁（S 锁，共享锁） 由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。<br>mysql&gt; select k from t where id=1 for update; <br>#写锁（X 锁，排他锁）<br></code></pre></td></tr></table></figure><p>MySQL 5.7，通过 <strong>sys.innodb_lock_waits</strong> 表查到是谁占着这个写锁。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from sys.innodb_lock_waits where locked_table=&#x27;`test`.`t`&#x27;\G<br></code></pre></td></tr></table></figure><p><strong>直接断开这个连接</strong>。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。</p></li></ol><h3 id="第二类：查询慢"><a href="#第二类：查询慢" class="headerlink" title="第二类：查询慢"></a>第二类：查询慢</h3><p>一致性读导致回滚日志过大引起的一致性读慢，当前读快</p><h2 id="幻读是什么，幻读有什么问题？"><a href="#幻读是什么，幻读有什么问题？" class="headerlink" title="幻读是什么，幻读有什么问题？"></a>幻读是什么，幻读有什么问题？</h2><h3 id="幻读是什么？"><a href="#幻读是什么？" class="headerlink" title="幻读是什么？"></a>幻读是什么？</h3><p>幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</p><p>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，<strong>幻读在“当前读”下才会出现。</strong></p><h3 id="幻读有什么问题？"><a href="#幻读有什么问题？" class="headerlink" title="幻读有什么问题？"></a>幻读有什么问题？</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `id` int(11) NOT NULL,<br>  `c` int(11) DEFAULT NULL,<br>  `d` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  KEY `c` (`c`)<br>) ENGINE=InnoDB;<br><br>insert into t values(0,0,0),(5,5,5),<br>(10,10,10),(15,15,15),(20,20,20),(25,25,25);<br></code></pre></td></tr></table></figure></blockquote><ol><li><p>首先是语义上的。</p><blockquote><p><img src="/article/假设只在 id=5 这一行加行锁 -- 语义被破坏.png"><span class="image-caption">假设只在 id=5 这一行加行锁 -- 语义被破坏</span></p><p>T1: session A 声明，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。</p><p>T2:session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。</p><p><strong>这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。</strong></p></blockquote></li><li><p>其次，是数据一致性的问题。</p><p>锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。</p><blockquote><p><img src="/article/假设只在 id=5 这一行加行锁 -- 数据一致性问题.png"><span class="image-caption">假设只在 id=5 这一行加行锁 -- 数据一致性问题</span></p><p><strong>update 的加锁语义和 select …for update 是一致的</strong></p><ol><li><p>正常执行</p><p>经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;</p><p>经过 T2 时刻，id=0 这一行变成 (0,5,5);</p><p>经过 T4 时刻，表里面多了一行 (1,5,5);</p></li><li><p>binlog 记录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs mysql">#T2 时刻，session B 事务提交，写入了两条语句；<br>update t set d=5 where id=0; /*(0,0,5)*/<br>update t set c=5 where id=0; /*(0,5,5)*/<br>#T4 时刻，session C 事务提交，写入了两条语句；<br>insert into t values(1,1,5); /*(1,1,5)*/<br>update t set c=5 where id=1; /*(1,5,5)*/<br>#T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。<br>update t set d=100 where d=5;/*所有d=5的行，d改成100*/<br></code></pre></td></tr></table></figure><p>这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。</p><p>id=0 和 id=1 这两行，发生了数据不一致。</p></li></ol><hr><p>为了解决上面数据不一致的问题，假设把扫描过程中碰到的行都加锁</p><img src="/article/46662/%E5%81%87%E8%AE%BE%E6%89%AB%E6%8F%8F%E5%88%B0%E7%9A%84%E8%A1%8C%E9%83%BD%E8%A2%AB%E5%8A%A0%E4%B8%8A%E4%BA%86%E8%A1%8C%E9%94%81.png" class title="假设扫描到的行都被加上了行锁"><p>由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。</p><p>binlog:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">insert into t values(1,1,5); /*(1,1,5)*/<br>update t set c=5 where id=1; /*(1,5,5)*/<br><br>update t set d=100 where d=5;/*所有d=5的行，d改成100*/<br><br>update t set d=5 where id=0; /*(0,0,5)*/<br>update t set c=5 where id=0; /*(0,5,5)*/<br></code></pre></td></tr></table></figure><p>按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。</p><p>id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。(因为：在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。)</p></blockquote></li></ol><p><strong>即使把所有的记录都加上锁，还是阻止不了新插入的记录</strong></p><h3 id="如何解决幻读？"><a href="#如何解决幻读？" class="headerlink" title="如何解决幻读？"></a>如何解决幻读？</h3><p>产生幻读的原因是，<strong>行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。</strong></p><p><strong>为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。</strong></p><p><strong>间隙锁，锁的就是两个值之间的空隙。</strong></p><blockquote><p>初始化插入了 6 个记录，这就产生了 7 个间隙</p><img src="/article/46662/%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95%E4%B8%8A%E7%9A%84%E8%A1%8C%E9%94%81%E5%92%8C%E9%97%B4%E9%9A%99%E9%94%81.png" class title="主键索引上的行锁和间隙锁"><p>当你执行 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from t where d=5 for update<br></code></pre></td></tr></table></figure><p>就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。</p></blockquote><p><strong>在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。</strong></p><p>数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。</p><p><strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。</strong>间隙锁之间都不存在冲突关系。</p><p>间隙锁和行锁合称 <strong>next-key lock</strong>，每个 next-key lock 是<strong>前开后闭区间</strong>。</p><blockquote><p>也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。</p></blockquote><p><strong>间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。</strong></p><blockquote><p><strong>只有在可重复读的隔离级别下，才会有间隙锁。读提交的隔离级别下不会有间隙锁</strong></p></blockquote><h2 id="为什么我只改一行的语句，锁这么多？"><a href="#为什么我只改一行的语句，锁这么多？" class="headerlink" title="为什么我只改一行的语句，锁这么多？"></a>为什么我只改一行的语句，锁这么多？</h2><p><strong>加锁规则</strong>：两个“原则”、两个“优化”和一个“bug”</p><ol><li>原则 1：加锁的基本单位是 <strong>next-key lock</strong>。next-key lock 是前开后闭区间。</li><li>原则 2：查找过程中访问到的对象才会加锁。</li><li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ol><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `id` int(11) NOT NULL,<br>  `c` int(11) DEFAULT NULL,<br>  `d` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  KEY `c` (`c`)<br>) ENGINE=InnoDB;<br><br>insert into t values(0,0,0),(5,5,5),<br>(10,10,10),(15,15,15),(20,20,20),(25,25,25);<br></code></pre></td></tr></table></figure></blockquote><h3 id="等值查询间隙锁"><a href="#等值查询间隙锁" class="headerlink" title="等值查询间隙锁"></a>等值查询间隙锁</h3><blockquote><img src="/article/46662/%E7%AD%89%E5%80%BC%E6%9F%A5%E8%AF%A2%E7%9A%84%E9%97%B4%E9%9A%99%E9%94%81.png" class title="等值查询的间隙锁"><p>由于表 t 中没有 id=7 的记录</p><ol><li>根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；</li><li>同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。</li></ol><p><strong>session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。</strong></p></blockquote><h3 id="非唯一索引等值锁"><a href="#非唯一索引等值锁" class="headerlink" title="非唯一索引等值锁"></a>非唯一索引等值锁</h3><blockquote><img src="/article/46662/%E5%8F%AA%E5%8A%A0%E5%9C%A8%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E4%B8%8A%E7%9A%84%E9%94%81.png" class title="只加在非唯一索引上的锁"><ol><li>根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。</li><li>要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。</li><li>但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。</li><li>根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。(加锁，是加在索引上的。 列上，有索引，就加在索引上； 列上，没有索引，就加在主键上；)</li></ol><p>但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。</p><p><strong>lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁</strong>。</p><p>这个例子说明，<strong>锁是加在索引上的</strong>；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。（改为select d ，因为索引c，并没有d列的值，需要回表，查主键，这样就会把id=5这行数据加锁。session B会被锁住。 session C 还是会因为session A 在C列上的间隙锁(0,5},(5,10)而不能插入。 实际加锁范围是：id=5的行锁，普通索引c上锁范围(0,5},(5,10)）</p></blockquote><h3 id="主键索引范围锁"><a href="#主键索引范围锁" class="headerlink" title="主键索引范围锁"></a>主键索引范围锁</h3><blockquote><p>这两条查询语句，加锁范围相同吗？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from t where id=10 for update;<br>mysql&gt; select * from t where id&gt;=10 and id&lt;11 for update;<br></code></pre></td></tr></table></figure><img src="/article/46662/%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95%E4%B8%8A%E8%8C%83%E5%9B%B4%E6%9F%A5%E8%AF%A2%E7%9A%84%E9%94%81.png" class title="主键索引上范围查询的锁"><ol><li>开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。</li><li>范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。</li></ol><p>所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。</p><p>注意：首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。</p></blockquote><h3 id="非唯一索引范围锁"><a href="#非唯一索引范围锁" class="headerlink" title="非唯一索引范围锁"></a>非唯一索引范围锁</h3><blockquote><img src="/article/46662/%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E8%8C%83%E5%9B%B4%E9%94%81.png" class title="非唯一索引范围锁"><p>这次 session A 用字段 c 来判断</p><p>加锁规则跟主键索引范围锁唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。</p></blockquote><h3 id="唯一索引范围锁-bug"><a href="#唯一索引范围锁-bug" class="headerlink" title="唯一索引范围锁 bug"></a>唯一索引范围锁 bug</h3><blockquote><p><img src="/article/唯一索引范围锁的 bug.png"><span class="image-caption">唯一索引范围锁的 bug</span></p><p>session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了</p><p>但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。</p></blockquote><h3 id="非唯一索引上存在”等值”的例子"><a href="#非唯一索引上存在”等值”的例子" class="headerlink" title="非唯一索引上存在”等值”的例子"></a>非唯一索引上存在”等值”的例子</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; insert into t values(30,10,30);<br></code></pre></td></tr></table></figure><p>新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。</p><p>由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。</p><img src="/article/46662/%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%AD%89%E5%80%BC%E7%9A%84%E4%BE%8B%E5%AD%90.png" class title="非唯一索引等值的例子"><p>可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。</p><p><img src="/article/delete 示例.png"><span class="image-caption">delete 示例</span></p><ol><li>session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。</li><li>session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。</li></ol><p>也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。</p><p><img src="/article/delete 加锁效果示例.png"><span class="image-caption">delete 加锁效果示例</span></p></blockquote><h3 id="limit-语句加锁"><a href="#limit-语句加锁" class="headerlink" title="limit 语句加锁"></a>limit 语句加锁</h3><blockquote><p><img src="/article/limit 语句加锁.png"><span class="image-caption">limit 语句加锁</span></p><p>session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了。</p><p>这是因为， delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。</p><p>因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间。</p><p><img src="/article/带 limit 2 的加锁效果.png"><span class="image-caption">带 limit 2 的加锁效果</span></p><p><strong>在删除数据的时候尽量加 limit</strong>。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。</p></blockquote><h3 id="一个死锁的例子"><a href="#一个死锁的例子" class="headerlink" title="一个死锁的例子"></a>一个死锁的例子</h3><blockquote><img src="/article/46662/%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97.png" class title="操作序列"><ol><li>session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；</li><li>session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；</li><li>然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。</li></ol><p>session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。</p><p><strong>也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;普通索引和唯一索引，应该怎么选择？&quot;&gt;&lt;a href=&quot;#普通索引和唯一索引，应该怎么选择？&quot; class=&quot;headerlink&quot; title=&quot;普通索引和唯一索引，应该怎么选择？&quot;&gt;&lt;/a&gt;普通索引和唯一索引，应该怎么选择？&lt;/h2&gt;&lt;h3 id=&quot;更新过程&quot;
      
    
    </summary>
    
      <category term="Mysql" scheme="https://boyolo.github.io/categories/Mysql/"/>
    
      <category term="面试" scheme="https://boyolo.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="实习,Mysql" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Mysql45讲</title>
    <link href="https://boyolo.github.io/article/53105.html"/>
    <id>https://boyolo.github.io/article/53105.html</id>
    <published>2022-03-26T06:52:53.000Z</published>
    <updated>2022-04-12T08:22:10.381Z</updated>
    
    <content type="html"><![CDATA[<p>关于MySQL的发音：</p><blockquote><p>The official way to pronounce “MySQL” is “My Ess Que Ell” (not “my sequel”), but we do not mind if you pronounce it as “my sequel” or in some other localized way.</p></blockquote><h2 id="一条SQL查询语句是如何执行的？"><a href="#一条SQL查询语句是如何执行的？" class="headerlink" title="一条SQL查询语句是如何执行的？"></a>一条SQL查询语句是如何执行的？</h2><p><img src="/article/MySQL 的基本架构示意图.png"><span class="image-caption">img</span></p><p><strong>MySQL 可以分为 Server 层和存储引擎层两部分。</strong>不同的存储引擎共用一个 Server 层。</p><p>Server 层包括<strong>连接器、查询缓存、分析器、优化器、执行器</strong>等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><p>现在最常用的存储引擎是 <strong>InnoDB</strong>，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql -h<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.558ex" height="2.509ex" style="vertical-align: -0.671ex;" viewbox="0 -791.3 2823.4 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title"><title id="MathJax-SVG-1-Title">ip -P</title><defs aria-hidden="true"><path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"/><path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"/><path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"/><path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"/></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true"> <use xlink:href="#E1-MJMATHI-69" x="0" y="0"/> <use xlink:href="#E1-MJMATHI-70" x="345" y="0"/> <use xlink:href="#E1-MJMAIN-2212" x="1071" y="0"/> <use xlink:href="#E1-MJMATHI-50" x="2071" y="0"/></g></svg>port -u$user -p<br></code></pre></td></tr></table></figure><p>连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份。</p><blockquote><ol><li><p>如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。</p></li><li><p>如果用户名密码认证通过，连接器会到<strong>权限表</strong>里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</p><p>(一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。)</p></li></ol></blockquote><p>显示用户正在运行的线程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">show processlist<br></code></pre></td></tr></table></figure><p>Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。</p><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 <code>wait_timeout</code> 控制的，默认值是 8 小时。</p><p><strong>建议尽量使用长连接</strong></p><blockquote><p>数据库里面，<strong>长连接</strong>是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。<strong>短连接</strong>则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</p></blockquote><p>全部使用长连接后，有些时候 MySQL 占用内存涨得特别快</p><p><strong>这是因为</strong> MySQL 在执行过程中临时使用的内存是管理在<strong>连接对象里面的</strong>。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，<strong>被系统强行杀掉（OOM）</strong>，从现象看就是 MySQL 异常重启了。</p><blockquote><p><strong>解决方法</strong></p><ol><li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>MySQL 5.7 或更新版本：可以在每次执行一个比较大的操作后，通过执行 <code>mysql_reset_connection</code> 来重新初始化连接资源。<strong>这个过程不需要重连和重新做权限验证</strong>，但是会将连接恢复到刚刚创建完时的状态。</li></ol></blockquote><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>MySQL 拿到一个查询请求后:</p><ol><li>先到查询缓存：之前是否执行过这条语句，之前执行过的语句及其结果可能会以 <code>key(查询语句)-value（查询结果）</code> 对的形式，被直接缓存在内存中。(<a href="https://dev.mysql.com/blog-archive/mysql-8-0-retiring-support-for-the-query-cache/">MySQL 8.0版本直接将查询缓存的整块功能删掉了</a> （弊大于利）查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空)。</li><li>没有找缓存结果：<a href="#分析器">开始真正执行语句</a></li></ol><h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><ol><li><strong>词法分析</strong>：MySQL 需要识别出输入的的字符串（SQL语句）分别是什么，代表什么；</li><li><strong>语法分析</strong>：根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。（语法错误提示：“You have an error in your SQL syntax”）。</li></ol><p>分析器处理语法和解析查询, 生成一课对应的解析树。 预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器。</p><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>在开始执行之前，还要先经过优化器的处理。</p><p><strong>优化器</strong>是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><p>优化器阶段完成后，这个语句的执行方案就确定下来了。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><ol><li>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限(在工程实现上，如果命中查询缓存，会在<strong>查询缓存返回结果</strong>的时候，做权限验证。查询也会在<strong>优化器之前</strong>调用 precheck 验证权限)；</li><li>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的<strong>引擎定义</strong>，去使用这个引擎提供的接口。</li></ol><p>你会在数据库的慢查询日志中看到一个 <code>rows_examined</code> 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><blockquote><p>执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 <code>rows_examined</code> 并不是完全相同的</p></blockquote><h2 id="一条SQL更新语句是如何执行的？"><a href="#一条SQL更新语句是如何执行的？" class="headerlink" title="一条SQL更新语句是如何执行的？"></a>一条SQL更新语句是如何执行的？</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">update T set c=c+1 where ID=2;<br></code></pre></td></tr></table></figure><p><img src="/article/MySQL 的基本架构示意图.png"><span class="image-caption">img</span></p><p><strong>执行流程</strong></p><p>执行语句前要先<strong>连接</strong>数据库，这是连接器的工作</p><p>在一个表上有<strong>更新</strong>的时候，跟这个表有关的<strong>查询缓存会失效</strong>，所以这条语句就会把表 T 上所有缓存结果都清空。</p><p><strong>分析器</strong>会通过词法和语法解析知道这是一条更新语句。<strong>优化器</strong>决定要使用 ID 这个索引。然后，<strong>执行器</strong>负责具体执行，找到这一行，然后更新。</p><p>两个重要的日志模块：<strong>redo log（重做日志）和 binlog（归档日志）</strong>（只要我们写的是DML语句（insert,update,delete,create）等等，那么我们在数据库服务端执行的时候就会涉及到 redo log(重做日志) 和 binlog(归档日志) 两个日志文件的变动）</p><h3 id="redo-log（重做日志）–InnoDB特有的日志"><a href="#redo-log（重做日志）–InnoDB特有的日志" class="headerlink" title="redo log（重做日志）–InnoDB特有的日志"></a>redo log（重做日志）–InnoDB特有的日志</h3><blockquote><p>问题：如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。</p></blockquote><p>解决：<strong>WAL 技术</strong>，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。</p><p>当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 <strong>redo log</strong>里面，并更新内存，这个时候更新就算完成了。同时，<strong>InnoDB 引擎</strong>会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><blockquote><p>问题：InnoDB 的 redo log 是固定大小的，redo log 写满之后，先将日志中的部分记录写到磁盘，腾出redo log的空间继续写入。</p></blockquote><p><img src="/article/redo log 循环写入.png"><span class="image-caption">img</span></p><p><code>write pos</code> 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。<code>check point</code> 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p><code>write pos</code> 和 <code>checkpoint</code> 之间的是“redo log”上还空着的部分，可以用来记录新的操作。</p><p>如果 <code>write pos</code> 追上 <code>checkpoint</code>，表示“redo log”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</p><p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 <strong>crash-safe</strong>。</p><p>redo log 用于保证 crash-safe 能力。<code>innodb_flush_log_at_trx_commit</code> 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。</p><h3 id="binlog（归档日志）–Server层-日志"><a href="#binlog（归档日志）–Server层-日志" class="headerlink" title="binlog（归档日志）–Server层 日志"></a>binlog（归档日志）–Server层 日志</h3><blockquote><p>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，<strong>binlog</strong> 日志只能用于<strong>归档</strong>。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。</p></blockquote><p><code>sync_binlog</code> 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</p><table><thead><tr><th style="text-align:left">redo log</th><th style="text-align:left">binlog</th></tr></thead><tbody><tr><td style="text-align:left">InnoDB 引擎特有的</td><td style="text-align:left">MySQL 的 Server 层实现的，所有引擎都可以使用</td></tr><tr><td style="text-align:left">物理日志：记录的是“在某个数据页上做了什么修改”</td><td style="text-align:left">逻辑日志：记录的是这个语句的原始逻辑</td></tr><tr><td style="text-align:left">循环写入，空间固定会用完</td><td style="text-align:left">追加写入，binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志</td></tr></tbody></table><p>浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。</p><p><img src="/article/update 语句执行流程.png"><span class="image-caption">img</span></p><p><strong>两阶段提交</strong>:为了让两份日志之间的逻辑一致</p><h2 id="事务隔离：为什么你改了我还看不见？"><a href="#事务隔离：为什么你改了我还看不见？" class="headerlink" title="事务隔离：为什么你改了我还看不见？"></a>事务隔离：为什么你改了我还看不见？</h2><p>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的（MySQL 原生的 MyISAM 引擎就不支持事务）。</p><p>ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</p><h3 id="隔离性与隔离级"><a href="#隔离性与隔离级" class="headerlink" title="隔离性与隔离级"></a>隔离性与隔离级</h3><p><strong>隔离得越严实，效率就会越低</strong></p><p>当数据库上有多个事务同时执行的时候，就可能出现<strong>脏读</strong>（dirty read）、<strong>不可重复读</strong>（non-repeatable read）、<strong>幻读</strong>（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><ol><li><strong>脏读</strong>：读到其他事务未提交的数据；</li><li><strong>不可重复读</strong>：前后读取的记录内容不一致；</li><li><strong>幻读</strong>：前后读取的记录数量不一致。</li></ol><blockquote><p>脏读：事务A查询数据后进行了一次修改且未提交，而事务B这个时候去查询，然后使用了这个数据，因为这个数据还没有被事务A 提交到数据库中，所以事务B的得到数据就是脏数据，对脏数据进行操作可能是不正确的。 不可重复读: 事务A访问了两次数据，但是这访问第二次之间事务B进行一次并进行了修改，导致事务A访问第二次的时候得到的数据与第一次不同，导致一个事务访问两次数据得到的数据不相同。因此叫做不可重复读。 幻读： 与不可重复读都点相似，只是这次是事务B在事务A访问第二次的之前做了一个新增，导致事务A第二次读取的时候发现了多的记录，这就是幻读。 丢失修改：事务A访问该数据，事务B也访问该数据，事务A修改了该数据，事务B也修改了该数据，这样导致事务A的修改被丢失，因此称为丢失修改； 不可重复度和幻读区别： 不可重复读主要是修改操作，幻读的主要在于新增或者删除。 幻读主要在于数据的条数变了，而不可重复读主要在于数据内容变了。</p></blockquote><p>SQL 标准的事务隔离级别包括<strong>：读未提交</strong>（read uncommitted）、<strong>读提交</strong>（read committed）、<strong>可重复读</strong>（repeatable read）和<strong>串行化</strong>（serializable ）。</p><ol><li><strong>读未提交</strong>，一个事务还没提交时，它做的变更就能被别的事务看到；</li><li><strong>读提交</strong>，一个事务提交之后，它做的变更才会被其他事务看到；</li><li><strong>可重复读</strong>，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的；(<strong>别人改数据的事务已经提交，我在我的事务中也不去读</strong>。)</li><li><strong>串行化</strong>，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ol><p><strong>这4种隔离级别，并行性能依次降低，安全性依次提高</strong></p><p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p><p>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。（事务启动时的视图可以认为是静态的，不受其他事务更新的影响。）</p><blockquote><p>事务启动方式：</p><ol><li>一致性视图是在执行第一个快照读语句时创建的；</li><li>一致性视图是在执行 <code>start transaction with consistent snapshot</code> 时创建的。</li></ol></blockquote><p>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。</p><p>这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</p><p>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p><p>Oracle 数据库的默认隔离级别其实就是“读提交”；</p><p>MySQL默认的隔离级别是”可重复读”。</p><h3 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h3><p>实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p><p><strong>同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）</strong></p><p>系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。（就是当系统里没有比这个回滚日志更早的视图的时候）</p><p><strong>问题：为什么建议你尽量不要使用长事务</strong></p><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 <strong>ibdata</strong> 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。</p><p>长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。</p><h3 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h3><ol><li><p>显式启动事务语句， <code>begin</code> 或 <code>start transaction</code>。配套的提交语句是 <code>commit</code>，回滚语句是 <code>rollback</code>。</p></li><li><p><code>set autocommit=0</code>，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 <code>commit</code> 或<code>rollback</code>语句，或者断开连接。</p><p><strong>建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。</strong></p></li><li><p>用 <code>commit work and chain</code> 语法</p><p>在 <strong>autocommit 为 1</strong> 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p></li></ol><p><code>information_schema 库的 innodb_trx 这个表</code>中查询长事务</p><hr><p><strong>问题：有什么方案来避免出现或者处理长事物？</strong></p><blockquote><p>首先，从应用开发端来看：</p><ol><li>确认是否使用了 <code>set autocommit=0</code>。这个确认工作可以在测试环境中开展，把 MySQL 的 <code>general_log</code> 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。</li><li>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 <code>begin/commit</code> 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。</li><li>业务连接数据库的时候，根据业务本身的预估，通过 <code>SET MAX_EXECUTION_TIME</code> 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。</li></ol><p>其次，从数据库端来看：</p><ol><li><p>监控 <code>information_schema.Innodb_trx 表</code>，设置长事务阈值，超过就报警 / 或者 kill；</p></li><li><p>Percona 的 pt-kill 这个工具不错，推荐使用；</p></li><li><p>在业务功能测试阶段要求输出所有的 <code>general_log</code>，分析日志行为提前发现问题；</p></li><li><p>如果使用的是 MySQL 5.6 或者更新版本，把 <code>innodb_undo_tablespaces</code> 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</p><p>(innodb_undo_tablespaces是控制undo是否开启独立的表空间的参数 </p><ol><li>为0表示：undo使用系统表空间，即ibdata1 </li><li>不为0表示：使用独立的表空间，一般名称为 undo001 undo002，存放地址的配置项为：innodb_undo_directory </li><li>一般innodb_undo_tablespaces 默认配置为0，innodb_undo_directory默认配置为当前数据目录)</li></ol></li></ol></blockquote><hr><h2 id="深入浅出索引"><a href="#深入浅出索引" class="headerlink" title="深入浅出索引"></a>深入浅出索引</h2><p><strong>索引的出现是为了提高查询效率</strong></p><h3 id="哈希表索引模型"><a href="#哈希表索引模型" class="headerlink" title="哈希表索引模型"></a>哈希表索引模型</h3><p>哈希表是一种以 <strong>键 - 值</strong>（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。</p><blockquote><p>思路：</p><p>用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。</p></blockquote><blockquote><p><strong>问题</strong>：多个 key 值经过哈希函数的换算，会出现同一个值的情况</p><p><strong>解决方法：</strong>拉出一个链表</p><img src="/article/53105/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class title="根据身份证号查找对应的名字"><p><strong>缺点：</strong>因为不是有序的（比如四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加），所以<strong>哈希索引做区间查询的速度是很慢的</strong>。</p><p>哈希表这种结构适用于只有<strong>等值查询</strong>的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p></blockquote><h3 id="有序数组索引模型"><a href="#有序数组索引模型" class="headerlink" title="有序数组索引模型"></a>有序数组索引模型</h3><p>适用于<strong>等值查询</strong>和<strong>范围查询</strong>场景</p><blockquote><p>根据身份证号查找对应的名字<strong>有序数组</strong>示意图</p><img src="/article/53105/%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class title="根据身份证号查找对应的名字"><p>用二分法就可以快速得到，这个<strong>时间复杂度是 O(log(N))</strong></p><p><strong>优点：</strong>仅仅看查询效率，有序数组就是最好的数据结构</p><p><strong>缺点：</strong>中间插入一个记录就必须得挪动后面所有的记录，成本太高</p><p>有序数组索引<strong>只适用于静态存储引擎</strong></p></blockquote><h3 id="二叉搜索树索引模型"><a href="#二叉搜索树索引模型" class="headerlink" title="二叉搜索树索引模型"></a>二叉搜索树索引模型</h3><blockquote><p>根据身份证号查找对应的名字<strong>二叉搜索树</strong>示意图</p><img src="/article/53105/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%A4%BA%E6%84%8F%E5%9B%BE.png" class title="根据身份证号查找对应的名字"><p>二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。</p><p><strong>时间复杂度是 O(log(N))</strong></p><p><strong>优点：</strong>二叉树是搜索效率最高的</p><p><strong>缺点：</strong></p><ol><li>为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是<strong>平衡二叉树</strong>。为了做这个保证，<strong>更新的时间复杂度也是 O(log(N))</strong>。</li><li>索引不止存在内存中，还要写到磁盘上（所以大多数的数据库存储并不使用二叉树）</li></ol><p><strong>解决方法：</strong>为了让一个查询<strong>尽量少地读磁盘</strong>，就必须让查询过程<strong>访问尽量少的数据块</strong>。那么，我们就不应该使用二叉树，而是要使用“<strong>N 叉</strong>”树。这里，<strong>“N 叉”树中的“N”取决于数据块的大小</strong>。</p><p><strong>N叉树优点：</strong>读写上的性能优点，以及适配磁盘的访问模式</p></blockquote><p>在 MySQL 中，<strong>索引是在存储引擎层实现</strong>的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。</p><h3 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h3><p>在 InnoDB 中，表都是根据<strong>主键顺序以索引</strong>的形式存放的，这种存储方式的表称为<strong>索引组织表</strong>。</p><p>InnoDB 使用了 <strong><a href="https://blog.csdn.net/weixin_35871519/article/details/113303881">B+ 树索引模型</a></strong>，所以数据都是存储在 B+ 树中的。</p><p><strong>每一个索引在 InnoDB 里面对应一棵 B+ 树</strong></p><p><strong>B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。</strong></p><blockquote><p>假设有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; create table T(<br>id int primary key, <br>k int not null, <br>name varchar(16),<br>index (k))engine=InnoDB;<br></code></pre></td></tr></table></figure><p>表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下:</p><p><img src="/article/InnoDB 的索引组织结构.png"><span class="image-caption">InnoDB 的索引组织结构</span></p><p>图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><p>查询时：</p><ol><li><p>主键查询方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from T where ID=500<br></code></pre></td></tr></table></figure><p>只需要搜索 ID 这棵 B+ 树</p></li><li><p>普通索引查询方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from T where k=5<br></code></pre></td></tr></table></figure><p>需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。</p></li></ol><p>基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该<strong>尽量使用主键查询</strong>。</p></blockquote><p><strong>主键索引</strong>的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为<strong>聚簇索引</strong>（clustered index）。</p><p><strong>非主键索引</strong>的叶子节点内容是<strong>主键的值</strong>。在 InnoDB 里，非主键索引也被称为<strong>二级索引</strong>（secondary index）。</p><h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a><strong>索引维护</strong></h3><p>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。</p><blockquote><p><strong>页分裂</strong>:新插入的数据符合条件的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。（除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。）</p><p><strong>页合并</strong>：当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p></blockquote><p><strong>性能和存储空间方面考量，自增主键往往是更合理的选择</strong></p><p>自增主键的插入数据模式，正符合了递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</p><blockquote><p>适合用业务字段直接做主键的场景:</p><ol><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ol><p>直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树</p></blockquote><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p><strong>经过索引优化，避免回表过程</strong></p><blockquote><p>搜索由</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select * from T where k between 3 and 5<br></code></pre></td></tr></table></figure><p>变为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">select ID from T where k between 3 and 5<br></code></pre></td></tr></table></figure><p>只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为<strong>覆盖索引</strong>。</p></blockquote><p>由于覆盖索引可以<strong>减少树的搜索次数</strong>，<strong>显著提升查询性能</strong>，所以使用<strong>覆盖索引</strong>是一个常用的性能优化手段。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p><strong>为一个不频繁的请求创建一个索引感觉很浪费</strong></p><p><strong>最左前缀</strong>可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p><blockquote><p><strong>问题：</strong>在建立联合索引的时候，如何安排索引内的字段顺序</p><p><strong>评估标准:</strong>索引的复用能力</p><ol><li>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</li><li>(如果既有联合查询，又有基于 a、b 各自的查询)第二原则是,空间</li></ol></blockquote><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>MySQL 5.6 引入的<strong>索引下推优化</strong>（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">mysql&gt; select * from tuser where name like &#x27;张%&#x27; and age=10 and ismale=1;<br></code></pre></td></tr></table></figure><p>无索引下推执行流程</p><img src="/article/53105/%E6%97%A0%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.jpg" class title="无索引下推执行流程"><p>索引下推执行流程</p><img src="/article/53105/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.jpg" class title="索引下推执行流程"></blockquote><hr><p><strong>问题：重建索引时，是重建非主键索引还是主键索引？</strong></p><p>重建非主键索引：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">alter table T drop index k;<br>alter table T add index(k);<br></code></pre></td></tr></table></figure><p>重建主键索引：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">alter table T drop primary key;<br>alter table T add primary key(id);<br></code></pre></td></tr></table></figure><blockquote><p>重建索引 k 的做法是合理的，可以达到省空间的目的。</p><p>但是，重建主键的过程不合理。<strong>不论是删除主键还是创建主键，都会将整个表重建。</strong>所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。</p></blockquote><hr><h2 id="全局锁和表锁-：给表加个字段怎么有这么多阻碍？"><a href="#全局锁和表锁-：给表加个字段怎么有这么多阻碍？" class="headerlink" title="全局锁和表锁 ：给表加个字段怎么有这么多阻碍？"></a>全局锁和表锁 ：给表加个字段怎么有这么多阻碍？</h2><p>数据库锁设计的<strong>初衷是处理并发问题</strong>。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。</p><p>MySQL 里面的锁大致可以分成<strong>全局锁、表级锁和行锁</strong>三类。</p><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock (FTWRL)</code>。</p><p>当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong></p><blockquote><p>全局锁的问题:</p><ol><li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li><li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</li></ol></blockquote><p>官方自带的逻辑备份工具是 <strong>mysqldump</strong>。当 mysqldump 使用参数–<code>single-transaction</code> 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。</p><blockquote><p><strong>问题：有了mysqldump功能，为什么还需要 FTWRL 呢？</strong></p><p>一致性读是好，但前提是引擎要支持<strong>可重复读</strong>隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。</p></blockquote><p><strong><code>single-transaction</code> 方法只适用于所有的表使用事务引擎的库。</strong></p><blockquote><p><strong>问题：既然要全库只读，为什么不使用 set global readonly=true 的方式呢？</strong></p><ol><li>一在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，不建议你使用。</li><li>在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。</li></ol></blockquote><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>MySQL 里面表级别的锁有两种：一种是<strong>表锁</strong>，一种是<strong>元数据锁</strong>（meta data lock，MDL)。</p><p><strong>表锁</strong></p><p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法<strong>除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</strong></p><p><strong>元数据锁</strong>(MySQL 5.5 版本中引入)</p><p>MDL 不需要显式使用，在访问一个表的时候会被自动加上。</p><p>MDL 的作用是，<strong>保证读写的正确性</strong>。</p><ol><li>当对一个表做增删改查操作的时候，加 <strong>MDL 读锁</strong>；</li><li>当要对表做结构变更操作的时候，加 <strong>MDL 写锁</strong>。</li></ol><p>每执行一条DML、DDL语句时都会申请MDL锁，<strong>DML操作需要MDL读锁，DDL操作需要MDL写锁</strong>（MDL加锁过程是系统自动控制，无法直接干预，读读共享，读写互斥，写写互斥）</p><ol><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li></ol><p><strong>MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。</strong></p><p><strong>表锁一般是在数据库引擎 <em>不支持行锁</em> 的时候才会被用到的。</strong></p><hr><p><strong>问题：如何安全地给小表加字段？</strong></p><blockquote><p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 <code>information_schema 库的 innodb_trx 表</code>中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。</p></blockquote><hr><p><strong>问题：如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？</strong></p><blockquote><p>在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。</p><p><code>DDL NOWAIT/WAIT n</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">ALTER TABLE tbl_name NOWAIT add column ...<br>ALTER TABLE tbl_name WAIT N add column ... <br></code></pre></td></tr></table></figure></blockquote><hr><p><strong>问题：如果你发现你的应用程序里有 lock tables 这样的语句，需要怎么做？</strong></p><blockquote><ol><li>要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；</li><li>要么是你的引擎升级了，但是代码还没升级。最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。</li></ol></blockquote><hr><p><strong>问题：备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？</strong></p><blockquote><p>假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mysql">Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;<br>Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；<br>/* other tables */<br>Q3:SAVEPOINT sp;<br>/* 时刻 1 */<br>Q4:show create table `t1`;<br>/* 时刻 2 */<br>Q5:SELECT * FROM `t1`;<br>/* 时刻 3 */<br>Q6:ROLLBACK TO SAVEPOINT sp;<br>/* 时刻 4 */<br>/* other tables */<br></code></pre></td></tr></table></figure><ol><li>如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。</li><li>如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；</li><li>如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。</li><li>从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。</li></ol></blockquote><hr><h2 id="行锁功过：怎么减少行锁对性能的影响？"><a href="#行锁功过：怎么减少行锁对性能的影响？" class="headerlink" title="行锁功过：怎么减少行锁对性能的影响？"></a>行锁功过：怎么减少行锁对性能的影响？</h2><p><strong>MySQL 的行锁是在引擎层由各个引擎自己实现的。</strong></p><p>(MyISAM 引擎就不支持行锁)</p><h3 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h3><p>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p><p><strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong></p><h3 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h3><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为<strong>死锁</strong>。</p><p>当出现死锁以后，有两种策略：</p><ol><li><p>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 <code>innodb_lock_wait_timeout</code> 来设置。</p><blockquote><p>问题：在 InnoDB 中，<code>innodb_lock_wait_timeout</code> 的默认值是 50s，意味着当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。</p><p>我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p></blockquote></li><li><p>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 on，表示开启这个逻辑。</p><p><code>innodb_deadlock_detect</code> 的默认值本身就是 on。</p><blockquote><p>问题：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p><p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p></blockquote></li></ol><hr><p><strong>问题：怎么解决由热点行更新导致的性能问题呢？</strong></p><blockquote><p>问题的症结在于，死锁检测要耗费大量的 CPU 资源。</p><ol><li><p>如果能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。</p></li><li><p>控制并发度</p><p>并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。</p><p>基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。</p></li><li><p>设计上优化</p><p>将一行改成逻辑上的多行来减少锁冲突</p></li></ol></blockquote><hr><h2 id="事务到底是隔离的还是不隔离的？"><a href="#事务到底是隔离的还是不隔离的？" class="headerlink" title="事务到底是隔离的还是不隔离的？"></a>事务到底是隔离的还是不隔离的？</h2><p>在 MySQL 里，有两个“视图”的概念：</p><p>一个是 <strong>view</strong>。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。</p><p>另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 <code>consistent read view</code>，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。<strong>它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。</strong></p><p><a href="#事务隔离：为什么你改了我还看不见？">参考章节</a></p><h3 id="“快照”在-MVCC-里是怎么工作的？"><a href="#“快照”在-MVCC-里是怎么工作的？" class="headerlink" title="“快照”在 MVCC 里是怎么工作的？"></a>“快照”在 MVCC 里是怎么工作的？</h3><p>在<strong>可重复读</strong>隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是<strong>基于整库</strong>的。</p><p>InnoDB 里面每个事务有一个<strong>唯一</strong>的事务 ID，叫作 <code>transaction id</code>。它是在事务开始的时候向 InnoDB 的事务系统申请的，是<strong>按申请顺序严格递增</strong>的。</p><p>而每行数据也都是有多个版本的。<strong>每次</strong>事务更新数据的时候，都会生成一个<strong>新的数据版本</strong>，并且把 <code>transaction id</code> 赋值给这个数据版本的事务 ID，记为 <code>row trx_id</code>。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。</p><p><strong>也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。</strong></p><p>在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。</p><p>数组里面事务 ID 的最小值记为<strong>低水位</strong>，当前系统里面已经创建过的事务 ID 的最大值加 1 记为<strong>高水位</strong>。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p><p>数据版本的可见性规则，就是<strong>基于数据的 row trx_id 和这个一致性视图的对比结果得到的。</strong></p><img src="/article/53105/%E6%95%B0%E6%8D%AE%E7%89%88%E6%9C%AC%E5%8F%AF%E8%A7%81%E6%80%A7%E8%A7%84%E5%88%99.png" class title="数据版本可见性规则"><p>对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：</p><ol><li><p>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p></li><li><p>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</p></li><li><p>如果落在黄色部分，那就包括两种情况</p><ol><li>若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；</li><li>若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li></ol><p>(高水位的定义是事务创建时所有未提交的事务ID的最大值+1是高水位，但并不是小于高水位大于低水位的事务就都没有提交。所以row trx_id 在这个范围内却不在数组中就是已经提交了的可见)</p></li></ol><p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p><ol><li>版本未提交，不可见；</li><li>版本已提交，但是是在视图创建后提交的，不可见；</li><li>版本已提交，而且是在视图创建前提交的，可见。</li></ol><h3 id="更新逻辑"><a href="#更新逻辑" class="headerlink" title="更新逻辑"></a>更新逻辑</h3><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“<strong>当前读</strong>”（current read）。</p><p>除了 update 语句外，select 语句如果加锁，也是当前读。（<code>lock in share mode</code> 或 <code>for update</code>）</p><hr><p><strong>问题：事务的可重复读的能力是怎么实现的？</strong></p><blockquote><p>可重复读的<strong>核心就是一致性读</strong>（consistent read）；</p><p>而事务更新数据的时候，只能用<strong>当前读</strong>。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p><p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p><ol><li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</li><li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</li></ol></blockquote><blockquote><p>这里需要说明一下，“<code>start transaction with consistent snapshot</code>; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在<strong>读提交</strong>隔离级别下，这个用法就没意义了，等效于普通的 <code>start transaction</code>。</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于MySQL的发音：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The official way to pronounce “MySQL” is “My Ess Que Ell” (not “my sequel”), but we do not mind if you pr
      
    
    </summary>
    
      <category term="Mysql" scheme="https://boyolo.github.io/categories/Mysql/"/>
    
      <category term="面试" scheme="https://boyolo.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="实习,Mysql" scheme="https://boyolo.github.io/tags/%E5%AE%9E%E4%B9%A0-Mysql/"/>
    
  </entry>
  
</feed>
